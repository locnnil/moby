diff --git a/.golangci.yml b/.golangci.yml
index 9aa35b6ca4..e84e4c1ad9 100644
--- a/.golangci.yml
+++ b/.golangci.yml
@@ -212,12 +212,7 @@ issues:
       linters:
         - staticcheck
 
-    - text: "SA1019: idtools\\.(CurrentIdentity|ToUserIdentityMapping|FromUserIdentityMapping|IDMap|MkdirAndChown|MkdirAllAndChown|MkdirAllAndChownNew) is deprecated"
-      linters:
-        - staticcheck
-
-    # FIXME(thaJeztah): ignoring until https://github.com/moby/moby/pull/49743 is merged.
-    - text: "SA1019: (archive|chrootarchive|dockerarchive)\\..* is deprecated: use \\[(archive|chrootarchive)\\."
+    - text: "SA1019: idtools\\.(CurrentIdentity|FromUserIdentityMapping|IDMap|MkdirAndChown|MkdirAllAndChown|MkdirAllAndChownNew) is deprecated"
       linters:
         - staticcheck
 
diff --git a/api/server/router/container/backend.go b/api/server/router/container/backend.go
index f763e59acb..6c6766c324 100644
--- a/api/server/router/container/backend.go
+++ b/api/server/router/container/backend.go
@@ -8,7 +8,7 @@ import (
 	"github.com/docker/docker/api/types/container"
 	"github.com/docker/docker/api/types/filters"
 	containerpkg "github.com/docker/docker/container"
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 )
 
 // execBackend includes functions to implement to provide exec functionality.
diff --git a/builder/builder-next/adapters/snapshot/snapshot.go b/builder/builder-next/adapters/snapshot/snapshot.go
index 1618b4231f..72dbbd3d30 100644
--- a/builder/builder-next/adapters/snapshot/snapshot.go
+++ b/builder/builder-next/adapters/snapshot/snapshot.go
@@ -18,7 +18,6 @@ import (
 	"github.com/moby/buildkit/snapshot"
 	"github.com/moby/buildkit/util/leaseutil"
 	"github.com/moby/locker"
-	"github.com/moby/sys/user"
 	"github.com/opencontainers/go-digest"
 	"github.com/pkg/errors"
 	bolt "go.etcd.io/bbolt"
@@ -37,7 +36,7 @@ type Opt struct {
 	GraphDriver     graphdriver.Driver
 	LayerStore      layer.Store
 	Root            string
-	IdentityMapping user.IdentityMapping
+	IdentityMapping idtools.IdentityMapping
 }
 
 type graphIDRegistrar interface {
@@ -113,9 +112,7 @@ func (s *snapshotter) IdentityMapping() *idtools.IdentityMapping {
 	if s.opt.IdentityMapping.Empty() {
 		return nil
 	}
-	// TODO: Update this once BuildKit switches from idtools
-	idMap := idtools.FromUserIdentityMapping(s.opt.IdentityMapping)
-	return &idMap
+	return &s.opt.IdentityMapping
 }
 
 func (s *snapshotter) Prepare(ctx context.Context, key, parent string, opts ...snapshots.Opt) error {
@@ -497,7 +494,7 @@ type mountable struct {
 	acquire  func() ([]mount.Mount, func() error, error)
 	release  func() error
 	refCount int
-	idmap    user.IdentityMapping
+	idmap    idtools.IdentityMapping
 }
 
 func (m *mountable) Mount() ([]mount.Mount, func() error, error) {
@@ -547,7 +544,5 @@ func (m *mountable) IdentityMapping() *idtools.IdentityMapping {
 	if m.idmap.Empty() {
 		return nil
 	}
-	// TODO: Update this once BuildKit switches from idtools
-	idtoolsMap := idtools.FromUserIdentityMapping(m.idmap)
-	return &idtoolsMap
+	return &m.idmap
 }
diff --git a/builder/builder-next/builder.go b/builder/builder-next/builder.go
index ff3b28e858..7668bf86df 100644
--- a/builder/builder-next/builder.go
+++ b/builder/builder-next/builder.go
@@ -26,6 +26,7 @@ import (
 	"github.com/docker/docker/errdefs"
 	"github.com/docker/docker/libnetwork"
 	"github.com/docker/docker/opts"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/docker/docker/pkg/streamformatter"
 	controlapi "github.com/moby/buildkit/api/services/control"
 	"github.com/moby/buildkit/client"
@@ -34,7 +35,6 @@ import (
 	"github.com/moby/buildkit/session"
 	"github.com/moby/buildkit/util/entitlements"
 	"github.com/moby/buildkit/util/tracing"
-	"github.com/moby/sys/user"
 	"github.com/pkg/errors"
 	"golang.org/x/sync/errgroup"
 	"google.golang.org/grpc"
@@ -89,7 +89,7 @@ type Opt struct {
 	RegistryHosts       docker.RegistryHosts
 	BuilderConfig       config.BuilderConfig
 	Rootless            bool
-	IdentityMapping     user.IdentityMapping
+	IdentityMapping     idtools.IdentityMapping
 	DNSConfig           config.DNSConfig
 	ApparmorProfile     string
 	UseSnapshotter      bool
diff --git a/builder/builder-next/executor_linux.go b/builder/builder-next/executor_linux.go
index 4813a6c5d1..b81fe8fab7 100644
--- a/builder/builder-next/executor_linux.go
+++ b/builder/builder-next/executor_linux.go
@@ -22,13 +22,12 @@ import (
 	"github.com/moby/buildkit/solver/llbsolver/cdidevices"
 	"github.com/moby/buildkit/solver/pb"
 	"github.com/moby/buildkit/util/network"
-	"github.com/moby/sys/user"
 	"github.com/opencontainers/runtime-spec/specs-go"
 )
 
 const networkName = "bridge"
 
-func newExecutor(root, cgroupParent string, net *libnetwork.Controller, dnsConfig *oci.DNSConfig, rootless bool, idmap user.IdentityMapping, apparmorProfile string, cdiManager *cdidevices.Manager) (executor.Executor, error) {
+func newExecutor(root, cgroupParent string, net *libnetwork.Controller, dnsConfig *oci.DNSConfig, rootless bool, idmap idtools.IdentityMapping, apparmorProfile string, cdiManager *cdidevices.Manager) (executor.Executor, error) {
 	netRoot := filepath.Join(root, "net")
 	networkProviders := map[pb.NetMode]network.Provider{
 		pb.NetMode_UNSET: &bridgeProvider{Controller: net, Root: netRoot},
@@ -49,9 +48,7 @@ func newExecutor(root, cgroupParent string, net *libnetwork.Controller, dnsConfi
 
 	// Returning a non-nil but empty *IdentityMapping breaks BuildKit:
 	// https://github.com/moby/moby/pull/39444
-	// TODO: Remove conversion once buildkit updates
-	idtoolsMap := idtools.FromUserIdentityMapping(idmap)
-	pidmap := &idtoolsMap
+	pidmap := &idmap
 	if idmap.Empty() {
 		pidmap = nil
 	}
diff --git a/builder/builder-next/executor_nolinux.go b/builder/builder-next/executor_nolinux.go
index 6150ecd641..ca0b6bc134 100644
--- a/builder/builder-next/executor_nolinux.go
+++ b/builder/builder-next/executor_nolinux.go
@@ -9,14 +9,14 @@ import (
 
 	"github.com/docker/docker/daemon/config"
 	"github.com/docker/docker/libnetwork"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/moby/buildkit/executor"
 	"github.com/moby/buildkit/executor/oci"
 	resourcetypes "github.com/moby/buildkit/executor/resources/types"
 	"github.com/moby/buildkit/solver/llbsolver/cdidevices"
-	"github.com/moby/sys/user"
 )
 
-func newExecutor(_, _ string, _ *libnetwork.Controller, _ *oci.DNSConfig, _ bool, _ user.IdentityMapping, _ string, _ *cdidevices.Manager) (executor.Executor, error) {
+func newExecutor(_, _ string, _ *libnetwork.Controller, _ *oci.DNSConfig, _ bool, _ idtools.IdentityMapping, _ string, _ *cdidevices.Manager) (executor.Executor, error) {
 	return &stubExecutor{}, nil
 }
 
diff --git a/builder/dockerfile/builder.go b/builder/dockerfile/builder.go
index 6c0661d95c..36096bccb6 100644
--- a/builder/dockerfile/builder.go
+++ b/builder/dockerfile/builder.go
@@ -16,12 +16,12 @@ import (
 	"github.com/docker/docker/builder"
 	"github.com/docker/docker/builder/remotecontext"
 	"github.com/docker/docker/errdefs"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/docker/docker/pkg/streamformatter"
 	"github.com/docker/docker/pkg/stringid"
 	"github.com/moby/buildkit/frontend/dockerfile/instructions"
 	"github.com/moby/buildkit/frontend/dockerfile/parser"
 	"github.com/moby/buildkit/frontend/dockerfile/shell"
-	"github.com/moby/sys/user"
 	ocispec "github.com/opencontainers/image-spec/specs-go/v1"
 	"github.com/pkg/errors"
 	"golang.org/x/sync/syncmap"
@@ -47,13 +47,13 @@ const (
 
 // BuildManager is shared across all Builder objects
 type BuildManager struct {
-	idMapping user.IdentityMapping
+	idMapping idtools.IdentityMapping
 	backend   builder.Backend
 	pathCache pathCache // TODO: make this persistent
 }
 
 // NewBuildManager creates a BuildManager
-func NewBuildManager(b builder.Backend, identityMapping user.IdentityMapping) (*BuildManager, error) {
+func NewBuildManager(b builder.Backend, identityMapping idtools.IdentityMapping) (*BuildManager, error) {
 	bm := &BuildManager{
 		backend:   b,
 		pathCache: &syncmap.Map{},
@@ -103,7 +103,7 @@ type builderOptions struct {
 	Backend        builder.Backend
 	ProgressWriter backend.ProgressWriter
 	PathCache      pathCache
-	IDMapping      user.IdentityMapping
+	IDMapping      idtools.IdentityMapping
 }
 
 // Builder is a Dockerfile builder
@@ -118,7 +118,7 @@ type Builder struct {
 
 	docker builder.Backend
 
-	idMapping        user.IdentityMapping
+	idMapping        idtools.IdentityMapping
 	disableCommit    bool
 	imageSources     *imageSources
 	pathCache        pathCache
diff --git a/builder/dockerfile/copy.go b/builder/dockerfile/copy.go
index 51d01ebab3..819c37c9c0 100644
--- a/builder/dockerfile/copy.go
+++ b/builder/dockerfile/copy.go
@@ -17,14 +17,14 @@ import (
 	"github.com/docker/docker/builder"
 	"github.com/docker/docker/builder/remotecontext"
 	"github.com/docker/docker/builder/remotecontext/urlutil"
+	"github.com/docker/docker/pkg/archive"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/docker/docker/pkg/longpath"
 	"github.com/docker/docker/pkg/progress"
 	"github.com/docker/docker/pkg/streamformatter"
 	"github.com/docker/docker/pkg/system"
 	"github.com/moby/buildkit/frontend/dockerfile/instructions"
-	"github.com/moby/go-archive"
 	"github.com/moby/sys/symlink"
-	"github.com/moby/sys/user"
 	ocispec "github.com/opencontainers/image-spec/specs-go/v1"
 	"github.com/pkg/errors"
 )
@@ -446,15 +446,9 @@ func downloadSource(output io.Writer, stdout io.Writer, srcURL string) (remote b
 	return lc, filename, err
 }
 
-type identity struct {
-	UID int
-	GID int
-	SID string
-}
-
 type copyFileOptions struct {
 	decompress bool
-	identity   *identity
+	identity   *idtools.Identity
 	archiver   *archive.Archiver
 }
 
@@ -504,7 +498,7 @@ func performCopyForInfo(dest copyInfo, source copyInfo, options copyFileOptions)
 	return copyFile(archiver, srcPath, destPath, options.identity)
 }
 
-func copyDirectory(archiver *archive.Archiver, source, dest string, identity *identity) error {
+func copyDirectory(archiver *archive.Archiver, source, dest string, identity *idtools.Identity) error {
 	destExists, err := isExistingDirectory(dest)
 	if err != nil {
 		return errors.Wrapf(err, "failed to query destination path")
@@ -519,13 +513,13 @@ func copyDirectory(archiver *archive.Archiver, source, dest string, identity *id
 	return nil
 }
 
-func copyFile(archiver *archive.Archiver, source, dest string, identity *identity) error {
+func copyFile(archiver *archive.Archiver, source, dest string, identity *idtools.Identity) error {
 	if identity == nil {
 		if err := os.MkdirAll(filepath.Dir(dest), 0o755); err != nil {
 			return err
 		}
 	} else {
-		if err := user.MkdirAllAndChown(filepath.Dir(dest), 0o755, identity.UID, identity.GID, user.WithOnlyNew); err != nil {
+		if err := idtools.MkdirAllAndChownNew(filepath.Dir(dest), 0o755, *identity); err != nil {
 			return errors.Wrapf(err, "failed to create new directory")
 		}
 	}
diff --git a/builder/dockerfile/copy_unix.go b/builder/dockerfile/copy_unix.go
index b538f9eb6c..a90afb98cb 100644
--- a/builder/dockerfile/copy_unix.go
+++ b/builder/dockerfile/copy_unix.go
@@ -7,9 +7,11 @@ import (
 	"path"
 	"path/filepath"
 	"strings"
+
+	"github.com/docker/docker/pkg/idtools"
 )
 
-func fixPermissions(source, destination string, id identity, overrideSkip bool) error {
+func fixPermissions(source, destination string, identity idtools.Identity, overrideSkip bool) error {
 	var (
 		skipChownRoot bool
 		err           error
@@ -37,7 +39,7 @@ func fixPermissions(source, destination string, id identity, overrideSkip bool)
 		}
 
 		fullpath = filepath.Join(destination, cleaned)
-		return os.Lchown(fullpath, id.UID, id.GID)
+		return os.Lchown(fullpath, identity.UID, identity.GID)
 	})
 }
 
diff --git a/builder/dockerfile/copy_windows.go b/builder/dockerfile/copy_windows.go
index f516d415a1..c4615cb4e1 100644
--- a/builder/dockerfile/copy_windows.go
+++ b/builder/dockerfile/copy_windows.go
@@ -8,6 +8,7 @@ import (
 
 	winio "github.com/Microsoft/go-winio"
 	"github.com/docker/docker/internal/usergroup"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/docker/docker/pkg/system"
 	"github.com/moby/sys/reexec"
 	"github.com/pkg/errors"
@@ -23,12 +24,12 @@ func init() {
 	reexec.Register("windows-fix-permissions", fixPermissionsReexec)
 }
 
-func fixPermissions(source, destination string, id identity, _ bool) error {
-	if id.SID == "" {
+func fixPermissions(source, destination string, identity idtools.Identity, _ bool) error {
+	if identity.SID == "" {
 		return nil
 	}
 
-	cmd := reexec.Command("windows-fix-permissions", source, destination, id.SID)
+	cmd := reexec.Command("windows-fix-permissions", source, destination, identity.SID)
 	output, err := cmd.CombinedOutput()
 
 	return errors.Wrapf(err, "failed to exec windows-fix-permissions: %s", output)
diff --git a/builder/dockerfile/evaluator_test.go b/builder/dockerfile/evaluator_test.go
index 21f226f1cd..48076906ba 100644
--- a/builder/dockerfile/evaluator_test.go
+++ b/builder/dockerfile/evaluator_test.go
@@ -7,8 +7,8 @@ import (
 	"testing"
 
 	"github.com/docker/docker/builder/remotecontext"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/moby/buildkit/frontend/dockerfile/instructions"
-	"github.com/moby/go-archive"
 	"github.com/moby/sys/reexec"
 	"gotest.tools/v3/assert"
 	is "gotest.tools/v3/assert/cmp"
diff --git a/builder/dockerfile/internals.go b/builder/dockerfile/internals.go
index 7d33b3c05f..fada8a65f2 100644
--- a/builder/dockerfile/internals.go
+++ b/builder/dockerfile/internals.go
@@ -19,10 +19,10 @@ import (
 	"github.com/docker/docker/builder"
 	networkSettings "github.com/docker/docker/daemon/network"
 	"github.com/docker/docker/image"
+	"github.com/docker/docker/pkg/archive"
+	"github.com/docker/docker/pkg/chrootarchive"
 	"github.com/docker/docker/pkg/stringid"
 	"github.com/docker/go-connections/nat"
-	"github.com/moby/go-archive"
-	"github.com/moby/go-archive/chrootarchive"
 	ocispec "github.com/opencontainers/image-spec/specs-go/v1"
 	"github.com/pkg/errors"
 )
@@ -152,13 +152,12 @@ func (b *Builder) performCopy(ctx context.Context, req dispatchRequest, inst cop
 		return err
 	}
 
-	uid, gid := b.idMapping.RootPair()
-	id := identity{UID: uid, GID: gid}
+	identity := b.idMapping.RootPair()
 	// if a chown was requested, perform the steps to get the uid, gid
 	// translated (if necessary because of user namespaces), and replace
 	// the root pair with the chown pair for copy operations
 	if inst.chownStr != "" {
-		id, err = parseChownFlag(ctx, b, state, inst.chownStr, destInfo.root, b.idMapping)
+		identity, err = parseChownFlag(ctx, b, state, inst.chownStr, destInfo.root, b.idMapping)
 		if err != nil {
 			if b.options.Platform != "windows" {
 				return errors.Wrapf(err, "unable to convert uid/gid chown string to host mapping")
@@ -174,7 +173,7 @@ func (b *Builder) performCopy(ctx context.Context, req dispatchRequest, inst cop
 			archiver:   b.getArchiver(),
 		}
 		if !inst.preserveOwnership {
-			opts.identity = &id
+			opts.identity = &identity
 		}
 		if err := performCopyForInfo(destInfo, info, opts); err != nil {
 			return errors.Wrapf(err, "failed to copy files")
diff --git a/builder/dockerfile/internals_linux.go b/builder/dockerfile/internals_linux.go
index 9b9e14ae39..694e129f75 100644
--- a/builder/dockerfile/internals_linux.go
+++ b/builder/dockerfile/internals_linux.go
@@ -6,16 +6,17 @@ import (
 	"strconv"
 	"strings"
 
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/moby/sys/symlink"
 	"github.com/moby/sys/user"
 	"github.com/pkg/errors"
 )
 
-func parseChownFlag(ctx context.Context, builder *Builder, state *dispatchState, chown, ctrRootPath string, identityMapping user.IdentityMapping) (identity, error) {
+func parseChownFlag(ctx context.Context, builder *Builder, state *dispatchState, chown, ctrRootPath string, identityMapping idtools.IdentityMapping) (idtools.Identity, error) {
 	var userStr, grpStr string
 	parts := strings.Split(chown, ":")
 	if len(parts) > 2 {
-		return identity{}, errors.New("invalid chown string format: " + chown)
+		return idtools.Identity{}, errors.New("invalid chown string format: " + chown)
 	}
 	if len(parts) == 1 {
 		// if no group specified, use the user spec as group as well
@@ -26,27 +27,27 @@ func parseChownFlag(ctx context.Context, builder *Builder, state *dispatchState,
 
 	passwdPath, err := symlink.FollowSymlinkInScope(filepath.Join(ctrRootPath, "etc", "passwd"), ctrRootPath)
 	if err != nil {
-		return identity{}, errors.Wrap(err, "can't resolve /etc/passwd path in container rootfs")
+		return idtools.Identity{}, errors.Wrap(err, "can't resolve /etc/passwd path in container rootfs")
 	}
 	groupPath, err := symlink.FollowSymlinkInScope(filepath.Join(ctrRootPath, "etc", "group"), ctrRootPath)
 	if err != nil {
-		return identity{}, errors.Wrap(err, "can't resolve /etc/group path in container rootfs")
+		return idtools.Identity{}, errors.Wrap(err, "can't resolve /etc/group path in container rootfs")
 	}
 	uid, err := lookupUser(userStr, passwdPath)
 	if err != nil {
-		return identity{}, errors.Wrap(err, "can't find uid for user "+userStr)
+		return idtools.Identity{}, errors.Wrap(err, "can't find uid for user "+userStr)
 	}
 	gid, err := lookupGroup(grpStr, groupPath)
 	if err != nil {
-		return identity{}, errors.Wrap(err, "can't find gid for group "+grpStr)
+		return idtools.Identity{}, errors.Wrap(err, "can't find gid for group "+grpStr)
 	}
 
 	// convert as necessary because of user namespaces
-	uid, gid, err = identityMapping.ToHost(uid, gid)
+	chownPair, err := identityMapping.ToHost(idtools.Identity{UID: uid, GID: gid})
 	if err != nil {
-		return identity{}, errors.Wrap(err, "unable to convert uid/gid to host mapping")
+		return idtools.Identity{}, errors.Wrap(err, "unable to convert uid/gid to host mapping")
 	}
-	return identity{UID: uid, GID: gid}, nil
+	return chownPair, nil
 }
 
 func lookupUser(userStr, filepath string) (int, error) {
diff --git a/builder/dockerfile/internals_linux_test.go b/builder/dockerfile/internals_linux_test.go
index eb8c953986..ae7e43283e 100644
--- a/builder/dockerfile/internals_linux_test.go
+++ b/builder/dockerfile/internals_linux_test.go
@@ -7,7 +7,7 @@ import (
 	"testing"
 
 	"github.com/docker/docker/api/types"
-	"github.com/moby/sys/user"
+	"github.com/docker/docker/pkg/idtools"
 	"gotest.tools/v3/assert"
 	is "gotest.tools/v3/assert/cmp"
 )
@@ -28,15 +28,15 @@ othergrp:x:6666:
 		`,
 	}
 	// test mappings for validating use of maps
-	idMaps := []user.IDMap{
+	idMaps := []idtools.IDMap{
 		{
-			ID:       0,
-			ParentID: 100000,
-			Count:    65536,
+			ContainerID: 0,
+			HostID:      100000,
+			Size:        65536,
 		},
 	}
-	remapped := user.IdentityMapping{UIDMaps: idMaps, GIDMaps: idMaps}
-	unmapped := user.IdentityMapping{}
+	remapped := idtools.IdentityMapping{UIDMaps: idMaps, GIDMaps: idMaps}
+	unmapped := idtools.IdentityMapping{}
 
 	contextDir, cleanup := createTestTempDir(t, "", "builder-chown-parse-test")
 	defer cleanup()
@@ -54,9 +54,9 @@ othergrp:x:6666:
 		builder   *Builder
 		name      string
 		chownStr  string
-		idMapping user.IdentityMapping
+		idMapping idtools.IdentityMapping
 		state     *dispatchState
-		expected  identity
+		expected  idtools.Identity
 	}{
 		{
 			builder:   &Builder{options: &types.ImageBuildOptions{Platform: "linux"}},
@@ -64,7 +64,7 @@ othergrp:x:6666:
 			chownStr:  "1",
 			idMapping: unmapped,
 			state:     &dispatchState{},
-			expected:  identity{UID: 1, GID: 1},
+			expected:  idtools.Identity{UID: 1, GID: 1},
 		},
 		{
 			builder:   &Builder{options: &types.ImageBuildOptions{Platform: "linux"}},
@@ -72,7 +72,7 @@ othergrp:x:6666:
 			chownStr:  "0:1",
 			idMapping: unmapped,
 			state:     &dispatchState{},
-			expected:  identity{UID: 0, GID: 1},
+			expected:  idtools.Identity{UID: 0, GID: 1},
 		},
 		{
 			builder:   &Builder{options: &types.ImageBuildOptions{Platform: "linux"}},
@@ -80,7 +80,7 @@ othergrp:x:6666:
 			chownStr:  "0",
 			idMapping: remapped,
 			state:     &dispatchState{},
-			expected:  identity{UID: 100000, GID: 100000},
+			expected:  idtools.Identity{UID: 100000, GID: 100000},
 		},
 		{
 			builder:   &Builder{options: &types.ImageBuildOptions{Platform: "linux"}},
@@ -88,7 +88,7 @@ othergrp:x:6666:
 			chownStr:  "1:33",
 			idMapping: remapped,
 			state:     &dispatchState{},
-			expected:  identity{UID: 100001, GID: 100033},
+			expected:  idtools.Identity{UID: 100001, GID: 100033},
 		},
 		{
 			builder:   &Builder{options: &types.ImageBuildOptions{Platform: "linux"}},
@@ -96,7 +96,7 @@ othergrp:x:6666:
 			chownStr:  "bin:5555",
 			idMapping: unmapped,
 			state:     &dispatchState{},
-			expected:  identity{UID: 1, GID: 5555},
+			expected:  idtools.Identity{UID: 1, GID: 5555},
 		},
 		{
 			builder:   &Builder{options: &types.ImageBuildOptions{Platform: "linux"}},
@@ -104,7 +104,7 @@ othergrp:x:6666:
 			chownStr:  "0:unicorn",
 			idMapping: remapped,
 			state:     &dispatchState{},
-			expected:  identity{UID: 100000, GID: 101002},
+			expected:  idtools.Identity{UID: 100000, GID: 101002},
 		},
 		{
 			builder:   &Builder{options: &types.ImageBuildOptions{Platform: "linux"}},
@@ -112,7 +112,7 @@ othergrp:x:6666:
 			chownStr:  "unicorn",
 			idMapping: remapped,
 			state:     &dispatchState{},
-			expected:  identity{UID: 101001, GID: 101002},
+			expected:  idtools.Identity{UID: 101001, GID: 101002},
 		},
 	} {
 		t.Run(testcase.name, func(t *testing.T) {
@@ -127,7 +127,7 @@ othergrp:x:6666:
 		builder   *Builder
 		name      string
 		chownStr  string
-		idMapping user.IdentityMapping
+		idMapping idtools.IdentityMapping
 		state     *dispatchState
 		descr     string
 	}{
diff --git a/builder/dockerfile/internals_test.go b/builder/dockerfile/internals_test.go
index aa6eafcb25..b46b112b4d 100644
--- a/builder/dockerfile/internals_test.go
+++ b/builder/dockerfile/internals_test.go
@@ -14,8 +14,8 @@ import (
 	"github.com/docker/docker/builder/remotecontext"
 	"github.com/docker/docker/image"
 	"github.com/docker/docker/layer"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/docker/go-connections/nat"
-	"github.com/moby/go-archive"
 	"github.com/opencontainers/go-digest"
 	"gotest.tools/v3/assert"
 	is "gotest.tools/v3/assert/cmp"
diff --git a/builder/dockerfile/internals_windows.go b/builder/dockerfile/internals_windows.go
index 0ef9315947..def324b35c 100644
--- a/builder/dockerfile/internals_windows.go
+++ b/builder/dockerfile/internals_windows.go
@@ -12,28 +12,27 @@ import (
 	"github.com/docker/docker/api/types/mount"
 	"github.com/docker/docker/errdefs"
 	"github.com/docker/docker/internal/usergroup"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/docker/docker/pkg/jsonmessage"
-	"github.com/moby/sys/user"
 	"golang.org/x/sys/windows"
 )
 
-func parseChownFlag(ctx context.Context, builder *Builder, state *dispatchState, chown, ctrRootPath string, identityMapping user.IdentityMapping) (identity, error) {
+func parseChownFlag(ctx context.Context, builder *Builder, state *dispatchState, chown, ctrRootPath string, identityMapping idtools.IdentityMapping) (idtools.Identity, error) {
 	if builder.options.Platform == "windows" {
 		return getAccountIdentity(ctx, builder, chown, ctrRootPath, state)
 	}
 
-	uid, gid := identityMapping.RootPair()
-	return identity{UID: uid, GID: gid}, nil
+	return identityMapping.RootPair(), nil
 }
 
-func getAccountIdentity(ctx context.Context, builder *Builder, accountName string, ctrRootPath string, state *dispatchState) (identity, error) {
+func getAccountIdentity(ctx context.Context, builder *Builder, accountName string, ctrRootPath string, state *dispatchState) (idtools.Identity, error) {
 	// If this is potentially a string SID then attempt to convert it to verify
 	// this, otherwise continue looking for the account.
 	if strings.HasPrefix(accountName, "S-") || strings.HasPrefix(accountName, "s-") {
 		sid, err := windows.StringToSid(accountName)
 
 		if err == nil {
-			return identity{SID: sid.String()}, nil
+			return idtools.Identity{SID: sid.String()}, nil
 		}
 	}
 
@@ -42,14 +41,14 @@ func getAccountIdentity(ctx context.Context, builder *Builder, accountName strin
 
 	// If this is a SID that is built-in and hence the same across all systems then use that.
 	if err == nil && (accType == windows.SidTypeAlias || accType == windows.SidTypeWellKnownGroup) {
-		return identity{SID: sid.String()}, nil
+		return idtools.Identity{SID: sid.String()}, nil
 	}
 
 	// Check if the account name is one unique to containers.
 	if strings.EqualFold(accountName, "ContainerAdministrator") {
-		return identity{SID: usergroup.ContainerAdministratorSidString}, nil
+		return idtools.Identity{SID: usergroup.ContainerAdministratorSidString}, nil
 	} else if strings.EqualFold(accountName, "ContainerUser") {
-		return identity{SID: usergroup.ContainerUserSidString}, nil
+		return idtools.Identity{SID: usergroup.ContainerUserSidString}, nil
 	}
 
 	// All other lookups failed, so therefore determine if the account in
@@ -57,7 +56,7 @@ func getAccountIdentity(ctx context.Context, builder *Builder, accountName strin
 	return lookupNTAccount(ctx, builder, accountName, state)
 }
 
-func lookupNTAccount(ctx context.Context, builder *Builder, accountName string, state *dispatchState) (identity, error) {
+func lookupNTAccount(ctx context.Context, builder *Builder, accountName string, state *dispatchState) (idtools.Identity, error) {
 	source, _ := filepath.Split(os.Args[0])
 
 	target := "C:\\Docker"
@@ -65,7 +64,7 @@ func lookupNTAccount(ctx context.Context, builder *Builder, accountName string,
 
 	optionsPlatform, err := platforms.Parse(builder.options.Platform)
 	if err != nil {
-		return identity{}, errdefs.InvalidParameter(err)
+		return idtools.Identity{}, errdefs.InvalidParameter(err)
 	}
 
 	runConfig := copyRunConfig(state.runConfig,
@@ -86,7 +85,7 @@ func lookupNTAccount(ctx context.Context, builder *Builder, accountName string,
 
 	container, err := builder.containerManager.Create(ctx, runConfig, hostConfig)
 	if err != nil {
-		return identity{}, err
+		return idtools.Identity{}, err
 	}
 
 	stdout := new(bytes.Buffer)
@@ -94,15 +93,15 @@ func lookupNTAccount(ctx context.Context, builder *Builder, accountName string,
 
 	if err := builder.containerManager.Run(ctx, container.ID, stdout, stderr); err != nil {
 		if err, ok := err.(*statusCodeError); ok {
-			return identity{}, &jsonmessage.JSONError{
+			return idtools.Identity{}, &jsonmessage.JSONError{
 				Message: stderr.String(),
 				Code:    err.StatusCode(),
 			}
 		}
-		return identity{}, err
+		return idtools.Identity{}, err
 	}
 
 	accountSid := stdout.String()
 
-	return identity{SID: accountSid}, nil
+	return idtools.Identity{SID: accountSid}, nil
 }
diff --git a/builder/remotecontext/archive.go b/builder/remotecontext/archive.go
index 715bed158d..fc476efb72 100644
--- a/builder/remotecontext/archive.go
+++ b/builder/remotecontext/archive.go
@@ -6,11 +6,11 @@ import (
 	"path/filepath"
 
 	"github.com/docker/docker/builder"
+	"github.com/docker/docker/pkg/archive"
+	"github.com/docker/docker/pkg/chrootarchive"
 	"github.com/docker/docker/pkg/longpath"
 	"github.com/docker/docker/pkg/system"
 	"github.com/docker/docker/pkg/tarsum"
-	"github.com/moby/go-archive"
-	"github.com/moby/go-archive/chrootarchive"
 	"github.com/moby/sys/symlink"
 	"github.com/pkg/errors"
 )
diff --git a/builder/remotecontext/filehash.go b/builder/remotecontext/filehash.go
index 75014ca425..3565dd8279 100644
--- a/builder/remotecontext/filehash.go
+++ b/builder/remotecontext/filehash.go
@@ -6,8 +6,8 @@ import (
 	"hash"
 	"os"
 
+	"github.com/docker/docker/pkg/archive"
 	"github.com/docker/docker/pkg/tarsum"
-	"github.com/moby/go-archive"
 )
 
 // NewFileHash returns new hash that is used for the builder cache keys
diff --git a/builder/remotecontext/git.go b/builder/remotecontext/git.go
index 9b24cd168a..b22416fb5b 100644
--- a/builder/remotecontext/git.go
+++ b/builder/remotecontext/git.go
@@ -7,7 +7,7 @@ import (
 	"github.com/containerd/log"
 	"github.com/docker/docker/builder"
 	"github.com/docker/docker/builder/remotecontext/git"
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 )
 
 // MakeGitContext returns a Context from gitURL that is cloned in a temporary directory.
diff --git a/builder/remotecontext/tarsum_test.go b/builder/remotecontext/tarsum_test.go
index 58ceab50d2..e564541a32 100644
--- a/builder/remotecontext/tarsum_test.go
+++ b/builder/remotecontext/tarsum_test.go
@@ -6,7 +6,7 @@ import (
 	"testing"
 
 	"github.com/docker/docker/builder"
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/moby/sys/reexec"
 	"github.com/pkg/errors"
 	"gotest.tools/v3/skip"
diff --git a/container/archive_windows.go b/container/archive_windows.go
index 5f9a71feb6..77552d21fb 100644
--- a/container/archive_windows.go
+++ b/container/archive_windows.go
@@ -5,7 +5,7 @@ import (
 	"path/filepath"
 
 	containertypes "github.com/docker/docker/api/types/container"
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/pkg/errors"
 )
 
diff --git a/daemon/archive_tarcopyoptions.go b/daemon/archive_tarcopyoptions.go
index 507d125dcf..42bd1ace2b 100644
--- a/daemon/archive_tarcopyoptions.go
+++ b/daemon/archive_tarcopyoptions.go
@@ -1,7 +1,8 @@
 package daemon // import "github.com/docker/docker/daemon"
 
 import (
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
+	"github.com/docker/docker/pkg/idtools"
 )
 
 // defaultTarCopyOptions is the setting that is used when unpacking an archive
@@ -9,6 +10,6 @@ import (
 func (daemon *Daemon) defaultTarCopyOptions(noOverwriteDirNonDir bool) *archive.TarOptions {
 	return &archive.TarOptions{
 		NoOverwriteDirNonDir: noOverwriteDirNonDir,
-		IDMap:                daemon.idMapping,
+		IDMap:                idtools.FromUserIdentityMapping(daemon.idMapping),
 	}
 }
diff --git a/daemon/archive_tarcopyoptions_unix.go b/daemon/archive_tarcopyoptions_unix.go
index d952543894..34ecc6e882 100644
--- a/daemon/archive_tarcopyoptions_unix.go
+++ b/daemon/archive_tarcopyoptions_unix.go
@@ -10,7 +10,8 @@ import (
 
 	"github.com/docker/docker/container"
 	"github.com/docker/docker/errdefs"
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/moby/sys/user"
 )
 
@@ -26,7 +27,7 @@ func (daemon *Daemon) tarCopyOptions(ctr *container.Container, noOverwriteDirNon
 
 	return &archive.TarOptions{
 		NoOverwriteDirNonDir: noOverwriteDirNonDir,
-		ChownOpts:            &archive.ChownOpts{UID: uid, GID: gid},
+		ChownOpts:            &idtools.Identity{UID: uid, GID: gid},
 	}, nil
 }
 
diff --git a/daemon/archive_unix.go b/daemon/archive_unix.go
index 8f7db9a3b0..a0ac2c68e9 100644
--- a/daemon/archive_unix.go
+++ b/daemon/archive_unix.go
@@ -12,9 +12,9 @@ import (
 	"github.com/docker/docker/api/types/events"
 	"github.com/docker/docker/container"
 	"github.com/docker/docker/errdefs"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/docker/docker/pkg/ioutils"
 	volumemounts "github.com/docker/docker/volume/mounts"
-	"github.com/moby/go-archive"
 	"github.com/pkg/errors"
 )
 
diff --git a/daemon/archive_windows.go b/daemon/archive_windows.go
index 2e1ff5d5f5..225ef78526 100644
--- a/daemon/archive_windows.go
+++ b/daemon/archive_windows.go
@@ -10,9 +10,9 @@ import (
 	"github.com/docker/docker/api/types/events"
 	"github.com/docker/docker/container"
 	"github.com/docker/docker/errdefs"
+	"github.com/docker/docker/pkg/archive"
+	"github.com/docker/docker/pkg/chrootarchive"
 	"github.com/docker/docker/pkg/ioutils"
-	"github.com/moby/go-archive"
-	"github.com/moby/go-archive/chrootarchive"
 )
 
 // containerStatPath stats the filesystem resource at the specified path in this
diff --git a/daemon/changes.go b/daemon/changes.go
index 731d9f4cce..a83f2c1902 100644
--- a/daemon/changes.go
+++ b/daemon/changes.go
@@ -6,7 +6,7 @@ import (
 	"time"
 
 	"github.com/docker/docker/internal/metrics"
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 )
 
 // ContainerChanges returns a list of container fs changes
diff --git a/daemon/container_operations_unix.go b/daemon/container_operations_unix.go
index 4316cc4a11..dd8351dd57 100644
--- a/daemon/container_operations_unix.go
+++ b/daemon/container_operations_unix.go
@@ -19,6 +19,7 @@ import (
 	"github.com/docker/docker/errdefs"
 	"github.com/docker/docker/libnetwork"
 	"github.com/docker/docker/libnetwork/drivers/bridge"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/docker/docker/pkg/process"
 	"github.com/docker/docker/pkg/stringid"
 	"github.com/moby/sys/mount"
@@ -577,6 +578,5 @@ func (daemon *Daemon) setupContainerMountsRoot(ctr *container.Container) error {
 	if err != nil {
 		return err
 	}
-	_, gid := daemon.IdentityMapping().RootPair()
-	return user.MkdirAllAndChown(p, 0o710, os.Getuid(), gid)
+	return idtools.MkdirAllAndChown(p, 0o710, idtools.Identity{UID: idtools.CurrentIdentity().UID, GID: daemon.IdentityMapping().RootPair().GID})
 }
diff --git a/daemon/containerd/image_builder.go b/daemon/containerd/image_builder.go
index 62c3630739..c11695fe44 100644
--- a/daemon/containerd/image_builder.go
+++ b/daemon/containerd/image_builder.go
@@ -30,11 +30,11 @@ import (
 	"github.com/docker/docker/image"
 	dimage "github.com/docker/docker/image"
 	"github.com/docker/docker/layer"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/docker/docker/pkg/progress"
 	"github.com/docker/docker/pkg/streamformatter"
 	"github.com/docker/docker/pkg/stringid"
 	imagespec "github.com/moby/docker-image-spec/specs-go/v1"
-	"github.com/moby/go-archive"
 	"github.com/opencontainers/go-digest"
 	"github.com/opencontainers/image-spec/identity"
 	"github.com/opencontainers/image-spec/specs-go"
diff --git a/daemon/containerd/image_changes.go b/daemon/containerd/image_changes.go
index ea147ce123..5c68402af0 100644
--- a/daemon/containerd/image_changes.go
+++ b/daemon/containerd/image_changes.go
@@ -7,8 +7,8 @@ import (
 	"github.com/containerd/containerd/v2/core/mount"
 	"github.com/containerd/log"
 	"github.com/docker/docker/container"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/docker/docker/pkg/stringid"
-	"github.com/moby/go-archive"
 )
 
 func (i *ImageService) Changes(ctx context.Context, ctr *container.Container) ([]archive.Change, error) {
diff --git a/daemon/containerd/image_commit.go b/daemon/containerd/image_commit.go
index 6c76c6e5f7..37c6da7928 100644
--- a/daemon/containerd/image_commit.go
+++ b/daemon/containerd/image_commit.go
@@ -18,8 +18,8 @@ import (
 	"github.com/containerd/log"
 	"github.com/docker/docker/api/types/backend"
 	"github.com/docker/docker/image"
+	"github.com/docker/docker/pkg/archive"
 	imagespec "github.com/moby/docker-image-spec/specs-go/v1"
-	"github.com/moby/go-archive"
 	"github.com/opencontainers/go-digest"
 	"github.com/opencontainers/image-spec/identity"
 	ocispec "github.com/opencontainers/image-spec/specs-go/v1"
@@ -152,8 +152,8 @@ func (i *ImageService) createDiff(ctx context.Context, name string, sn snapshots
 	if !i.idMapping.Empty() {
 		// The rootfs of the container is remapped if an id mapping exists, we
 		// need to "unremap" it before committing the snapshot
-		uid, gid := i.idMapping.RootPair()
-		usernsID := fmt.Sprintf("%s-%d-%d-%s", name, uid, gid, uniquePart())
+		rootPair := i.idMapping.RootPair()
+		usernsID := fmt.Sprintf("%s-%d-%d-%s", name, rootPair.UID, rootPair.GID, uniquePart())
 		remappedID := usernsID + remapSuffix
 		baseName := name
 
diff --git a/daemon/containerd/image_exporter.go b/daemon/containerd/image_exporter.go
index 7f0a5ec7d5..49d1c62f06 100644
--- a/daemon/containerd/image_exporter.go
+++ b/daemon/containerd/image_exporter.go
@@ -18,8 +18,8 @@ import (
 	"github.com/docker/docker/api/types/events"
 	"github.com/docker/docker/daemon/images"
 	"github.com/docker/docker/errdefs"
+	dockerarchive "github.com/docker/docker/pkg/archive"
 	"github.com/docker/docker/pkg/streamformatter"
-	dockerarchive "github.com/moby/go-archive"
 	ocispec "github.com/opencontainers/image-spec/specs-go/v1"
 	"github.com/pkg/errors"
 )
diff --git a/daemon/containerd/image_import.go b/daemon/containerd/image_import.go
index 113af36faf..c78bafa7bc 100644
--- a/daemon/containerd/image_import.go
+++ b/daemon/containerd/image_import.go
@@ -20,10 +20,10 @@ import (
 	"github.com/docker/docker/builder/dockerfile"
 	"github.com/docker/docker/errdefs"
 	"github.com/docker/docker/image"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/docker/docker/pkg/pools"
 	"github.com/google/uuid"
 	imagespec "github.com/moby/docker-image-spec/specs-go/v1"
-	"github.com/moby/go-archive"
 	"github.com/opencontainers/go-digest"
 	"github.com/opencontainers/image-spec/specs-go"
 	ocispec "github.com/opencontainers/image-spec/specs-go/v1"
diff --git a/daemon/containerd/image_load_test.go b/daemon/containerd/image_load_test.go
index b36d36e532..4b4629dece 100644
--- a/daemon/containerd/image_load_test.go
+++ b/daemon/containerd/image_load_test.go
@@ -14,7 +14,7 @@ import (
 	"github.com/containerd/platforms"
 	"github.com/docker/docker/errdefs"
 	"github.com/docker/docker/internal/testutils/specialimage"
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 	ocispec "github.com/opencontainers/image-spec/specs-go/v1"
 	"gotest.tools/v3/assert"
 	is "gotest.tools/v3/assert/cmp"
diff --git a/daemon/containerd/image_snapshot_unix.go b/daemon/containerd/image_snapshot_unix.go
index 5188a65e51..74985f1d1c 100644
--- a/daemon/containerd/image_snapshot_unix.go
+++ b/daemon/containerd/image_snapshot_unix.go
@@ -13,6 +13,7 @@ import (
 	"github.com/containerd/containerd/v2/core/snapshots"
 	"github.com/containerd/continuity/fs"
 	"github.com/containerd/continuity/sysx"
+	"github.com/docker/docker/pkg/idtools"
 )
 
 const (
@@ -53,12 +54,12 @@ func (i *ImageService) remapRootFS(ctx context.Context, mounts []mount.Mount) er
 				return fmt.Errorf("cannot get underlying data for %s", path)
 			}
 
-			uid, gid, err := i.idMapping.ToHost(int(stat.Uid), int(stat.Gid))
+			ids, err := i.idMapping.ToHost(idtools.Identity{UID: int(stat.Uid), GID: int(stat.Gid)})
 			if err != nil {
 				return err
 			}
 
-			return chownWithCaps(path, uid, gid)
+			return chownWithCaps(path, ids.UID, ids.GID)
 		})
 	})
 }
@@ -81,7 +82,7 @@ func (i *ImageService) copyAndUnremapRootFS(ctx context.Context, dst, src []moun
 					return fmt.Errorf("cannot get underlying data for %s", path)
 				}
 
-				uid, gid, err := i.idMapping.ToContainer(int(stat.Uid), int(stat.Gid))
+				uid, gid, err := i.idMapping.ToContainer(idtools.Identity{UID: int(stat.Uid), GID: int(stat.Gid)})
 				if err != nil {
 					return err
 				}
@@ -104,7 +105,7 @@ func (i *ImageService) unremapRootFS(ctx context.Context, mounts []mount.Mount)
 				return fmt.Errorf("cannot get underlying data for %s", path)
 			}
 
-			uid, gid, err := i.idMapping.ToContainer(int(stat.Uid), int(stat.Gid))
+			uid, gid, err := i.idMapping.ToContainer(idtools.Identity{UID: int(stat.Uid), GID: int(stat.Gid)})
 			if err != nil {
 				return err
 			}
diff --git a/daemon/containerd/service.go b/daemon/containerd/service.go
index 7dc1b02db3..2f6419f2de 100644
--- a/daemon/containerd/service.go
+++ b/daemon/containerd/service.go
@@ -20,7 +20,7 @@ import (
 	"github.com/docker/docker/daemon/snapshotter"
 	"github.com/docker/docker/distribution"
 	"github.com/docker/docker/errdefs"
-	"github.com/moby/sys/user"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/pkg/errors"
 )
 
@@ -37,7 +37,7 @@ type ImageService struct {
 	eventsService       *daemonevents.Events
 	pruneRunning        atomic.Bool
 	refCountMounter     snapshotter.Mounter
-	idMapping           user.IdentityMapping
+	idMapping           idtools.IdentityMapping
 
 	// defaultPlatformOverride is used in tests to override the host platform.
 	defaultPlatformOverride platforms.MatchComparer
@@ -51,7 +51,7 @@ type ImageServiceConfig struct {
 	Registry        distribution.RegistryResolver
 	EventsService   *daemonevents.Events
 	RefCountMounter snapshotter.Mounter
-	IDMapping       user.IdentityMapping
+	IDMapping       idtools.IdentityMapping
 }
 
 // NewService creates a new ImageService.
diff --git a/daemon/create.go b/daemon/create.go
index 3ea5c1decc..ba001204f1 100644
--- a/daemon/create.go
+++ b/daemon/create.go
@@ -3,7 +3,6 @@ package daemon // import "github.com/docker/docker/daemon"
 import (
 	"context"
 	"fmt"
-	"os"
 	"strings"
 	"time"
 
@@ -20,8 +19,8 @@ import (
 	"github.com/docker/docker/image"
 	"github.com/docker/docker/internal/metrics"
 	"github.com/docker/docker/internal/multierror"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/docker/docker/runconfig"
-	"github.com/moby/sys/user"
 	ocispec "github.com/opencontainers/image-spec/specs-go/v1"
 	"github.com/opencontainers/selinux/go-selinux"
 	"github.com/tonistiigi/go-archvariant"
@@ -193,12 +192,11 @@ func (daemon *Daemon) create(ctx context.Context, daemonCfg *config.Config, opts
 	}
 	ctr.RWLayer = rwLayer
 
-	cuid := os.Getuid()
-	_, gid := daemon.IdentityMapping().RootPair()
-	if err := user.MkdirAndChown(ctr.Root, 0o710, cuid, gid); err != nil {
+	current := idtools.CurrentIdentity()
+	if err := idtools.MkdirAndChown(ctr.Root, 0o710, idtools.Identity{UID: current.UID, GID: daemon.IdentityMapping().RootPair().GID}); err != nil {
 		return nil, err
 	}
-	if err := user.MkdirAndChown(ctr.CheckpointDir(), 0o700, cuid, os.Getegid()); err != nil {
+	if err := idtools.MkdirAndChown(ctr.CheckpointDir(), 0o700, current); err != nil {
 		return nil, err
 	}
 
diff --git a/daemon/daemon.go b/daemon/daemon.go
index 39285e5750..50bb480d3b 100644
--- a/daemon/daemon.go
+++ b/daemon/daemon.go
@@ -1072,15 +1072,15 @@ func NewDaemon(ctx context.Context, config *config.Config, pluginStore *plugin.S
 			RegistryHosts:   d.RegistryHosts,
 			Registry:        d.registryService,
 			EventsService:   d.EventsService,
-			IDMapping:       idMapping,
-			RefCountMounter: snapshotter.NewMounter(config.Root, driverName, idMapping),
+			IDMapping:       idtools.FromUserIdentityMapping(idMapping),
+			RefCountMounter: snapshotter.NewMounter(config.Root, driverName, idtools.FromUserIdentityMapping(idMapping)),
 		})
 	} else {
 		layerStore, err := layer.NewStoreFromOptions(layer.StoreOptions{
 			Root:               cfgStore.Root,
 			GraphDriver:        driverName,
 			GraphDriverOptions: cfgStore.GraphOptions,
-			IDMapping:          idMapping,
+			IDMapping:          idtools.FromUserIdentityMapping(idMapping),
 		})
 		if err != nil {
 			return nil, err
@@ -1599,8 +1599,8 @@ func (daemon *Daemon) GetAttachmentStore() *network.AttachmentStore {
 }
 
 // IdentityMapping returns uid/gid mapping or a SID (in the case of Windows) for the builder
-func (daemon *Daemon) IdentityMapping() user.IdentityMapping {
-	return daemon.idMapping
+func (daemon *Daemon) IdentityMapping() idtools.IdentityMapping {
+	return idtools.FromUserIdentityMapping(daemon.idMapping)
 }
 
 // ImageService returns the Daemon's ImageService
diff --git a/daemon/export.go b/daemon/export.go
index 15159fd977..b3aaca8477 100644
--- a/daemon/export.go
+++ b/daemon/export.go
@@ -9,8 +9,9 @@ import (
 	"github.com/docker/docker/api/types/events"
 	"github.com/docker/docker/container"
 	"github.com/docker/docker/errdefs"
-	"github.com/moby/go-archive"
-	"github.com/moby/go-archive/chrootarchive"
+	"github.com/docker/docker/pkg/archive"
+	"github.com/docker/docker/pkg/chrootarchive"
+	"github.com/docker/docker/pkg/idtools"
 )
 
 // ContainerExport writes the contents of the container to the given
@@ -65,7 +66,7 @@ func (daemon *Daemon) containerExport(ctx context.Context, ctr *container.Contai
 
 	archv, err := chrootarchive.Tar(basefs, &archive.TarOptions{
 		Compression: archive.Uncompressed,
-		IDMap:       daemon.idMapping,
+		IDMap:       idtools.FromUserIdentityMapping(daemon.idMapping),
 	}, basefs)
 	if err != nil {
 		return err
diff --git a/daemon/graphdriver/btrfs/btrfs.go b/daemon/graphdriver/btrfs/btrfs.go
index 6f8ec97031..423430cf72 100644
--- a/daemon/graphdriver/btrfs/btrfs.go
+++ b/daemon/graphdriver/btrfs/btrfs.go
@@ -38,9 +38,9 @@ import (
 	"github.com/docker/docker/daemon/graphdriver"
 	"github.com/docker/docker/daemon/internal/fstype"
 	"github.com/docker/docker/internal/containerfs"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/docker/go-units"
 	"github.com/moby/sys/mount"
-	"github.com/moby/sys/user"
 	"github.com/moby/sys/userns"
 	"github.com/opencontainers/selinux/go-selinux/label"
 	"github.com/pkg/errors"
@@ -58,7 +58,7 @@ type btrfsOptions struct {
 
 // Init returns a new BTRFS driver.
 // An error is returned if BTRFS is not supported.
-func Init(home string, options []string, idMap user.IdentityMapping) (graphdriver.Driver, error) {
+func Init(home string, options []string, idMap idtools.IdentityMapping) (graphdriver.Driver, error) {
 	// Perform feature detection on /var/lib/docker/btrfs if it's an existing directory.
 	// This covers situations where /var/lib/docker/btrfs is a mount, and on a different
 	// filesystem than /var/lib/docker.
@@ -77,8 +77,13 @@ func Init(home string, options []string, idMap user.IdentityMapping) (graphdrive
 		return nil, graphdriver.ErrPrerequisites
 	}
 
-	_, gid := idMap.RootPair()
-	if err := user.MkdirAllAndChown(home, 0o710, os.Getuid(), gid); err != nil {
+	currentID := idtools.CurrentIdentity()
+	dirID := idtools.Identity{
+		UID: currentID.UID,
+		GID: idMap.RootPair().GID,
+	}
+
+	if err := idtools.MkdirAllAndChown(home, 0o710, dirID); err != nil {
 		return nil, err
 	}
 
@@ -139,7 +144,7 @@ func parseOptions(opt []string) (btrfsOptions, bool, error) {
 type Driver struct {
 	// root of the file system
 	home         string
-	idMap        user.IdentityMapping
+	idMap        idtools.IdentityMapping
 	options      btrfsOptions
 	quotaEnabled bool
 	once         sync.Once
@@ -482,9 +487,15 @@ func (d *Driver) CreateReadWrite(id, parent string, opts *graphdriver.CreateOpts
 func (d *Driver) Create(id, parent string, opts *graphdriver.CreateOpts) error {
 	quotas := path.Join(d.home, "quotas")
 	subvolumes := path.Join(d.home, "subvolumes")
+	root := d.idMap.RootPair()
+
+	currentID := idtools.CurrentIdentity()
+	dirID := idtools.Identity{
+		UID: currentID.UID,
+		GID: root.GID,
+	}
 
-	uid, gid := d.idMap.RootPair()
-	if err := user.MkdirAllAndChown(subvolumes, 0o710, os.Getuid(), gid); err != nil {
+	if err := idtools.MkdirAllAndChown(subvolumes, 0o710, dirID); err != nil {
 		return err
 	}
 	if parent == "" {
@@ -519,7 +530,7 @@ func (d *Driver) Create(id, parent string, opts *graphdriver.CreateOpts) error {
 		if err := d.setStorageSize(path.Join(subvolumes, id), driver); err != nil {
 			return err
 		}
-		if err := user.MkdirAllAndChown(quotas, 0o700, os.Getuid(), os.Getegid()); err != nil {
+		if err := idtools.MkdirAllAndChown(quotas, 0o700, idtools.CurrentIdentity()); err != nil {
 			return err
 		}
 		if err := os.WriteFile(path.Join(quotas, id), []byte(fmt.Sprint(driver.options.size)), 0o644); err != nil {
@@ -529,8 +540,8 @@ func (d *Driver) Create(id, parent string, opts *graphdriver.CreateOpts) error {
 
 	// if we have a remapped root (user namespaces enabled), change the created snapshot
 	// dir ownership to match
-	if uid != 0 || gid != 0 {
-		if err := os.Chown(path.Join(subvolumes, id), uid, gid); err != nil {
+	if root.UID != 0 || root.GID != 0 {
+		if err := root.Chown(path.Join(subvolumes, id)); err != nil {
 			return err
 		}
 	}
diff --git a/daemon/graphdriver/driver.go b/daemon/graphdriver/driver.go
index 2c994eb3de..7fc56af980 100644
--- a/daemon/graphdriver/driver.go
+++ b/daemon/graphdriver/driver.go
@@ -9,8 +9,8 @@ import (
 	"strings"
 
 	"github.com/containerd/log"
-	"github.com/moby/go-archive"
-	"github.com/moby/sys/user"
+	"github.com/docker/docker/pkg/archive"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/pkg/errors"
 	"github.com/vbatts/tar-split/tar/storage"
 )
@@ -26,7 +26,7 @@ type CreateOpts struct {
 }
 
 // InitFunc initializes the storage driver.
-type InitFunc func(root string, options []string, idMap user.IdentityMapping) (Driver, error)
+type InitFunc func(root string, options []string, idMap idtools.IdentityMapping) (Driver, error)
 
 // ProtoDriver defines the basic capabilities of a driver.
 // This interface exists solely to be a minimum set of methods
@@ -151,7 +151,7 @@ func getDriver(name string, config Options) (Driver, error) {
 type Options struct {
 	Root                string
 	DriverOptions       []string
-	IDMap               user.IdentityMapping
+	IDMap               idtools.IdentityMapping
 	ExperimentalEnabled bool
 }
 
diff --git a/daemon/graphdriver/fsdiff.go b/daemon/graphdriver/fsdiff.go
index 1bfe91ffbe..39fc64071b 100644
--- a/daemon/graphdriver/fsdiff.go
+++ b/daemon/graphdriver/fsdiff.go
@@ -6,10 +6,10 @@ import (
 	"time"
 
 	"github.com/containerd/log"
+	"github.com/docker/docker/pkg/archive"
+	"github.com/docker/docker/pkg/chrootarchive"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/docker/docker/pkg/ioutils"
-	"github.com/moby/go-archive"
-	"github.com/moby/go-archive/chrootarchive"
-	"github.com/moby/sys/user"
 )
 
 // ApplyUncompressedLayer defines the unpack method used by the graph
@@ -22,7 +22,7 @@ var ApplyUncompressedLayer = chrootarchive.ApplyUncompressedLayer
 // on the exported NewNaiveDiffDriver function below.
 type NaiveDiffDriver struct {
 	ProtoDriver
-	IDMap user.IdentityMapping
+	IDMap idtools.IdentityMapping
 	// If true, allow ApplyDiff to succeed in spite of failures to set
 	// extended attributes on the unpacked files due to the destination
 	// filesystem not supporting them or a lack of permissions. The
@@ -38,7 +38,7 @@ type NaiveDiffDriver struct {
 //	Changes(id, parent string) ([]archive.Change, error)
 //	ApplyDiff(id, parent string, diff archive.Reader) (size int64, err error)
 //	DiffSize(id, parent string) (size int64, err error)
-func NewNaiveDiffDriver(driver ProtoDriver, idMap user.IdentityMapping) Driver {
+func NewNaiveDiffDriver(driver ProtoDriver, idMap idtools.IdentityMapping) Driver {
 	return &NaiveDiffDriver{
 		ProtoDriver: driver,
 		IDMap:       idMap,
diff --git a/daemon/graphdriver/fuse-overlayfs/fuseoverlayfs.go b/daemon/graphdriver/fuse-overlayfs/fuseoverlayfs.go
index 13596d64f9..d72d65395f 100644
--- a/daemon/graphdriver/fuse-overlayfs/fuseoverlayfs.go
+++ b/daemon/graphdriver/fuse-overlayfs/fuseoverlayfs.go
@@ -20,12 +20,12 @@ import (
 	"github.com/docker/docker/daemon/internal/mountref"
 	"github.com/docker/docker/internal/containerfs"
 	"github.com/docker/docker/internal/directory"
+	"github.com/docker/docker/pkg/archive"
+	"github.com/docker/docker/pkg/chrootarchive"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/docker/docker/pkg/parsers/kernel"
-	"github.com/moby/go-archive"
-	"github.com/moby/go-archive/chrootarchive"
 	"github.com/moby/locker"
 	"github.com/moby/sys/mount"
-	"github.com/moby/sys/user"
 	"github.com/moby/sys/userns"
 	"github.com/opencontainers/selinux/go-selinux/label"
 	"github.com/pkg/errors"
@@ -59,7 +59,7 @@ const (
 // mounts that are created using this driver.
 type Driver struct {
 	home      string
-	idMap     user.IdentityMapping
+	idMap     idtools.IdentityMapping
 	ctr       *mountref.Counter
 	naiveDiff graphdriver.DiffDriver
 	locker    *locker.Locker
@@ -74,7 +74,7 @@ func init() {
 // Init returns the naive diff driver for fuse-overlayfs.
 // If fuse-overlayfs is not supported on the host, the error
 // graphdriver.ErrNotSupported is returned.
-func Init(home string, options []string, idMap user.IdentityMapping) (graphdriver.Driver, error) {
+func Init(home string, options []string, idMap idtools.IdentityMapping) (graphdriver.Driver, error) {
 	if _, err := exec.LookPath(binary); err != nil {
 		logger.Error(err)
 		return nil, graphdriver.ErrNotSupported
@@ -83,12 +83,16 @@ func Init(home string, options []string, idMap user.IdentityMapping) (graphdrive
 		return nil, graphdriver.ErrNotSupported
 	}
 
-	cuid := os.Getuid()
-	_, gid := idMap.RootPair()
-	if err := user.MkdirAllAndChown(home, 0o710, cuid, gid); err != nil {
+	currentID := idtools.CurrentIdentity()
+	dirID := idtools.Identity{
+		UID: currentID.UID,
+		GID: idMap.RootPair().GID,
+	}
+
+	if err := idtools.MkdirAllAndChown(home, 0o710, dirID); err != nil {
 		return nil, err
 	}
-	if err := user.MkdirAllAndChown(path.Join(home, linkDir), 0o700, cuid, os.Getegid()); err != nil {
+	if err := idtools.MkdirAllAndChown(path.Join(home, linkDir), 0o700, currentID); err != nil {
 		return nil, err
 	}
 
@@ -171,12 +175,12 @@ func (d *Driver) Create(id, parent string, opts *graphdriver.CreateOpts) (retErr
 
 func (d *Driver) create(id, parent string, opts *graphdriver.CreateOpts) (retErr error) {
 	dir := d.dir(id)
-	uid, gid := d.idMap.RootPair()
+	root := d.idMap.RootPair()
 
-	if err := user.MkdirAllAndChown(path.Dir(dir), 0o710, uid, gid); err != nil {
+	if err := idtools.MkdirAllAndChown(path.Dir(dir), 0o710, root); err != nil {
 		return err
 	}
-	if err := user.MkdirAndChown(dir, 0o710, uid, gid); err != nil {
+	if err := idtools.MkdirAndChown(dir, 0o710, root); err != nil {
 		return err
 	}
 
@@ -191,7 +195,7 @@ func (d *Driver) create(id, parent string, opts *graphdriver.CreateOpts) (retErr
 		return fmt.Errorf("--storage-opt is not supported")
 	}
 
-	if err := user.MkdirAndChown(path.Join(dir, diffDirName), 0o755, uid, gid); err != nil {
+	if err := idtools.MkdirAndChown(path.Join(dir, diffDirName), 0o755, root); err != nil {
 		return err
 	}
 
@@ -210,7 +214,7 @@ func (d *Driver) create(id, parent string, opts *graphdriver.CreateOpts) (retErr
 		return nil
 	}
 
-	if err := user.MkdirAndChown(path.Join(dir, workDirName), 0o710, uid, gid); err != nil {
+	if err := idtools.MkdirAndChown(path.Join(dir, workDirName), 0o710, root); err != nil {
 		return err
 	}
 
@@ -363,8 +367,7 @@ func (d *Driver) Get(id, mountLabel string) (_ string, retErr error) {
 	mountData := label.FormatMountLabel(opts, mountLabel)
 	mountTarget := mergedDir
 
-	uid, gid := d.idMap.RootPair()
-	if err := user.MkdirAndChown(mergedDir, 0o700, uid, gid); err != nil {
+	if err := idtools.MkdirAndChown(mergedDir, 0o700, d.idMap.RootPair()); err != nil {
 		return "", err
 	}
 
diff --git a/daemon/graphdriver/fuse-overlayfs/fuseoverlayfs_test.go b/daemon/graphdriver/fuse-overlayfs/fuseoverlayfs_test.go
index 1cd9e53ae8..e70714bedd 100644
--- a/daemon/graphdriver/fuse-overlayfs/fuseoverlayfs_test.go
+++ b/daemon/graphdriver/fuse-overlayfs/fuseoverlayfs_test.go
@@ -7,7 +7,7 @@ import (
 
 	"github.com/docker/docker/daemon/graphdriver"
 	"github.com/docker/docker/daemon/graphdriver/graphtest"
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 )
 
 func init() {
diff --git a/daemon/graphdriver/graphtest/testutil.go b/daemon/graphdriver/graphtest/testutil.go
index 5631c34122..2cba5343ae 100644
--- a/daemon/graphdriver/graphtest/testutil.go
+++ b/daemon/graphdriver/graphtest/testutil.go
@@ -10,8 +10,8 @@ import (
 	"sort"
 
 	"github.com/docker/docker/daemon/graphdriver"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/docker/docker/pkg/stringid"
-	"github.com/moby/go-archive"
 )
 
 func randomContent(size int, seed int64) []byte {
diff --git a/daemon/graphdriver/overlay2/overlay.go b/daemon/graphdriver/overlay2/overlay.go
index 6c496cfdd9..c4b296b622 100644
--- a/daemon/graphdriver/overlay2/overlay.go
+++ b/daemon/graphdriver/overlay2/overlay.go
@@ -22,14 +22,14 @@ import (
 	"github.com/docker/docker/daemon/internal/mountref"
 	"github.com/docker/docker/internal/containerfs"
 	"github.com/docker/docker/internal/directory"
+	"github.com/docker/docker/pkg/archive"
+	"github.com/docker/docker/pkg/chrootarchive"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/docker/docker/quota"
 	"github.com/docker/go-units"
-	"github.com/moby/go-archive"
-	"github.com/moby/go-archive/chrootarchive"
 	"github.com/moby/locker"
 	"github.com/moby/sys/atomicwriter"
 	"github.com/moby/sys/mount"
-	"github.com/moby/sys/user"
 	"github.com/moby/sys/userns"
 	"github.com/opencontainers/selinux/go-selinux/label"
 	"golang.org/x/sys/unix"
@@ -92,7 +92,7 @@ type overlayOptions struct {
 // mounts that are created using this driver.
 type Driver struct {
 	home          string
-	idMap         user.IdentityMapping
+	idMap         idtools.IdentityMapping
 	ctr           *mountref.Counter
 	quotaCtl      *quota.Control
 	options       overlayOptions
@@ -123,7 +123,7 @@ func init() {
 // graphdriver.ErrNotSupported is returned.
 // If an overlay filesystem is not supported over an existing filesystem then
 // the error graphdriver.ErrIncompatibleFS is returned.
-func Init(home string, options []string, idMap user.IdentityMapping) (graphdriver.Driver, error) {
+func Init(home string, options []string, idMap idtools.IdentityMapping) (graphdriver.Driver, error) {
 	opts, err := parseOptions(options)
 	if err != nil {
 		return nil, err
@@ -164,12 +164,15 @@ func Init(home string, options []string, idMap user.IdentityMapping) (graphdrive
 		return nil, err
 	}
 
-	cuid := os.Getuid()
-	_, gid := idMap.RootPair()
-	if err := user.MkdirAllAndChown(home, 0o710, cuid, gid); err != nil {
+	cur := idtools.CurrentIdentity()
+	dirID := idtools.Identity{
+		UID: cur.UID,
+		GID: idMap.RootPair().GID,
+	}
+	if err := idtools.MkdirAllAndChown(home, 0o710, dirID); err != nil {
 		return nil, err
 	}
-	if err := user.MkdirAllAndChown(path.Join(home, linkDir), 0o700, cuid, os.Getegid()); err != nil {
+	if err := idtools.MkdirAllAndChown(path.Join(home, linkDir), 0o700, cur); err != nil {
 		return nil, err
 	}
 
@@ -345,12 +348,16 @@ func (d *Driver) Create(id, parent string, opts *graphdriver.CreateOpts) (retErr
 func (d *Driver) create(id, parent string, opts *graphdriver.CreateOpts) (retErr error) {
 	dir := d.dir(id)
 
-	cuid := os.Getuid()
-	uid, gid := d.idMap.RootPair()
-	if err := user.MkdirAllAndChown(path.Dir(dir), 0o710, cuid, gid); err != nil {
+	root := d.idMap.RootPair()
+	dirID := idtools.Identity{
+		UID: idtools.CurrentIdentity().UID,
+		GID: root.GID,
+	}
+
+	if err := idtools.MkdirAllAndChown(path.Dir(dir), 0o710, dirID); err != nil {
 		return err
 	}
-	if err := user.MkdirAndChown(dir, 0o710, cuid, gid); err != nil {
+	if err := idtools.MkdirAndChown(dir, 0o710, dirID); err != nil {
 		return err
 	}
 
@@ -375,7 +382,7 @@ func (d *Driver) create(id, parent string, opts *graphdriver.CreateOpts) (retErr
 		}
 	}
 
-	if err := user.MkdirAndChown(path.Join(dir, diffDirName), 0o755, uid, gid); err != nil {
+	if err := idtools.MkdirAndChown(path.Join(dir, diffDirName), 0o755, root); err != nil {
 		return err
 	}
 
@@ -394,7 +401,7 @@ func (d *Driver) create(id, parent string, opts *graphdriver.CreateOpts) (retErr
 		return nil
 	}
 
-	if err := user.MkdirAndChown(path.Join(dir, workDirName), 0o700, uid, gid); err != nil {
+	if err := idtools.MkdirAndChown(path.Join(dir, workDirName), 0o700, root); err != nil {
 		return err
 	}
 
@@ -566,8 +573,8 @@ func (d *Driver) Get(id, mountLabel string) (_ string, retErr error) {
 	mount := unix.Mount
 	mountTarget := mergedDir
 
-	uid, gid := d.idMap.RootPair()
-	if err := user.MkdirAndChown(mergedDir, 0o700, uid, gid); err != nil {
+	root := d.idMap.RootPair()
+	if err := idtools.MkdirAndChown(mergedDir, 0o700, root); err != nil {
 		return "", err
 	}
 
@@ -601,7 +608,7 @@ func (d *Driver) Get(id, mountLabel string) (_ string, retErr error) {
 	if !readonly {
 		// chown "workdir/work" to the remapped root UID/GID. Overlay fs inside a
 		// user namespace requires this to move a directory from lower to upper.
-		if err := os.Chown(path.Join(workDir, workDirName), uid, gid); err != nil {
+		if err := root.Chown(path.Join(workDir, workDirName)); err != nil {
 			return "", err
 		}
 	}
diff --git a/daemon/graphdriver/overlay2/overlay_test.go b/daemon/graphdriver/overlay2/overlay_test.go
index 7d5f9f5218..9655bb77a9 100644
--- a/daemon/graphdriver/overlay2/overlay_test.go
+++ b/daemon/graphdriver/overlay2/overlay_test.go
@@ -8,7 +8,7 @@ import (
 
 	"github.com/docker/docker/daemon/graphdriver"
 	"github.com/docker/docker/daemon/graphdriver/graphtest"
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 )
 
 func init() {
diff --git a/daemon/graphdriver/vfs/copy_unsupported.go b/daemon/graphdriver/vfs/copy_unsupported.go
index cca5289d53..60c6b0a2ff 100644
--- a/daemon/graphdriver/vfs/copy_unsupported.go
+++ b/daemon/graphdriver/vfs/copy_unsupported.go
@@ -3,10 +3,10 @@
 package vfs // import "github.com/docker/docker/daemon/graphdriver/vfs"
 
 import (
-	"github.com/moby/go-archive/chrootarchive"
-	"github.com/moby/sys/user"
+	"github.com/docker/docker/pkg/chrootarchive"
+	"github.com/docker/docker/pkg/idtools"
 )
 
 func dirCopy(srcDir, dstDir string) error {
-	return chrootarchive.NewArchiver(user.IdentityMapping{}).CopyWithTar(srcDir, dstDir)
+	return chrootarchive.NewArchiver(idtools.IdentityMapping{}).CopyWithTar(srcDir, dstDir)
 }
diff --git a/daemon/graphdriver/vfs/driver.go b/daemon/graphdriver/vfs/driver.go
index 22d7681b06..4a7118aa12 100644
--- a/daemon/graphdriver/vfs/driver.go
+++ b/daemon/graphdriver/vfs/driver.go
@@ -8,9 +8,9 @@ import (
 	"github.com/docker/docker/daemon/graphdriver"
 	"github.com/docker/docker/errdefs"
 	"github.com/docker/docker/internal/containerfs"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/docker/docker/quota"
 	"github.com/docker/go-units"
-	"github.com/moby/sys/user"
 	"github.com/opencontainers/selinux/go-selinux/label"
 	"github.com/pkg/errors"
 )
@@ -29,7 +29,7 @@ func init() {
 
 // Init returns a new VFS driver.
 // This sets the home directory for the driver and returns NaiveDiffDriver.
-func Init(home string, options []string, idMap user.IdentityMapping) (graphdriver.Driver, error) {
+func Init(home string, options []string, idMap idtools.IdentityMapping) (graphdriver.Driver, error) {
 	d := &Driver{
 		home:      home,
 		idMapping: idMap,
@@ -39,8 +39,11 @@ func Init(home string, options []string, idMap user.IdentityMapping) (graphdrive
 		return nil, err
 	}
 
-	_, gid := d.idMapping.RootPair()
-	if err := user.MkdirAllAndChown(home, 0o710, os.Getuid(), gid); err != nil {
+	dirID := idtools.Identity{
+		UID: idtools.CurrentIdentity().UID,
+		GID: d.idMapping.RootPair().GID,
+	}
+	if err := idtools.MkdirAllAndChown(home, 0o710, dirID); err != nil {
 		return nil, err
 	}
 
@@ -64,7 +67,7 @@ func Init(home string, options []string, idMap user.IdentityMapping) (graphdrive
 type Driver struct {
 	driverQuota
 	home             string
-	idMapping        user.IdentityMapping
+	idMapping        idtools.IdentityMapping
 	bestEffortXattrs bool
 }
 
@@ -158,12 +161,16 @@ func (d *Driver) Create(id, parent string, opts *graphdriver.CreateOpts) error {
 
 func (d *Driver) create(id, parent string, size uint64) error {
 	dir := d.dir(id)
-	uid, gid := d.idMapping.RootPair()
+	rootIDs := d.idMapping.RootPair()
 
-	if err := user.MkdirAllAndChown(filepath.Dir(dir), 0o710, os.Getuid(), gid); err != nil {
+	dirID := idtools.Identity{
+		UID: idtools.CurrentIdentity().UID,
+		GID: rootIDs.GID,
+	}
+	if err := idtools.MkdirAllAndChown(filepath.Dir(dir), 0o710, dirID); err != nil {
 		return err
 	}
-	if err := user.MkdirAndChown(dir, 0o755, uid, gid); err != nil {
+	if err := idtools.MkdirAndChown(dir, 0o755, rootIDs); err != nil {
 		return err
 	}
 
diff --git a/daemon/graphdriver/windows/windows.go b/daemon/graphdriver/windows/windows.go
index e4b2962d30..77947df197 100644
--- a/daemon/graphdriver/windows/windows.go
+++ b/daemon/graphdriver/windows/windows.go
@@ -27,12 +27,12 @@ import (
 	"github.com/containerd/log"
 	"github.com/docker/docker/daemon/graphdriver"
 	"github.com/docker/docker/daemon/internal/mountref"
+	"github.com/docker/docker/pkg/archive"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/docker/docker/pkg/ioutils"
 	"github.com/docker/docker/pkg/longpath"
 	"github.com/docker/go-units"
-	"github.com/moby/go-archive"
 	"github.com/moby/sys/reexec"
-	"github.com/moby/sys/user"
 	"github.com/pkg/errors"
 	"golang.org/x/sys/windows"
 )
@@ -89,7 +89,7 @@ type Driver struct {
 }
 
 // InitFilter returns a new Windows storage filter driver.
-func InitFilter(home string, options []string, _ user.IdentityMapping) (graphdriver.Driver, error) {
+func InitFilter(home string, options []string, _ idtools.IdentityMapping) (graphdriver.Driver, error) {
 	log.G(context.TODO()).Debugf("WindowsGraphDriver InitFilter at %s", home)
 
 	fsType, err := winiofs.GetFileSystemType(home)
diff --git a/daemon/graphdriver/zfs/zfs.go b/daemon/graphdriver/zfs/zfs.go
index 969606b61e..6bc2050da7 100644
--- a/daemon/graphdriver/zfs/zfs.go
+++ b/daemon/graphdriver/zfs/zfs.go
@@ -16,11 +16,11 @@ import (
 	"github.com/containerd/log"
 	"github.com/docker/docker/daemon/graphdriver"
 	"github.com/docker/docker/daemon/internal/mountref"
+	"github.com/docker/docker/pkg/idtools"
 	zfs "github.com/mistifyio/go-zfs/v3"
 	"github.com/moby/locker"
 	"github.com/moby/sys/mount"
 	"github.com/moby/sys/mountinfo"
-	"github.com/moby/sys/user"
 	"github.com/opencontainers/selinux/go-selinux/label"
 	"github.com/pkg/errors"
 	"golang.org/x/sys/unix"
@@ -46,7 +46,7 @@ func (*Logger) Log(cmd []string) {
 // Init returns a new ZFS driver.
 // It takes base mount path and an array of options which are represented as key value pairs.
 // Each option is in the for key=value. 'zfs.fsname' is expected to be a valid key in the options.
-func Init(base string, opt []string, idMap user.IdentityMapping) (graphdriver.Driver, error) {
+func Init(base string, opt []string, idMap idtools.IdentityMapping) (graphdriver.Driver, error) {
 	var err error
 
 	logger := log.G(context.TODO()).WithField("storage-driver", "zfs")
@@ -105,8 +105,11 @@ func Init(base string, opt []string, idMap user.IdentityMapping) (graphdriver.Dr
 		return nil, fmt.Errorf("BUG: zfs get all -t filesystem -rHp '%s' should contain '%s'", options.fsName, options.fsName)
 	}
 
-	_, gid := idMap.RootPair()
-	if err := user.MkdirAllAndChown(base, 0o710, os.Getuid(), gid); err != nil {
+	dirID := idtools.Identity{
+		UID: idtools.CurrentIdentity().UID,
+		GID: idMap.RootPair().GID,
+	}
+	if err := idtools.MkdirAllAndChown(base, 0o710, dirID); err != nil {
 		return nil, fmt.Errorf("Failed to create '%s': %v", base, err)
 	}
 
@@ -178,7 +181,7 @@ type Driver struct {
 	options          zfsOptions
 	sync.Mutex       // protects filesystem cache against concurrent access
 	filesystemsCache map[string]bool
-	idMap            user.IdentityMapping
+	idMap            idtools.IdentityMapping
 	ctr              *mountref.Counter
 	locker           *locker.Locker
 }
@@ -401,9 +404,9 @@ func (d *Driver) Get(id, mountLabel string) (_ string, retErr error) {
 	options := label.FormatMountLabel("", mountLabel)
 	log.G(context.TODO()).WithField("storage-driver", "zfs").Debugf(`mount("%s", "%s", "%s")`, filesystem, mountpoint, options)
 
-	uid, gid := d.idMap.RootPair()
+	root := d.idMap.RootPair()
 	// Create the target directories if they don't exist
-	if err := user.MkdirAllAndChown(mountpoint, 0o755, uid, gid); err != nil {
+	if err := idtools.MkdirAllAndChown(mountpoint, 0o755, root); err != nil {
 		return "", err
 	}
 
@@ -413,7 +416,7 @@ func (d *Driver) Get(id, mountLabel string) (_ string, retErr error) {
 
 	// this could be our first mount after creation of the filesystem, and the root dir may still have root
 	// permissions instead of the remapped root uid:gid (if user namespaces are enabled):
-	if err := os.Chown(mountpoint, uid, gid); err != nil {
+	if err := root.Chown(mountpoint); err != nil {
 		return "", fmt.Errorf("error modifying zfs mountpoint (%s) directory ownership: %v", mountpoint, err)
 	}
 
diff --git a/daemon/image_service.go b/daemon/image_service.go
index 8293d5e16f..a24ffe91a8 100644
--- a/daemon/image_service.go
+++ b/daemon/image_service.go
@@ -15,7 +15,7 @@ import (
 	"github.com/docker/docker/daemon/images"
 	"github.com/docker/docker/image"
 	"github.com/docker/docker/layer"
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/opencontainers/go-digest"
 	ocispec "github.com/opencontainers/image-spec/specs-go/v1"
 )
diff --git a/daemon/images/image_changes.go b/daemon/images/image_changes.go
index 2b4e9dc88c..92b1c11c5f 100644
--- a/daemon/images/image_changes.go
+++ b/daemon/images/image_changes.go
@@ -7,7 +7,7 @@ import (
 
 	"github.com/docker/docker/container"
 	"github.com/docker/docker/layer"
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 )
 
 func (i *ImageService) Changes(ctx context.Context, container *container.Container) ([]archive.Change, error) {
diff --git a/daemon/images/image_import.go b/daemon/images/image_import.go
index 8c656d7900..fc2000637e 100644
--- a/daemon/images/image_import.go
+++ b/daemon/images/image_import.go
@@ -15,7 +15,7 @@ import (
 	"github.com/docker/docker/errdefs"
 	"github.com/docker/docker/image"
 	"github.com/docker/docker/layer"
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 	ocispec "github.com/opencontainers/image-spec/specs-go/v1"
 )
 
diff --git a/daemon/snapshotter/mount.go b/daemon/snapshotter/mount.go
index cb005fba2e..8806d17d8e 100644
--- a/daemon/snapshotter/mount.go
+++ b/daemon/snapshotter/mount.go
@@ -8,9 +8,9 @@ import (
 	"github.com/containerd/containerd/v2/core/mount"
 	"github.com/containerd/log"
 	"github.com/docker/docker/daemon/internal/mountref"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/moby/locker"
 	"github.com/moby/sys/mountinfo"
-	"github.com/moby/sys/user"
 )
 
 // Mounter handles mounting/unmounting things coming in from a snapshotter
@@ -25,7 +25,7 @@ type Mounter interface {
 }
 
 // NewMounter creates a new mounter for the provided snapshotter
-func NewMounter(home string, snapshotter string, idMap user.IdentityMapping) *refCountMounter {
+func NewMounter(home string, snapshotter string, idMap idtools.IdentityMapping) *refCountMounter {
 	return &refCountMounter{
 		base: mounter{
 			home:        home,
@@ -113,17 +113,20 @@ func (m *refCountMounter) Mounted(containerID string) (string, error) {
 type mounter struct {
 	home        string
 	snapshotter string
-	idMap       user.IdentityMapping
+	idMap       idtools.IdentityMapping
 }
 
 func (m mounter) Mount(mounts []mount.Mount, containerID string) (string, error) {
 	target := m.target(containerID)
 
-	uid, gid := m.idMap.RootPair()
-	if err := user.MkdirAllAndChown(filepath.Dir(target), 0o710, os.Getuid(), gid); err != nil {
+	root := m.idMap.RootPair()
+	if err := idtools.MkdirAllAndChown(filepath.Dir(target), 0o710, idtools.Identity{
+		UID: idtools.CurrentIdentity().UID,
+		GID: root.GID,
+	}); err != nil {
 		return "", err
 	}
-	if err := user.MkdirAllAndChown(target, 0o710, uid, gid); err != nil {
+	if err := idtools.MkdirAllAndChown(target, 0o710, root); err != nil {
 		return "", err
 	}
 
diff --git a/distribution/xfer/download.go b/distribution/xfer/download.go
index 80eec9e82e..1f8d7c10a7 100644
--- a/distribution/xfer/download.go
+++ b/distribution/xfer/download.go
@@ -11,9 +11,9 @@ import (
 	"github.com/docker/distribution"
 	"github.com/docker/docker/image"
 	"github.com/docker/docker/layer"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/docker/docker/pkg/ioutils"
 	"github.com/docker/docker/pkg/progress"
-	"github.com/moby/go-archive"
 )
 
 const maxDownloadAttempts = 5
diff --git a/image/tarexport/load.go b/image/tarexport/load.go
index 73c7cec75b..b01bf40b5b 100644
--- a/image/tarexport/load.go
+++ b/image/tarexport/load.go
@@ -20,11 +20,11 @@ import (
 	v1 "github.com/docker/docker/image/v1"
 	"github.com/docker/docker/internal/ioutils"
 	"github.com/docker/docker/layer"
+	"github.com/docker/docker/pkg/archive"
+	"github.com/docker/docker/pkg/chrootarchive"
 	"github.com/docker/docker/pkg/progress"
 	"github.com/docker/docker/pkg/streamformatter"
 	"github.com/docker/docker/pkg/stringid"
-	"github.com/moby/go-archive"
-	"github.com/moby/go-archive/chrootarchive"
 	"github.com/moby/sys/sequential"
 	"github.com/moby/sys/symlink"
 	"github.com/opencontainers/go-digest"
diff --git a/image/tarexport/save.go b/image/tarexport/save.go
index cfbf795acb..3f25a49faf 100644
--- a/image/tarexport/save.go
+++ b/image/tarexport/save.go
@@ -21,8 +21,8 @@ import (
 	v1 "github.com/docker/docker/image/v1"
 	"github.com/docker/docker/internal/ioutils"
 	"github.com/docker/docker/layer"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/docker/docker/pkg/system"
-	"github.com/moby/go-archive"
 	"github.com/moby/sys/sequential"
 	"github.com/opencontainers/go-digest"
 	"github.com/opencontainers/image-spec/specs-go"
diff --git a/integration-cli/docker_cli_build_test.go b/integration-cli/docker_cli_build_test.go
index c97412a9e8..7aac687867 100644
--- a/integration-cli/docker_cli_build_test.go
+++ b/integration-cli/docker_cli_build_test.go
@@ -20,12 +20,12 @@ import (
 	"github.com/docker/docker/api/types/versions"
 	"github.com/docker/docker/integration-cli/cli"
 	"github.com/docker/docker/integration-cli/cli/build"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/docker/docker/testutil"
 	"github.com/docker/docker/testutil/fakecontext"
 	"github.com/docker/docker/testutil/fakegit"
 	"github.com/docker/docker/testutil/fakestorage"
 	"github.com/moby/buildkit/frontend/dockerfile/command"
-	"github.com/moby/go-archive"
 	"github.com/opencontainers/go-digest"
 	"gotest.tools/v3/assert"
 	is "gotest.tools/v3/assert/cmp"
diff --git a/integration-cli/docker_cli_cp_utils_test.go b/integration-cli/docker_cli_cp_utils_test.go
index 21988aa41d..39b4b86358 100644
--- a/integration-cli/docker_cli_cp_utils_test.go
+++ b/integration-cli/docker_cli_cp_utils_test.go
@@ -12,7 +12,7 @@ import (
 	"testing"
 
 	"github.com/docker/docker/integration-cli/cli"
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 	"gotest.tools/v3/assert"
 	is "gotest.tools/v3/assert/cmp"
 )
diff --git a/integration-cli/docker_utils_test.go b/integration-cli/docker_utils_test.go
index b1b15b9a4e..df5e99fd46 100644
--- a/integration-cli/docker_utils_test.go
+++ b/integration-cli/docker_utils_test.go
@@ -20,8 +20,8 @@ import (
 	"github.com/docker/docker/integration-cli/cli"
 	"github.com/docker/docker/integration-cli/daemon"
 	"github.com/docker/docker/internal/testutils/specialimage"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/docker/docker/testutil"
-	"github.com/moby/go-archive"
 	"gotest.tools/v3/assert"
 	is "gotest.tools/v3/assert/cmp"
 	"gotest.tools/v3/icmd"
diff --git a/integration/container/copy_test.go b/integration/container/copy_test.go
index b2afad6dfb..5cccb120e9 100644
--- a/integration/container/copy_test.go
+++ b/integration/container/copy_test.go
@@ -15,9 +15,9 @@ import (
 	containertypes "github.com/docker/docker/api/types/container"
 	"github.com/docker/docker/errdefs"
 	"github.com/docker/docker/integration/internal/container"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/docker/docker/pkg/jsonmessage"
 	"github.com/docker/docker/testutil/fakecontext"
-	"github.com/moby/go-archive"
 	"gotest.tools/v3/assert"
 	is "gotest.tools/v3/assert/cmp"
 	"gotest.tools/v3/skip"
diff --git a/integration/container/overlayfs_linux_test.go b/integration/container/overlayfs_linux_test.go
index 3b64ef2ef9..83ec69620b 100644
--- a/integration/container/overlayfs_linux_test.go
+++ b/integration/container/overlayfs_linux_test.go
@@ -7,7 +7,7 @@ import (
 
 	containertypes "github.com/docker/docker/api/types/container"
 	"github.com/docker/docker/integration/internal/container"
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 	"golang.org/x/sys/unix"
 	"gotest.tools/v3/assert"
 	"gotest.tools/v3/skip"
diff --git a/integration/image/save_test.go b/integration/image/save_test.go
index ce311e9aea..dc840b629d 100644
--- a/integration/image/save_test.go
+++ b/integration/image/save_test.go
@@ -22,8 +22,8 @@ import (
 	"github.com/docker/docker/integration/internal/container"
 	"github.com/docker/docker/internal/testutils"
 	"github.com/docker/docker/internal/testutils/specialimage"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/docker/docker/testutil/fakecontext"
-	"github.com/moby/go-archive"
 	"github.com/opencontainers/go-digest"
 	ocispec "github.com/opencontainers/image-spec/specs-go/v1"
 	"gotest.tools/v3/assert"
diff --git a/integration/plugin/authz/authz_plugin_test.go b/integration/plugin/authz/authz_plugin_test.go
index 1f9150d638..d916f41b9e 100644
--- a/integration/plugin/authz/authz_plugin_test.go
+++ b/integration/plugin/authz/authz_plugin_test.go
@@ -21,10 +21,10 @@ import (
 	"github.com/docker/docker/api/types/image"
 	"github.com/docker/docker/client"
 	"github.com/docker/docker/integration/internal/container"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/docker/docker/pkg/authorization"
 	"github.com/docker/docker/testutil/environment"
 	"github.com/docker/go-connections/sockets"
-	"github.com/moby/go-archive"
 	"gotest.tools/v3/assert"
 	"gotest.tools/v3/skip"
 )
diff --git a/internal/testutils/archive.go b/internal/testutils/archive.go
index 12f7faefd2..064ef1be2d 100644
--- a/internal/testutils/archive.go
+++ b/internal/testutils/archive.go
@@ -3,7 +3,7 @@ package testutils
 import (
 	"io"
 
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/opencontainers/go-digest"
 )
 
diff --git a/internal/testutils/specialimage/load.go b/internal/testutils/specialimage/load.go
index 2722b216e4..1d5b6e049e 100644
--- a/internal/testutils/specialimage/load.go
+++ b/internal/testutils/specialimage/load.go
@@ -10,8 +10,8 @@ import (
 	"testing"
 
 	"github.com/docker/docker/client"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/docker/docker/pkg/jsonmessage"
-	"github.com/moby/go-archive"
 	ocispec "github.com/opencontainers/image-spec/specs-go/v1"
 	"gotest.tools/v3/assert"
 )
diff --git a/internal/testutils/specialimage/multilayer.go b/internal/testutils/specialimage/multilayer.go
index 88bf9fc451..d57881b024 100644
--- a/internal/testutils/specialimage/multilayer.go
+++ b/internal/testutils/specialimage/multilayer.go
@@ -9,8 +9,8 @@ import (
 
 	"github.com/containerd/platforms"
 	"github.com/distribution/reference"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/google/uuid"
-	"github.com/moby/go-archive"
 	"github.com/opencontainers/go-digest"
 	"github.com/opencontainers/image-spec/specs-go"
 	ocispec "github.com/opencontainers/image-spec/specs-go/v1"
diff --git a/layer/layer.go b/layer/layer.go
index c849fabbdf..3f2d3adcaa 100644
--- a/layer/layer.go
+++ b/layer/layer.go
@@ -16,7 +16,7 @@ import (
 
 	"github.com/containerd/log"
 	"github.com/docker/distribution"
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/opencontainers/go-digest"
 )
 
diff --git a/layer/layer_store.go b/layer/layer_store.go
index 9b0996c70a..24fd8b5332 100644
--- a/layer/layer_store.go
+++ b/layer/layer_store.go
@@ -12,9 +12,9 @@ import (
 	"github.com/containerd/log"
 	"github.com/docker/distribution"
 	"github.com/docker/docker/daemon/graphdriver"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/docker/docker/pkg/stringid"
 	"github.com/moby/locker"
-	"github.com/moby/sys/user"
 	"github.com/opencontainers/go-digest"
 	"github.com/vbatts/tar-split/tar/asm"
 	"github.com/vbatts/tar-split/tar/storage"
@@ -46,7 +46,7 @@ type StoreOptions struct {
 	Root               string
 	GraphDriver        string
 	GraphDriverOptions []string
-	IDMapping          user.IdentityMapping
+	IDMapping          idtools.IdentityMapping
 }
 
 // NewStoreFromOptions creates a new Store instance
diff --git a/layer/layer_test.go b/layer/layer_test.go
index d81a7c49b1..6464b48183 100644
--- a/layer/layer_test.go
+++ b/layer/layer_test.go
@@ -13,9 +13,9 @@ import (
 	"github.com/containerd/continuity/driver"
 	"github.com/docker/docker/daemon/graphdriver"
 	"github.com/docker/docker/daemon/graphdriver/vfs"
+	"github.com/docker/docker/pkg/archive"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/docker/docker/pkg/stringid"
-	"github.com/moby/go-archive"
-	"github.com/moby/sys/user"
 	"github.com/opencontainers/go-digest"
 )
 
@@ -28,16 +28,16 @@ func init() {
 func newVFSGraphDriver(td string) (graphdriver.Driver, error) {
 	return graphdriver.New("vfs", graphdriver.Options{
 		Root: td,
-		IDMap: user.IdentityMapping{
-			UIDMaps: []user.IDMap{{
-				ID:       0,
-				ParentID: int64(os.Getuid()),
-				Count:    1,
+		IDMap: idtools.IdentityMapping{
+			UIDMaps: []idtools.IDMap{{
+				ContainerID: 0,
+				HostID:      os.Getuid(),
+				Size:        1,
 			}},
-			GIDMaps: []user.IDMap{{
-				ID:       0,
-				ParentID: int64(os.Getgid()),
-				Count:    1,
+			GIDMaps: []idtools.IDMap{{
+				ContainerID: 0,
+				HostID:      os.Getgid(),
+				Size:        1,
 			}},
 		},
 	})
diff --git a/layer/mount_test.go b/layer/mount_test.go
index e71d078533..dea4a436a0 100644
--- a/layer/mount_test.go
+++ b/layer/mount_test.go
@@ -9,7 +9,7 @@ import (
 	"testing"
 
 	"github.com/containerd/continuity/driver"
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 )
 
 func TestMountInit(t *testing.T) {
diff --git a/layer/mounted_layer.go b/layer/mounted_layer.go
index d08d84e487..0e6d3655b3 100644
--- a/layer/mounted_layer.go
+++ b/layer/mounted_layer.go
@@ -4,7 +4,7 @@ import (
 	"io"
 	"sync"
 
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 )
 
 type mountedLayer struct {
diff --git a/libnetwork/drivers/windows/overlay/overlay.pb.go b/libnetwork/drivers/windows/overlay/overlay.pb.go
index bb7c45361e..9d0cf2663f 100644
--- a/libnetwork/drivers/windows/overlay/overlay.pb.go
+++ b/libnetwork/drivers/windows/overlay/overlay.pb.go
@@ -2,15 +2,13 @@
 // source: drivers/windows/overlay/overlay.proto
 
 /*
-Package overlay is a generated protocol buffer package.
+	Package overlay is a generated protocol buffer package.
 
-It is generated from these files:
+	It is generated from these files:
+		drivers/windows/overlay/overlay.proto
 
-	drivers/windows/overlay/overlay.proto
-
-It has these top-level messages:
-
-	PeerRecord
+	It has these top-level messages:
+		PeerRecord
 */
 package overlay
 
diff --git a/vendor/github.com/moby/go-archive/archive.go b/pkg/archive/archive.go
similarity index 97%
rename from vendor/github.com/moby/go-archive/archive.go
rename to pkg/archive/archive.go
index c207e8e7b0..9bbb11c197 100644
--- a/vendor/github.com/moby/go-archive/archive.go
+++ b/pkg/archive/archive.go
@@ -25,10 +25,10 @@ import (
 	"time"
 
 	"github.com/containerd/log"
+	"github.com/docker/docker/pkg/idtools"
 	"github.com/klauspost/compress/zstd"
 	"github.com/moby/patternmatcher"
 	"github.com/moby/sys/sequential"
-	"github.com/moby/sys/user"
 )
 
 // ImpliedDirectoryMode represents the mode (Unix permissions) applied to directories that are implied by files in a
@@ -49,19 +49,14 @@ type (
 	// WhiteoutFormat is the format of whiteouts unpacked
 	WhiteoutFormat int
 
-	ChownOpts struct {
-		UID int
-		GID int
-	}
-
 	// TarOptions wraps the tar options.
 	TarOptions struct {
 		IncludeFiles     []string
 		ExcludePatterns  []string
 		Compression      Compression
 		NoLchown         bool
-		IDMap            user.IdentityMapping
-		ChownOpts        *ChownOpts
+		IDMap            idtools.IdentityMapping
+		ChownOpts        *idtools.Identity
 		IncludeSourceDir bool
 		// WhiteoutFormat is the expected on disk format for whiteout files.
 		// This format will be converted to the standard format on pack
@@ -88,7 +83,7 @@ type (
 // mappings for untar, an Archiver can be created with maps which will then be passed to Untar operations.
 type Archiver struct {
 	Untar     func(io.Reader, string, *TarOptions) error
-	IDMapping user.IdentityMapping
+	IDMapping idtools.IdentityMapping
 }
 
 // NewDefaultArchiver returns a new Archiver without any IdentityMapping
@@ -603,8 +598,8 @@ type tarAppender struct {
 
 	// for hardlink mapping
 	SeenFiles       map[uint64]string
-	IdentityMapping user.IdentityMapping
-	ChownOpts       *ChownOpts
+	IdentityMapping idtools.IdentityMapping
+	ChownOpts       *idtools.Identity
 
 	// For packing and unpacking whiteout files in the
 	// non standard format. The whiteout files defined
@@ -613,7 +608,7 @@ type tarAppender struct {
 	WhiteoutConverter tarWhiteoutConverter
 }
 
-func newTarAppender(idMapping user.IdentityMapping, writer io.Writer, chownOpts *ChownOpts) *tarAppender {
+func newTarAppender(idMapping idtools.IdentityMapping, writer io.Writer, chownOpts *idtools.Identity) *tarAppender {
 	return &tarAppender{
 		SeenFiles:       make(map[uint64]string),
 		TarWriter:       tar.NewWriter(writer),
@@ -684,11 +679,11 @@ func (ta *tarAppender) addTarFile(path, name string) error {
 	// writing tar headers/files. We skip whiteout files because they were written
 	// by the kernel and already have proper ownership relative to the host
 	if !isOverlayWhiteout && !strings.HasPrefix(filepath.Base(hdr.Name), WhiteoutPrefix) && !ta.IdentityMapping.Empty() {
-		uid, gid, err := getFileUIDGID(fi.Sys())
+		fileIDPair, err := getFileUIDGID(fi.Sys())
 		if err != nil {
 			return err
 		}
-		hdr.Uid, hdr.Gid, err = ta.IdentityMapping.ToContainer(uid, gid)
+		hdr.Uid, hdr.Gid, err = ta.IdentityMapping.ToContainer(fileIDPair)
 		if err != nil {
 			return err
 		}
@@ -748,7 +743,7 @@ func createTarFile(path, extractDir string, hdr *tar.Header, reader io.Reader, o
 	var (
 		Lchown                     = true
 		inUserns, bestEffortXattrs bool
-		chownOpts                  *ChownOpts
+		chownOpts                  *idtools.Identity
 	)
 
 	// TODO(thaJeztah): make opts a required argument.
@@ -844,7 +839,7 @@ func createTarFile(path, extractDir string, hdr *tar.Header, reader io.Reader, o
 	// Lchown is not supported on Windows.
 	if Lchown && runtime.GOOS != "windows" {
 		if chownOpts == nil {
-			chownOpts = &ChownOpts{UID: hdr.Uid, GID: hdr.Gid}
+			chownOpts = &idtools.Identity{UID: hdr.Uid, GID: hdr.Gid}
 		}
 		if err := os.Lchown(path, chownOpts.UID, chownOpts.GID); err != nil {
 			var msg string
@@ -1277,9 +1272,9 @@ func createImpliedDirectories(dest string, hdr *tar.Header, options *TarOptions)
 			// RootPair() is confined inside this loop as most cases will not require a call, so we can spend some
 			// unneeded function calls in the uncommon case to encapsulate logic -- implied directories are a niche
 			// usage that reduces the portability of an image.
-			uid, gid := options.IDMap.RootPair()
+			rootIDs := options.IDMap.RootPair()
 
-			err = user.MkdirAllAndChown(parentPath, ImpliedDirectoryMode, uid, gid, user.WithOnlyNew)
+			err = idtools.MkdirAllAndChownNew(parentPath, ImpliedDirectoryMode, rootIDs)
 			if err != nil {
 				return err
 			}
@@ -1375,9 +1370,9 @@ func (archiver *Archiver) CopyWithTar(src, dst string) error {
 	// if this Archiver is set up with ID mapping we need to create
 	// the new destination directory with the remapped root UID/GID pair
 	// as owner
-	uid, gid := archiver.IDMapping.RootPair()
+	rootIDs := archiver.IDMapping.RootPair()
 	// Create dst, copy src's content into it
-	if err := user.MkdirAllAndChown(dst, 0o755, uid, gid, user.WithOnlyNew); err != nil {
+	if err := idtools.MkdirAllAndChownNew(dst, 0o755, rootIDs); err != nil {
 		return err
 	}
 	return archiver.TarUntar(src, dst)
@@ -1461,13 +1456,13 @@ func (archiver *Archiver) CopyFileWithTar(src, dst string) (err error) {
 }
 
 // IdentityMapping returns the IdentityMapping of the archiver.
-func (archiver *Archiver) IdentityMapping() user.IdentityMapping {
+func (archiver *Archiver) IdentityMapping() idtools.IdentityMapping {
 	return archiver.IDMapping
 }
 
-func remapIDs(idMapping user.IdentityMapping, hdr *tar.Header) error {
-	uid, gid, err := idMapping.ToHost(hdr.Uid, hdr.Gid)
-	hdr.Uid, hdr.Gid = uid, gid
+func remapIDs(idMapping idtools.IdentityMapping, hdr *tar.Header) error {
+	ids, err := idMapping.ToHost(idtools.Identity{UID: hdr.Uid, GID: hdr.Gid})
+	hdr.Uid, hdr.Gid = ids.UID, ids.GID
 	return err
 }
 
diff --git a/pkg/archive/archive_deprecated.go b/pkg/archive/archive_deprecated.go
deleted file mode 100644
index df001b686b..0000000000
--- a/pkg/archive/archive_deprecated.go
+++ /dev/null
@@ -1,257 +0,0 @@
-// Package archive provides helper functions for dealing with archive files.
-package archive
-
-import (
-	"archive/tar"
-	"io"
-	"os"
-
-	"github.com/docker/docker/pkg/idtools"
-	"github.com/moby/go-archive"
-)
-
-// ImpliedDirectoryMode represents the mode (Unix permissions) applied to directories that are implied by files in a
-// tar, but that do not have their own header entry.
-//
-// Deprecated: use [archive.ImpliedDirectoryMode] instead.
-const ImpliedDirectoryMode = archive.ImpliedDirectoryMode
-
-type (
-	// Compression is the state represents if compressed or not.
-	//
-	// Deprecated: use [archive.Compression] instead.
-	Compression = archive.Compression
-	// WhiteoutFormat is the format of whiteouts unpacked
-	//
-	// Deprecated: use [archive.WhiteoutFormat] instead.
-	WhiteoutFormat = archive.WhiteoutFormat
-
-	// TarOptions wraps the tar options.
-	//
-	// Deprecated: use [archive.TarOptions] instead.
-	TarOptions struct {
-		IncludeFiles     []string
-		ExcludePatterns  []string
-		Compression      archive.Compression
-		NoLchown         bool
-		IDMap            idtools.IdentityMapping
-		ChownOpts        *idtools.Identity
-		IncludeSourceDir bool
-		// WhiteoutFormat is the expected on disk format for whiteout files.
-		// This format will be converted to the standard format on pack
-		// and from the standard format on unpack.
-		WhiteoutFormat archive.WhiteoutFormat
-		// When unpacking, specifies whether overwriting a directory with a
-		// non-directory is allowed and vice versa.
-		NoOverwriteDirNonDir bool
-		// For each include when creating an archive, the included name will be
-		// replaced with the matching name from this map.
-		RebaseNames map[string]string
-		InUserNS    bool
-		// Allow unpacking to succeed in spite of failures to set extended
-		// attributes on the unpacked files due to the destination filesystem
-		// not supporting them or a lack of permissions. Extended attributes
-		// were probably in the archive for a reason, so set this option at
-		// your own peril.
-		BestEffortXattrs bool
-	}
-)
-
-// Archiver implements the Archiver interface and allows the reuse of most utility functions of
-// this package with a pluggable Untar function. Also, to facilitate the passing of specific id
-// mappings for untar, an Archiver can be created with maps which will then be passed to Untar operations.
-//
-// Deprecated: use [archive.Archiver] instead.
-type Archiver struct {
-	Untar     func(io.Reader, string, *TarOptions) error
-	IDMapping idtools.IdentityMapping
-}
-
-// NewDefaultArchiver returns a new Archiver without any IdentityMapping
-//
-// Deprecated: use [archive.NewDefaultArchiver] instead.
-func NewDefaultArchiver() *Archiver {
-	return &Archiver{Untar: Untar}
-}
-
-const (
-	Uncompressed = archive.Uncompressed // Deprecated: use [archive.Uncompressed] instead.
-	Bzip2        = archive.Bzip2        // Deprecated: use [archive.Bzip2] instead.
-	Gzip         = archive.Gzip         // Deprecated: use [archive.Gzip] instead.
-	Xz           = archive.Xz           // Deprecated: use [archive.Xz] instead.
-	Zstd         = archive.Zstd         // Deprecated: use [archive.Zstd] instead.
-)
-
-const (
-	AUFSWhiteoutFormat    = archive.AUFSWhiteoutFormat    // Deprecated: use [archive.AUFSWhiteoutFormat] instead.
-	OverlayWhiteoutFormat = archive.OverlayWhiteoutFormat // Deprecated: use [archive.OverlayWhiteoutFormat] instead.
-)
-
-// IsArchivePath checks if the (possibly compressed) file at the given path
-// starts with a tar file header.
-//
-// Deprecated: use [archive.IsArchivePath] instead.
-func IsArchivePath(path string) bool {
-	return archive.IsArchivePath(path)
-}
-
-// DetectCompression detects the compression algorithm of the source.
-//
-// Deprecated: use [archive.DetectCompression] instead.
-func DetectCompression(source []byte) archive.Compression {
-	return archive.DetectCompression(source)
-}
-
-// DecompressStream decompresses the archive and returns a ReaderCloser with the decompressed archive.
-//
-// Deprecated: use [archive.DecompressStream] instead.
-func DecompressStream(arch io.Reader) (io.ReadCloser, error) {
-	return archive.DecompressStream(arch)
-}
-
-// CompressStream compresses the dest with specified compression algorithm.
-//
-// Deprecated: use [archive.CompressStream] instead.
-func CompressStream(dest io.Writer, compression archive.Compression) (io.WriteCloser, error) {
-	return archive.CompressStream(dest, compression)
-}
-
-// TarModifierFunc is a function that can be passed to ReplaceFileTarWrapper.
-//
-// Deprecated: use [archive.TarModifierFunc] instead.
-type TarModifierFunc = archive.TarModifierFunc
-
-// ReplaceFileTarWrapper converts inputTarStream to a new tar stream.
-//
-// Deprecated: use [archive.ReplaceFileTarWrapper] instead.
-func ReplaceFileTarWrapper(inputTarStream io.ReadCloser, mods map[string]archive.TarModifierFunc) io.ReadCloser {
-	return archive.ReplaceFileTarWrapper(inputTarStream, mods)
-}
-
-// FileInfoHeaderNoLookups creates a partially-populated tar.Header from fi.
-//
-// Deprecated: use [archive.FileInfoHeaderNoLookups] instead.
-func FileInfoHeaderNoLookups(fi os.FileInfo, link string) (*tar.Header, error) {
-	return archive.FileInfoHeaderNoLookups(fi, link)
-}
-
-// FileInfoHeader creates a populated Header from fi.
-//
-// Deprecated: use [archive.FileInfoHeader] instead.
-func FileInfoHeader(name string, fi os.FileInfo, link string) (*tar.Header, error) {
-	return archive.FileInfoHeader(name, fi, link)
-}
-
-// ReadSecurityXattrToTarHeader reads security.capability xattr from filesystem
-// to a tar header
-//
-// Deprecated: use [archive.ReadSecurityXattrToTarHeader] instead.
-func ReadSecurityXattrToTarHeader(path string, hdr *tar.Header) error {
-	return archive.ReadSecurityXattrToTarHeader(path, hdr)
-}
-
-// Tar creates an archive from the directory at `path`, and returns it as a
-// stream of bytes.
-//
-// Deprecated: use [archive.Tar] instead.
-func Tar(path string, compression archive.Compression) (io.ReadCloser, error) {
-	return archive.TarWithOptions(path, &archive.TarOptions{Compression: compression})
-}
-
-// TarWithOptions creates an archive with the given options.
-//
-// Deprecated: use [archive.TarWithOptions] instead.
-func TarWithOptions(srcPath string, options *TarOptions) (io.ReadCloser, error) {
-	return archive.TarWithOptions(srcPath, toArchiveOpt(options))
-}
-
-// Tarballer is a lower-level interface to TarWithOptions.
-//
-// Deprecated: use [archive.Tarballer] instead.
-type Tarballer = archive.Tarballer
-
-// NewTarballer constructs a new tarballer using TarWithOptions.
-//
-// Deprecated: use [archive.Tarballer] instead.
-func NewTarballer(srcPath string, options *TarOptions) (*archive.Tarballer, error) {
-	return archive.NewTarballer(srcPath, toArchiveOpt(options))
-}
-
-// Unpack unpacks the decompressedArchive to dest with options.
-//
-// Deprecated: use [archive.Unpack] instead.
-func Unpack(decompressedArchive io.Reader, dest string, options *TarOptions) error {
-	return archive.Unpack(decompressedArchive, dest, toArchiveOpt(options))
-}
-
-// Untar reads a stream of bytes from `archive`, parses it as a tar archive,
-// and unpacks it into the directory at `dest`.
-//
-// Deprecated: use [archive.Untar] instead.
-func Untar(tarArchive io.Reader, dest string, options *TarOptions) error {
-	return archive.Untar(tarArchive, dest, toArchiveOpt(options))
-}
-
-// UntarUncompressed reads a stream of bytes from `tarArchive`, parses it as a tar archive,
-// and unpacks it into the directory at `dest`.
-// The archive must be an uncompressed stream.
-//
-// Deprecated: use [archive.UntarUncompressed] instead.
-func UntarUncompressed(tarArchive io.Reader, dest string, options *TarOptions) error {
-	return archive.UntarUncompressed(tarArchive, dest, toArchiveOpt(options))
-}
-
-// TarUntar is a convenience function which calls Tar and Untar, with the output of one piped into the other.
-// If either Tar or Untar fails, TarUntar aborts and returns the error.
-func (archiver *Archiver) TarUntar(src, dst string) error {
-	return (&archive.Archiver{
-		Untar: func(reader io.Reader, s string, options *archive.TarOptions) error {
-			return archiver.Untar(reader, s, &TarOptions{
-				IDMap: archiver.IDMapping,
-			})
-		},
-		IDMapping: idtools.ToUserIdentityMapping(archiver.IDMapping),
-	}).TarUntar(src, dst)
-}
-
-// UntarPath untar a file from path to a destination, src is the source tar file path.
-func (archiver *Archiver) UntarPath(src, dst string) error {
-	return (&archive.Archiver{
-		Untar: func(reader io.Reader, s string, options *archive.TarOptions) error {
-			return archiver.Untar(reader, s, &TarOptions{
-				IDMap: archiver.IDMapping,
-			})
-		},
-		IDMapping: idtools.ToUserIdentityMapping(archiver.IDMapping),
-	}).UntarPath(src, dst)
-}
-
-// CopyWithTar creates a tar archive of filesystem path `src`, and
-// unpacks it at filesystem path `dst`.
-// The archive is streamed directly with fixed buffering and no
-// intermediary disk IO.
-func (archiver *Archiver) CopyWithTar(src, dst string) error {
-	return (&archive.Archiver{
-		Untar: func(reader io.Reader, s string, options *archive.TarOptions) error {
-			return archiver.Untar(reader, s, nil)
-		},
-		IDMapping: idtools.ToUserIdentityMapping(archiver.IDMapping),
-	}).CopyWithTar(src, dst)
-}
-
-// CopyFileWithTar emulates the behavior of the 'cp' command-line
-// for a single file. It copies a regular file from path `src` to
-// path `dst`, and preserves all its metadata.
-func (archiver *Archiver) CopyFileWithTar(src, dst string) (err error) {
-	return (&archive.Archiver{
-		Untar: func(reader io.Reader, s string, options *archive.TarOptions) error {
-			return archiver.Untar(reader, s, nil)
-		},
-		IDMapping: idtools.ToUserIdentityMapping(archiver.IDMapping),
-	}).CopyFileWithTar(src, dst)
-}
-
-// IdentityMapping returns the IdentityMapping of the archiver.
-func (archiver *Archiver) IdentityMapping() idtools.IdentityMapping {
-	return archiver.IDMapping
-}
diff --git a/vendor/github.com/moby/go-archive/archive_linux.go b/pkg/archive/archive_linux.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/archive_linux.go
rename to pkg/archive/archive_linux.go
diff --git a/pkg/archive/archive_linux_test.go b/pkg/archive/archive_linux_test.go
new file mode 100644
index 0000000000..b96e91d908
--- /dev/null
+++ b/pkg/archive/archive_linux_test.go
@@ -0,0 +1,193 @@
+package archive
+
+import (
+	"archive/tar"
+	"bytes"
+	"io"
+	"os"
+	"path/filepath"
+	"syscall"
+	"testing"
+
+	"github.com/google/go-cmp/cmp/cmpopts"
+	"github.com/moby/sys/userns"
+	"golang.org/x/sys/unix"
+	"gotest.tools/v3/assert"
+	is "gotest.tools/v3/assert/cmp"
+	"gotest.tools/v3/skip"
+)
+
+// setupOverlayTestDir creates files in a directory with overlay whiteouts
+// Tree layout
+//
+//	.
+//	 d1     # opaque, 0700
+//	    f1 # empty file, 0600
+//	 d2     # opaque, 0750
+//	    f1 # empty file, 0660
+//	 d3     # 0700
+//	     f1 # whiteout, 0644
+func setupOverlayTestDir(t *testing.T, src string) {
+	skip.If(t, os.Getuid() != 0, "skipping test that requires root")
+	skip.If(t, userns.RunningInUserNS(), "skipping test that requires initial userns (trusted.overlay.opaque xattr cannot be set in userns, even with Ubuntu kernel)")
+	// Create opaque directory containing single file and permission 0700
+	err := os.Mkdir(filepath.Join(src, "d1"), 0o700)
+	assert.NilError(t, err)
+
+	err = unix.Lsetxattr(filepath.Join(src, "d1"), "trusted.overlay.opaque", []byte("y"), 0)
+	assert.NilError(t, err)
+
+	err = os.WriteFile(filepath.Join(src, "d1", "f1"), []byte{}, 0o600)
+	assert.NilError(t, err)
+
+	// Create another opaque directory containing single file but with permission 0750
+	err = os.Mkdir(filepath.Join(src, "d2"), 0o750)
+	assert.NilError(t, err)
+
+	err = unix.Lsetxattr(filepath.Join(src, "d2"), "trusted.overlay.opaque", []byte("y"), 0)
+	assert.NilError(t, err)
+
+	err = os.WriteFile(filepath.Join(src, "d2", "f1"), []byte{}, 0o660)
+	assert.NilError(t, err)
+
+	// Create regular directory with deleted file
+	err = os.Mkdir(filepath.Join(src, "d3"), 0o700)
+	assert.NilError(t, err)
+
+	err = unix.Mknod(filepath.Join(src, "d3", "f1"), unix.S_IFCHR, 0)
+	assert.NilError(t, err)
+}
+
+func checkOpaqueness(t *testing.T, path string, opaque string) {
+	xattrOpaque, err := lgetxattr(path, "trusted.overlay.opaque")
+	assert.NilError(t, err)
+
+	if string(xattrOpaque) != opaque {
+		t.Fatalf("Unexpected opaque value: %q, expected %q", string(xattrOpaque), opaque)
+	}
+}
+
+func checkOverlayWhiteout(t *testing.T, path string) {
+	stat, err := os.Stat(path)
+	assert.NilError(t, err)
+
+	statT, ok := stat.Sys().(*syscall.Stat_t)
+	if !ok {
+		t.Fatalf("Unexpected type: %t, expected *syscall.Stat_t", stat.Sys())
+	}
+	if statT.Rdev != 0 {
+		t.Fatalf("Non-zero device number for whiteout")
+	}
+}
+
+func checkFileMode(t *testing.T, path string, perm os.FileMode) {
+	stat, err := os.Stat(path)
+	assert.NilError(t, err)
+
+	if stat.Mode() != perm {
+		t.Fatalf("Unexpected file mode for %s: %o, expected %o", path, stat.Mode(), perm)
+	}
+}
+
+func TestOverlayTarUntar(t *testing.T) {
+	restore := overrideUmask(0)
+	defer restore()
+
+	src, err := os.MkdirTemp("", "docker-test-overlay-tar-src")
+	assert.NilError(t, err)
+	defer os.RemoveAll(src)
+
+	setupOverlayTestDir(t, src)
+
+	dst, err := os.MkdirTemp("", "docker-test-overlay-tar-dst")
+	assert.NilError(t, err)
+	defer os.RemoveAll(dst)
+
+	options := &TarOptions{
+		Compression:    Uncompressed,
+		WhiteoutFormat: OverlayWhiteoutFormat,
+	}
+	reader, err := TarWithOptions(src, options)
+	assert.NilError(t, err)
+	archive, err := io.ReadAll(reader)
+	reader.Close()
+	assert.NilError(t, err)
+
+	// The archive should encode opaque directories and file whiteouts
+	// in AUFS format.
+	entries := make(map[string]struct{})
+	rdr := tar.NewReader(bytes.NewReader(archive))
+	for {
+		h, err := rdr.Next()
+		if err == io.EOF {
+			break
+		}
+		assert.NilError(t, err)
+		assert.Check(t, is.Equal(h.Devmajor, int64(0)), "unexpected device file in archive")
+		assert.Check(t, is.DeepEqual(h.PAXRecords, map[string]string(nil), cmpopts.EquateEmpty()))
+		entries[h.Name] = struct{}{}
+	}
+
+	assert.DeepEqual(t, entries, map[string]struct{}{
+		"d1/":                         {},
+		"d1/" + WhiteoutOpaqueDir:     {},
+		"d1/f1":                       {},
+		"d2/":                         {},
+		"d2/" + WhiteoutOpaqueDir:     {},
+		"d2/f1":                       {},
+		"d3/":                         {},
+		"d3/" + WhiteoutPrefix + "f1": {},
+	})
+
+	err = Untar(bytes.NewReader(archive), dst, options)
+	assert.NilError(t, err)
+
+	checkFileMode(t, filepath.Join(dst, "d1"), 0o700|os.ModeDir)
+	checkFileMode(t, filepath.Join(dst, "d2"), 0o750|os.ModeDir)
+	checkFileMode(t, filepath.Join(dst, "d3"), 0o700|os.ModeDir)
+	checkFileMode(t, filepath.Join(dst, "d1", "f1"), 0o600)
+	checkFileMode(t, filepath.Join(dst, "d2", "f1"), 0o660)
+	checkFileMode(t, filepath.Join(dst, "d3", "f1"), os.ModeCharDevice|os.ModeDevice)
+
+	checkOpaqueness(t, filepath.Join(dst, "d1"), "y")
+	checkOpaqueness(t, filepath.Join(dst, "d2"), "y")
+	checkOpaqueness(t, filepath.Join(dst, "d3"), "")
+	checkOverlayWhiteout(t, filepath.Join(dst, "d3", "f1"))
+}
+
+func TestOverlayTarAUFSUntar(t *testing.T) {
+	restore := overrideUmask(0)
+	defer restore()
+
+	src, err := os.MkdirTemp("", "docker-test-overlay-tar-src")
+	assert.NilError(t, err)
+	defer os.RemoveAll(src)
+
+	setupOverlayTestDir(t, src)
+
+	dst, err := os.MkdirTemp("", "docker-test-overlay-tar-dst")
+	assert.NilError(t, err)
+	defer os.RemoveAll(dst)
+
+	archive, err := TarWithOptions(src, &TarOptions{
+		Compression:    Uncompressed,
+		WhiteoutFormat: OverlayWhiteoutFormat,
+	})
+	assert.NilError(t, err)
+	defer archive.Close()
+
+	err = Untar(archive, dst, &TarOptions{
+		Compression:    Uncompressed,
+		WhiteoutFormat: AUFSWhiteoutFormat,
+	})
+	assert.NilError(t, err)
+
+	checkFileMode(t, filepath.Join(dst, "d1"), 0o700|os.ModeDir)
+	checkFileMode(t, filepath.Join(dst, "d1", WhiteoutOpaqueDir), 0o700)
+	checkFileMode(t, filepath.Join(dst, "d2"), 0o750|os.ModeDir)
+	checkFileMode(t, filepath.Join(dst, "d2", WhiteoutOpaqueDir), 0o750)
+	checkFileMode(t, filepath.Join(dst, "d3"), 0o700|os.ModeDir)
+	checkFileMode(t, filepath.Join(dst, "d1", "f1"), 0o600)
+	checkFileMode(t, filepath.Join(dst, "d2", "f1"), 0o660)
+	checkFileMode(t, filepath.Join(dst, "d3", WhiteoutPrefix+"f1"), 0o600)
+}
diff --git a/vendor/github.com/moby/go-archive/archive_other.go b/pkg/archive/archive_other.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/archive_other.go
rename to pkg/archive/archive_other.go
diff --git a/pkg/archive/archive_test.go b/pkg/archive/archive_test.go
new file mode 100644
index 0000000000..078077eb4e
--- /dev/null
+++ b/pkg/archive/archive_test.go
@@ -0,0 +1,1476 @@
+package archive
+
+import (
+	"archive/tar"
+	"bytes"
+	"compress/gzip"
+	"fmt"
+	"io"
+	"io/fs"
+	"os"
+	"os/exec"
+	"path/filepath"
+	"reflect"
+	"runtime"
+	"strings"
+	"testing"
+	"time"
+
+	"github.com/docker/docker/pkg/idtools"
+	"github.com/moby/sys/userns"
+	"gotest.tools/v3/assert"
+	is "gotest.tools/v3/assert/cmp"
+	"gotest.tools/v3/skip"
+)
+
+var tmp string
+
+func init() {
+	tmp = "/tmp/"
+	if runtime.GOOS == "windows" {
+		tmp = os.Getenv("TEMP") + `\`
+	}
+}
+
+var defaultArchiver = NewDefaultArchiver()
+
+func defaultTarUntar(src, dst string) error {
+	return defaultArchiver.TarUntar(src, dst)
+}
+
+func defaultUntarPath(src, dst string) error {
+	return defaultArchiver.UntarPath(src, dst)
+}
+
+func defaultCopyFileWithTar(src, dst string) (err error) {
+	return defaultArchiver.CopyFileWithTar(src, dst)
+}
+
+func defaultCopyWithTar(src, dst string) error {
+	return defaultArchiver.CopyWithTar(src, dst)
+}
+
+func TestIsArchivePathDir(t *testing.T) {
+	cmd := exec.Command("sh", "-c", "mkdir -p /tmp/archivedir")
+	output, err := cmd.CombinedOutput()
+	if err != nil {
+		t.Fatalf("Fail to create an archive file for test : %s.", output)
+	}
+	if IsArchivePath(tmp + "archivedir") {
+		t.Fatalf("Incorrectly recognised directory as an archive")
+	}
+}
+
+func TestIsArchivePathInvalidFile(t *testing.T) {
+	cmd := exec.Command("sh", "-c", "dd if=/dev/zero bs=1024 count=1 of=/tmp/archive && gzip --stdout /tmp/archive > /tmp/archive.gz")
+	output, err := cmd.CombinedOutput()
+	if err != nil {
+		t.Fatalf("Fail to create an archive file for test : %s.", output)
+	}
+	if IsArchivePath(tmp + "archive") {
+		t.Fatalf("Incorrectly recognised invalid tar path as archive")
+	}
+	if IsArchivePath(tmp + "archive.gz") {
+		t.Fatalf("Incorrectly recognised invalid compressed tar path as archive")
+	}
+}
+
+func TestIsArchivePathTar(t *testing.T) {
+	whichTar := "tar"
+	cmdStr := fmt.Sprintf("touch /tmp/archivedata && %s -cf /tmp/archive /tmp/archivedata && gzip --stdout /tmp/archive > /tmp/archive.gz", whichTar)
+	cmd := exec.Command("sh", "-c", cmdStr)
+	output, err := cmd.CombinedOutput()
+	if err != nil {
+		t.Fatalf("Fail to create an archive file for test : %s.", output)
+	}
+	if !IsArchivePath(tmp + "/archive") {
+		t.Fatalf("Did not recognise valid tar path as archive")
+	}
+	if !IsArchivePath(tmp + "archive.gz") {
+		t.Fatalf("Did not recognise valid compressed tar path as archive")
+	}
+}
+
+func testDecompressStream(t *testing.T, ext, compressCommand string) io.Reader {
+	cmd := exec.Command("sh", "-c",
+		fmt.Sprintf("touch /tmp/archive && %s /tmp/archive", compressCommand))
+	output, err := cmd.CombinedOutput()
+	if err != nil {
+		t.Fatalf("Failed to create an archive file for test : %s.", output)
+	}
+	filename := "archive." + ext
+	archive, err := os.Open(tmp + filename)
+	if err != nil {
+		t.Fatalf("Failed to open file %s: %v", filename, err)
+	}
+	defer archive.Close()
+
+	r, err := DecompressStream(archive)
+	if err != nil {
+		t.Fatalf("Failed to decompress %s: %v", filename, err)
+	}
+	if _, err = io.ReadAll(r); err != nil {
+		t.Fatalf("Failed to read the decompressed stream: %v ", err)
+	}
+	if err = r.Close(); err != nil {
+		t.Fatalf("Failed to close the decompressed stream: %v ", err)
+	}
+
+	return r
+}
+
+func TestDecompressStreamGzip(t *testing.T) {
+	testDecompressStream(t, "gz", "gzip -f")
+}
+
+func TestDecompressStreamBzip2(t *testing.T) {
+	testDecompressStream(t, "bz2", "bzip2 -f")
+}
+
+func TestDecompressStreamXz(t *testing.T) {
+	if runtime.GOOS == "windows" {
+		t.Skip("Xz not present in msys2")
+	}
+	testDecompressStream(t, "xz", "xz -f")
+}
+
+func TestDecompressStreamZstd(t *testing.T) {
+	if _, err := exec.LookPath("zstd"); err != nil {
+		t.Skip("zstd not installed")
+	}
+	testDecompressStream(t, "zst", "zstd -f")
+}
+
+func TestCompressStreamXzUnsupported(t *testing.T) {
+	dest, err := os.Create(tmp + "dest")
+	if err != nil {
+		t.Fatalf("Fail to create the destination file")
+	}
+	defer dest.Close()
+
+	_, err = CompressStream(dest, Xz)
+	if err == nil {
+		t.Fatalf("Should fail as xz is unsupported for compression format.")
+	}
+}
+
+func TestCompressStreamBzip2Unsupported(t *testing.T) {
+	dest, err := os.Create(tmp + "dest")
+	if err != nil {
+		t.Fatalf("Fail to create the destination file")
+	}
+	defer dest.Close()
+
+	_, err = CompressStream(dest, Bzip2)
+	if err == nil {
+		t.Fatalf("Should fail as bzip2 is unsupported for compression format.")
+	}
+}
+
+func TestCompressStreamInvalid(t *testing.T) {
+	dest, err := os.Create(tmp + "dest")
+	if err != nil {
+		t.Fatalf("Fail to create the destination file")
+	}
+	defer dest.Close()
+
+	_, err = CompressStream(dest, -1)
+	if err == nil {
+		t.Fatalf("Should fail as xz is unsupported for compression format.")
+	}
+}
+
+func TestExtensionInvalid(t *testing.T) {
+	compression := Compression(-1)
+	output := compression.Extension()
+	if output != "" {
+		t.Fatalf("The extension of an invalid compression should be an empty string.")
+	}
+}
+
+func TestExtensionUncompressed(t *testing.T) {
+	compression := Uncompressed
+	output := compression.Extension()
+	if output != "tar" {
+		t.Fatalf("The extension of an uncompressed archive should be 'tar'.")
+	}
+}
+
+func TestExtensionBzip2(t *testing.T) {
+	compression := Bzip2
+	output := compression.Extension()
+	if output != "tar.bz2" {
+		t.Fatalf("The extension of a bzip2 archive should be 'tar.bz2'")
+	}
+}
+
+func TestExtensionGzip(t *testing.T) {
+	compression := Gzip
+	output := compression.Extension()
+	if output != "tar.gz" {
+		t.Fatalf("The extension of a gzip archive should be 'tar.gz'")
+	}
+}
+
+func TestExtensionXz(t *testing.T) {
+	compression := Xz
+	output := compression.Extension()
+	if output != "tar.xz" {
+		t.Fatalf("The extension of a xz archive should be 'tar.xz'")
+	}
+}
+
+func TestExtensionZstd(t *testing.T) {
+	compression := Zstd
+	output := compression.Extension()
+	if output != "tar.zst" {
+		t.Fatalf("The extension of a zstd archive should be 'tar.zst'")
+	}
+}
+
+func TestCmdStreamLargeStderr(t *testing.T) {
+	cmd := exec.Command("sh", "-c", "dd if=/dev/zero bs=1k count=1000 of=/dev/stderr; echo hello")
+	out, err := cmdStream(cmd, nil)
+	if err != nil {
+		t.Fatalf("Failed to start command: %s", err)
+	}
+	errCh := make(chan error, 1)
+	go func() {
+		_, err := io.Copy(io.Discard, out)
+		errCh <- err
+	}()
+	select {
+	case err := <-errCh:
+		if err != nil {
+			t.Fatalf("Command should not have failed (err=%.100s...)", err)
+		}
+	case <-time.After(5 * time.Second):
+		t.Fatalf("Command did not complete in 5 seconds; probable deadlock")
+	}
+}
+
+func TestCmdStreamBad(t *testing.T) {
+	// TODO Windows: Figure out why this is failing in CI but not locally
+	if runtime.GOOS == "windows" {
+		t.Skip("Failing on Windows CI machines")
+	}
+	badCmd := exec.Command("sh", "-c", "echo hello; echo >&2 error couldn\\'t reverse the phase pulser; exit 1")
+	out, err := cmdStream(badCmd, nil)
+	if err != nil {
+		t.Fatalf("Failed to start command: %s", err)
+	}
+	if output, err := io.ReadAll(out); err == nil {
+		t.Fatalf("Command should have failed")
+	} else if err.Error() != "exit status 1: error couldn't reverse the phase pulser\n" {
+		t.Fatalf("Wrong error value (%s)", err)
+	} else if s := string(output); s != "hello\n" {
+		t.Fatalf("Command output should be '%s', not '%s'", "hello\\n", output)
+	}
+}
+
+func TestCmdStreamGood(t *testing.T) {
+	cmd := exec.Command("sh", "-c", "echo hello; exit 0")
+	out, err := cmdStream(cmd, nil)
+	if err != nil {
+		t.Fatal(err)
+	}
+	if output, err := io.ReadAll(out); err != nil {
+		t.Fatalf("Command should not have failed (err=%s)", err)
+	} else if s := string(output); s != "hello\n" {
+		t.Fatalf("Command output should be '%s', not '%s'", "hello\\n", output)
+	}
+}
+
+func TestUntarPathWithInvalidDest(t *testing.T) {
+	tempFolder, err := os.MkdirTemp("", "docker-archive-test")
+	assert.NilError(t, err)
+	defer os.RemoveAll(tempFolder)
+	invalidDestFolder := filepath.Join(tempFolder, "invalidDest")
+	// Create a src file
+	srcFile := filepath.Join(tempFolder, "src")
+	tarFile := filepath.Join(tempFolder, "src.tar")
+	f, err := os.Create(srcFile)
+	if assert.Check(t, err) {
+		_ = f.Close()
+	}
+
+	d, err := os.Create(invalidDestFolder) // being a file (not dir) should cause an error
+	if assert.Check(t, err) {
+		_ = d.Close()
+	}
+
+	// Translate back to Unix semantics as next exec.Command is run under sh
+	srcFileU := srcFile
+	tarFileU := tarFile
+	if runtime.GOOS == "windows" {
+		tarFileU = "/tmp/" + filepath.Base(filepath.Dir(tarFile)) + "/src.tar"
+		srcFileU = "/tmp/" + filepath.Base(filepath.Dir(srcFile)) + "/src"
+	}
+
+	cmd := exec.Command("sh", "-c", "tar cf "+tarFileU+" "+srcFileU)
+	_, err = cmd.CombinedOutput()
+	assert.NilError(t, err)
+
+	err = defaultUntarPath(tarFile, invalidDestFolder)
+	if err == nil {
+		t.Fatalf("UntarPath with invalid destination path should throw an error.")
+	}
+}
+
+func TestUntarPathWithInvalidSrc(t *testing.T) {
+	dest, err := os.MkdirTemp("", "docker-archive-test")
+	if err != nil {
+		t.Fatalf("Fail to create the destination file")
+	}
+	defer os.RemoveAll(dest)
+	err = defaultUntarPath("/invalid/path", dest)
+	if err == nil {
+		t.Fatalf("UntarPath with invalid src path should throw an error.")
+	}
+}
+
+func TestUntarPath(t *testing.T) {
+	skip.If(t, runtime.GOOS != "windows" && os.Getuid() != 0, "skipping test that requires root")
+	tmpFolder, err := os.MkdirTemp("", "docker-archive-test")
+	assert.NilError(t, err)
+	defer os.RemoveAll(tmpFolder)
+	srcFile := filepath.Join(tmpFolder, "src")
+	tarFile := filepath.Join(tmpFolder, "src.tar")
+	f, err := os.Create(filepath.Join(tmpFolder, "src"))
+	if assert.Check(t, err) {
+		_ = f.Close()
+	}
+
+	destFolder := filepath.Join(tmpFolder, "dest")
+	err = os.MkdirAll(destFolder, 0o740)
+	if err != nil {
+		t.Fatalf("Fail to create the destination file")
+	}
+
+	// Translate back to Unix semantics as next exec.Command is run under sh
+	srcFileU := srcFile
+	tarFileU := tarFile
+	if runtime.GOOS == "windows" {
+		tarFileU = "/tmp/" + filepath.Base(filepath.Dir(tarFile)) + "/src.tar"
+		srcFileU = "/tmp/" + filepath.Base(filepath.Dir(srcFile)) + "/src"
+	}
+	cmd := exec.Command("sh", "-c", "tar cf "+tarFileU+" "+srcFileU)
+	_, err = cmd.CombinedOutput()
+	assert.NilError(t, err)
+
+	err = defaultUntarPath(tarFile, destFolder)
+	if err != nil {
+		t.Fatalf("UntarPath shouldn't throw an error, %s.", err)
+	}
+	expectedFile := filepath.Join(destFolder, srcFileU)
+	_, err = os.Stat(expectedFile)
+	if err != nil {
+		t.Fatalf("Destination folder should contain the source file but did not.")
+	}
+}
+
+// Do the same test as above but with the destination as file, it should fail
+func TestUntarPathWithDestinationFile(t *testing.T) {
+	tmpFolder, err := os.MkdirTemp("", "docker-archive-test")
+	if err != nil {
+		t.Fatal(err)
+	}
+	defer os.RemoveAll(tmpFolder)
+	srcFile := filepath.Join(tmpFolder, "src")
+	tarFile := filepath.Join(tmpFolder, "src.tar")
+	f, err := os.Create(filepath.Join(tmpFolder, "src"))
+	if assert.Check(t, err) {
+		_ = f.Close()
+	}
+
+	// Translate back to Unix semantics as next exec.Command is run under sh
+	srcFileU := srcFile
+	tarFileU := tarFile
+	if runtime.GOOS == "windows" {
+		tarFileU = "/tmp/" + filepath.Base(filepath.Dir(tarFile)) + "/src.tar"
+		srcFileU = "/tmp/" + filepath.Base(filepath.Dir(srcFile)) + "/src"
+	}
+	cmd := exec.Command("sh", "-c", "tar cf "+tarFileU+" "+srcFileU)
+	_, err = cmd.CombinedOutput()
+	if err != nil {
+		t.Fatal(err)
+	}
+	destFile := filepath.Join(tmpFolder, "dest")
+	f, err = os.Create(destFile)
+	if assert.Check(t, err) {
+		_ = f.Close()
+	}
+	err = defaultUntarPath(tarFile, destFile)
+	if err == nil {
+		t.Fatalf("UntarPath should throw an error if the destination if a file")
+	}
+}
+
+// Do the same test as above but with the destination folder already exists
+// and the destination file is a directory
+// It's working, see https://github.com/docker/docker/issues/10040
+func TestUntarPathWithDestinationSrcFileAsFolder(t *testing.T) {
+	tmpFolder, err := os.MkdirTemp("", "docker-archive-test")
+	if err != nil {
+		t.Fatal(err)
+	}
+	defer os.RemoveAll(tmpFolder)
+	srcFile := filepath.Join(tmpFolder, "src")
+	tarFile := filepath.Join(tmpFolder, "src.tar")
+	f, err := os.Create(srcFile)
+	if assert.Check(t, err) {
+		_ = f.Close()
+	}
+
+	// Translate back to Unix semantics as next exec.Command is run under sh
+	srcFileU := srcFile
+	tarFileU := tarFile
+	if runtime.GOOS == "windows" {
+		tarFileU = "/tmp/" + filepath.Base(filepath.Dir(tarFile)) + "/src.tar"
+		srcFileU = "/tmp/" + filepath.Base(filepath.Dir(srcFile)) + "/src"
+	}
+
+	cmd := exec.Command("sh", "-c", "tar cf "+tarFileU+" "+srcFileU)
+	_, err = cmd.CombinedOutput()
+	if err != nil {
+		t.Fatal(err)
+	}
+	destFolder := filepath.Join(tmpFolder, "dest")
+	err = os.MkdirAll(destFolder, 0o740)
+	if err != nil {
+		t.Fatalf("Fail to create the destination folder")
+	}
+	// Let's create a folder that will has the same path as the extracted file (from tar)
+	destSrcFileAsFolder := filepath.Join(destFolder, srcFileU)
+	err = os.MkdirAll(destSrcFileAsFolder, 0o740)
+	if err != nil {
+		t.Fatal(err)
+	}
+	err = defaultUntarPath(tarFile, destFolder)
+	if err != nil {
+		t.Fatalf("UntarPath should throw not throw an error if the extracted file already exists and is a folder")
+	}
+}
+
+func TestCopyWithTarInvalidSrc(t *testing.T) {
+	tempFolder, err := os.MkdirTemp("", "docker-archive-test")
+	if err != nil {
+		t.Fatal(nil)
+	}
+	destFolder := filepath.Join(tempFolder, "dest")
+	invalidSrc := filepath.Join(tempFolder, "doesnotexists")
+	err = os.MkdirAll(destFolder, 0o740)
+	if err != nil {
+		t.Fatal(err)
+	}
+	err = defaultCopyWithTar(invalidSrc, destFolder)
+	if err == nil {
+		t.Fatalf("archiver.CopyWithTar with invalid src path should throw an error.")
+	}
+}
+
+func TestCopyWithTarInexistentDestWillCreateIt(t *testing.T) {
+	skip.If(t, runtime.GOOS != "windows" && os.Getuid() != 0, "skipping test that requires root")
+	tempFolder, err := os.MkdirTemp("", "docker-archive-test")
+	if err != nil {
+		t.Fatal(nil)
+	}
+	srcFolder := filepath.Join(tempFolder, "src")
+	inexistentDestFolder := filepath.Join(tempFolder, "doesnotexists")
+	err = os.MkdirAll(srcFolder, 0o740)
+	if err != nil {
+		t.Fatal(err)
+	}
+	err = defaultCopyWithTar(srcFolder, inexistentDestFolder)
+	if err != nil {
+		t.Fatalf("CopyWithTar with an inexistent folder shouldn't fail.")
+	}
+	_, err = os.Stat(inexistentDestFolder)
+	if err != nil {
+		t.Fatalf("CopyWithTar with an inexistent folder should create it.")
+	}
+}
+
+// Test CopyWithTar with a file as src
+func TestCopyWithTarSrcFile(t *testing.T) {
+	folder, err := os.MkdirTemp("", "docker-archive-test")
+	if err != nil {
+		t.Fatal(err)
+	}
+	defer os.RemoveAll(folder)
+	dest := filepath.Join(folder, "dest")
+	srcFolder := filepath.Join(folder, "src")
+	src := filepath.Join(folder, filepath.Join("src", "src"))
+	err = os.MkdirAll(srcFolder, 0o740)
+	if err != nil {
+		t.Fatal(err)
+	}
+	err = os.MkdirAll(dest, 0o740)
+	if err != nil {
+		t.Fatal(err)
+	}
+	os.WriteFile(src, []byte("content"), 0o777)
+	err = defaultCopyWithTar(src, dest)
+	if err != nil {
+		t.Fatalf("archiver.CopyWithTar shouldn't throw an error, %s.", err)
+	}
+	_, err = os.Stat(dest)
+	// FIXME Check the content
+	if err != nil {
+		t.Fatalf("Destination file should be the same as the source.")
+	}
+}
+
+// Test CopyWithTar with a folder as src
+func TestCopyWithTarSrcFolder(t *testing.T) {
+	folder, err := os.MkdirTemp("", "docker-archive-test")
+	if err != nil {
+		t.Fatal(err)
+	}
+	defer os.RemoveAll(folder)
+	dest := filepath.Join(folder, "dest")
+	src := filepath.Join(folder, filepath.Join("src", "folder"))
+	err = os.MkdirAll(src, 0o740)
+	if err != nil {
+		t.Fatal(err)
+	}
+	err = os.MkdirAll(dest, 0o740)
+	if err != nil {
+		t.Fatal(err)
+	}
+	os.WriteFile(filepath.Join(src, "file"), []byte("content"), 0o777)
+	err = defaultCopyWithTar(src, dest)
+	if err != nil {
+		t.Fatalf("archiver.CopyWithTar shouldn't throw an error, %s.", err)
+	}
+	_, err = os.Stat(dest)
+	// FIXME Check the content (the file inside)
+	if err != nil {
+		t.Fatalf("Destination folder should contain the source file but did not.")
+	}
+}
+
+func TestCopyFileWithTarInvalidSrc(t *testing.T) {
+	tempFolder, err := os.MkdirTemp("", "docker-archive-test")
+	if err != nil {
+		t.Fatal(err)
+	}
+	defer os.RemoveAll(tempFolder)
+	destFolder := filepath.Join(tempFolder, "dest")
+	err = os.MkdirAll(destFolder, 0o740)
+	if err != nil {
+		t.Fatal(err)
+	}
+	invalidFile := filepath.Join(tempFolder, "doesnotexists")
+	err = defaultCopyFileWithTar(invalidFile, destFolder)
+	if err == nil {
+		t.Fatalf("archiver.CopyWithTar with invalid src path should throw an error.")
+	}
+}
+
+func TestCopyFileWithTarInexistentDestWillCreateIt(t *testing.T) {
+	tempFolder, err := os.MkdirTemp("", "docker-archive-test")
+	if err != nil {
+		t.Fatal(nil)
+	}
+	defer os.RemoveAll(tempFolder)
+	srcFile := filepath.Join(tempFolder, "src")
+	inexistentDestFolder := filepath.Join(tempFolder, "doesnotexists")
+	f, err := os.Create(srcFile)
+	if assert.Check(t, err) {
+		_ = f.Close()
+	}
+	err = defaultCopyFileWithTar(srcFile, inexistentDestFolder)
+	if err != nil {
+		t.Fatalf("CopyWithTar with an inexistent folder shouldn't fail.")
+	}
+	_, err = os.Stat(inexistentDestFolder)
+	if err != nil {
+		t.Fatalf("CopyWithTar with an inexistent folder should create it.")
+	}
+	// FIXME Test the src file and content
+}
+
+func TestCopyFileWithTarSrcFolder(t *testing.T) {
+	folder, err := os.MkdirTemp("", "docker-archive-copyfilewithtar-test")
+	if err != nil {
+		t.Fatal(err)
+	}
+	defer os.RemoveAll(folder)
+	dest := filepath.Join(folder, "dest")
+	src := filepath.Join(folder, "srcfolder")
+	err = os.MkdirAll(src, 0o740)
+	if err != nil {
+		t.Fatal(err)
+	}
+	err = os.MkdirAll(dest, 0o740)
+	if err != nil {
+		t.Fatal(err)
+	}
+	err = defaultCopyFileWithTar(src, dest)
+	if err == nil {
+		t.Fatalf("CopyFileWithTar should throw an error with a folder.")
+	}
+}
+
+func TestCopyFileWithTarSrcFile(t *testing.T) {
+	folder, err := os.MkdirTemp("", "docker-archive-test")
+	if err != nil {
+		t.Fatal(err)
+	}
+	defer os.RemoveAll(folder)
+	dest := filepath.Join(folder, "dest")
+	srcFolder := filepath.Join(folder, "src")
+	src := filepath.Join(folder, filepath.Join("src", "src"))
+	err = os.MkdirAll(srcFolder, 0o740)
+	if err != nil {
+		t.Fatal(err)
+	}
+	err = os.MkdirAll(dest, 0o740)
+	if err != nil {
+		t.Fatal(err)
+	}
+	os.WriteFile(src, []byte("content"), 0o777)
+	err = defaultCopyWithTar(src, dest+"/")
+	if err != nil {
+		t.Fatalf("archiver.CopyFileWithTar shouldn't throw an error, %s.", err)
+	}
+	_, err = os.Stat(dest)
+	if err != nil {
+		t.Fatalf("Destination folder should contain the source file but did not.")
+	}
+}
+
+func TestTarFiles(t *testing.T) {
+	// try without hardlinks
+	if err := checkNoChanges(1000, false); err != nil {
+		t.Fatal(err)
+	}
+	// try with hardlinks
+	if err := checkNoChanges(1000, true); err != nil {
+		t.Fatal(err)
+	}
+}
+
+func checkNoChanges(fileNum int, hardlinks bool) error {
+	srcDir, err := os.MkdirTemp("", "docker-test-srcDir")
+	if err != nil {
+		return err
+	}
+	defer os.RemoveAll(srcDir)
+
+	destDir, err := os.MkdirTemp("", "docker-test-destDir")
+	if err != nil {
+		return err
+	}
+	defer os.RemoveAll(destDir)
+
+	_, err = prepareUntarSourceDirectory(fileNum, srcDir, hardlinks)
+	if err != nil {
+		return err
+	}
+
+	err = defaultTarUntar(srcDir, destDir)
+	if err != nil {
+		return err
+	}
+
+	changes, err := ChangesDirs(destDir, srcDir)
+	if err != nil {
+		return err
+	}
+	if len(changes) > 0 {
+		return fmt.Errorf("with %d files and %v hardlinks: expected 0 changes, got %d", fileNum, hardlinks, len(changes))
+	}
+	return nil
+}
+
+func tarUntar(t *testing.T, origin string, options *TarOptions) ([]Change, error) {
+	archive, err := TarWithOptions(origin, options)
+	if err != nil {
+		t.Fatal(err)
+	}
+	defer archive.Close()
+
+	buf := make([]byte, 10)
+	if _, err := io.ReadFull(archive, buf); err != nil {
+		return nil, err
+	}
+	wrap := io.MultiReader(bytes.NewReader(buf), archive)
+
+	detectedCompression := DetectCompression(buf)
+	compression := options.Compression
+	if detectedCompression.Extension() != compression.Extension() {
+		return nil, fmt.Errorf("Wrong compression detected. Actual compression: %s, found %s", compression.Extension(), detectedCompression.Extension())
+	}
+
+	tmp, err := os.MkdirTemp("", "docker-test-untar")
+	if err != nil {
+		return nil, err
+	}
+	defer os.RemoveAll(tmp)
+	if err := Untar(wrap, tmp, nil); err != nil {
+		return nil, err
+	}
+	if _, err := os.Stat(tmp); err != nil {
+		return nil, err
+	}
+
+	return ChangesDirs(origin, tmp)
+}
+
+func TestDetectCompressionZstd(t *testing.T) {
+	// test zstd compression without skippable frames.
+	compressedData := []byte{
+		0x28, 0xb5, 0x2f, 0xfd, // magic number of Zstandard frame: 0xFD2FB528
+		0x04, 0x00, 0x31, 0x00, 0x00, // frame header
+		0x64, 0x6f, 0x63, 0x6b, 0x65, 0x72, // data block "docker"
+		0x16, 0x0e, 0x21, 0xc3, // content checksum
+	}
+	compression := DetectCompression(compressedData)
+	if compression != Zstd {
+		t.Fatal("Unexpected compression")
+	}
+	// test zstd compression with skippable frames.
+	hex := []byte{
+		0x50, 0x2a, 0x4d, 0x18, // magic number of skippable frame: 0x184D2A50 to 0x184D2A5F
+		0x04, 0x00, 0x00, 0x00, // frame size
+		0x5d, 0x00, 0x00, 0x00, // user data
+		0x28, 0xb5, 0x2f, 0xfd, // magic number of Zstandard frame: 0xFD2FB528
+		0x04, 0x00, 0x31, 0x00, 0x00, // frame header
+		0x64, 0x6f, 0x63, 0x6b, 0x65, 0x72, // data block "docker"
+		0x16, 0x0e, 0x21, 0xc3, // content checksum
+	}
+	compression = DetectCompression(hex)
+	if compression != Zstd {
+		t.Fatal("Unexpected compression")
+	}
+}
+
+func TestTarUntar(t *testing.T) {
+	origin, err := os.MkdirTemp("", "docker-test-untar-origin")
+	if err != nil {
+		t.Fatal(err)
+	}
+	defer os.RemoveAll(origin)
+	if err := os.WriteFile(filepath.Join(origin, "1"), []byte("hello world"), 0o700); err != nil {
+		t.Fatal(err)
+	}
+	if err := os.WriteFile(filepath.Join(origin, "2"), []byte("welcome!"), 0o700); err != nil {
+		t.Fatal(err)
+	}
+	if err := os.WriteFile(filepath.Join(origin, "3"), []byte("will be ignored"), 0o700); err != nil {
+		t.Fatal(err)
+	}
+
+	for _, c := range []Compression{
+		Uncompressed,
+		Gzip,
+	} {
+		changes, err := tarUntar(t, origin, &TarOptions{
+			Compression:     c,
+			ExcludePatterns: []string{"3"},
+		})
+		if err != nil {
+			t.Fatalf("Error tar/untar for compression %s: %s", c.Extension(), err)
+		}
+
+		if len(changes) != 1 || changes[0].Path != string(filepath.Separator)+"3" {
+			t.Fatalf("Unexpected differences after tarUntar: %v", changes)
+		}
+	}
+}
+
+func TestTarWithOptionsChownOptsAlwaysOverridesIdPair(t *testing.T) {
+	origin, err := os.MkdirTemp("", "docker-test-tar-chown-opt")
+	assert.NilError(t, err)
+
+	defer os.RemoveAll(origin)
+	filePath := filepath.Join(origin, "1")
+	err = os.WriteFile(filePath, []byte("hello world"), 0o700)
+	assert.NilError(t, err)
+
+	idMaps := []idtools.IDMap{
+		0: {
+			ContainerID: 0,
+			HostID:      0,
+			Size:        65536,
+		},
+		1: {
+			ContainerID: 0,
+			HostID:      100000,
+			Size:        65536,
+		},
+	}
+
+	tests := []struct {
+		opts        *TarOptions
+		expectedUID int
+		expectedGID int
+	}{
+		{&TarOptions{ChownOpts: &idtools.Identity{UID: 1337, GID: 42}}, 1337, 42},
+		{&TarOptions{ChownOpts: &idtools.Identity{UID: 100001, GID: 100001}, IDMap: idtools.IdentityMapping{UIDMaps: idMaps, GIDMaps: idMaps}}, 100001, 100001},
+		{&TarOptions{ChownOpts: &idtools.Identity{UID: 0, GID: 0}, NoLchown: false}, 0, 0},
+		{&TarOptions{ChownOpts: &idtools.Identity{UID: 1, GID: 1}, NoLchown: true}, 1, 1},
+		{&TarOptions{ChownOpts: &idtools.Identity{UID: 1000, GID: 1000}, NoLchown: true}, 1000, 1000},
+	}
+	for _, tc := range tests {
+		t.Run("", func(t *testing.T) {
+			reader, err := TarWithOptions(filePath, tc.opts)
+			assert.NilError(t, err)
+			tr := tar.NewReader(reader)
+			defer reader.Close()
+			for {
+				hdr, err := tr.Next()
+				if err == io.EOF {
+					// end of tar archive
+					break
+				}
+				assert.NilError(t, err)
+				assert.Check(t, is.Equal(hdr.Uid, tc.expectedUID), "Uid equals expected value")
+				assert.Check(t, is.Equal(hdr.Gid, tc.expectedGID), "Gid equals expected value")
+			}
+		})
+	}
+}
+
+func TestTarWithOptions(t *testing.T) {
+	origin, err := os.MkdirTemp("", "docker-test-untar-origin")
+	if err != nil {
+		t.Fatal(err)
+	}
+	if _, err := os.MkdirTemp(origin, "folder"); err != nil {
+		t.Fatal(err)
+	}
+	defer os.RemoveAll(origin)
+	if err := os.WriteFile(filepath.Join(origin, "1"), []byte("hello world"), 0o700); err != nil {
+		t.Fatal(err)
+	}
+	if err := os.WriteFile(filepath.Join(origin, "2"), []byte("welcome!"), 0o700); err != nil {
+		t.Fatal(err)
+	}
+
+	tests := []struct {
+		opts       *TarOptions
+		numChanges int
+	}{
+		{&TarOptions{IncludeFiles: []string{"1"}}, 2},
+		{&TarOptions{ExcludePatterns: []string{"2"}}, 1},
+		{&TarOptions{ExcludePatterns: []string{"1", "folder*"}}, 2},
+		{&TarOptions{IncludeFiles: []string{"1", "1"}}, 2},
+		{&TarOptions{IncludeFiles: []string{"1"}, RebaseNames: map[string]string{"1": "test"}}, 4},
+	}
+	for _, tc := range tests {
+		changes, err := tarUntar(t, origin, tc.opts)
+		if err != nil {
+			t.Fatalf("Error tar/untar when testing inclusion/exclusion: %s", err)
+		}
+		if len(changes) != tc.numChanges {
+			t.Errorf("Expected %d changes, got %d for %+v:",
+				tc.numChanges, len(changes), tc.opts)
+		}
+	}
+}
+
+// Some tar archives such as http://haproxy.1wt.eu/download/1.5/src/devel/haproxy-1.5-dev21.tar.gz
+// use PAX Global Extended Headers.
+// Failing prevents the archives from being uncompressed during ADD
+func TestTypeXGlobalHeaderDoesNotFail(t *testing.T) {
+	hdr := tar.Header{Typeflag: tar.TypeXGlobalHeader}
+	tmpDir, err := os.MkdirTemp("", "docker-test-archive-pax-test")
+	if err != nil {
+		t.Fatal(err)
+	}
+	defer os.RemoveAll(tmpDir)
+	err = createTarFile(filepath.Join(tmpDir, "pax_global_header"), tmpDir, &hdr, nil, nil)
+	if err != nil {
+		t.Fatal(err)
+	}
+}
+
+// Some tar have both GNU specific (huge uid) and Ustar specific (long name) things.
+// Not supposed to happen (should use PAX instead of Ustar for long name) but it does and it should still work.
+func TestUntarUstarGnuConflict(t *testing.T) {
+	f, err := os.Open("testdata/broken.tar")
+	if err != nil {
+		t.Fatal(err)
+	}
+	defer f.Close()
+
+	found := false
+	tr := tar.NewReader(f)
+	// Iterate through the files in the archive.
+	for {
+		hdr, err := tr.Next()
+		if err == io.EOF {
+			// end of tar archive
+			break
+		}
+		if err != nil {
+			t.Fatal(err)
+		}
+		if hdr.Name == "root/.cpanm/work/1395823785.24209/Plack-1.0030/blib/man3/Plack::Middleware::LighttpdScriptNameFix.3pm" {
+			found = true
+			break
+		}
+	}
+	if !found {
+		t.Fatalf("%s not found in the archive", "root/.cpanm/work/1395823785.24209/Plack-1.0030/blib/man3/Plack::Middleware::LighttpdScriptNameFix.3pm")
+	}
+}
+
+func prepareUntarSourceDirectory(numberOfFiles int, targetPath string, makeLinks bool) (int, error) {
+	fileData := []byte("fooo")
+	for n := 0; n < numberOfFiles; n++ {
+		fileName := fmt.Sprintf("file-%d", n)
+		if err := os.WriteFile(filepath.Join(targetPath, fileName), fileData, 0o700); err != nil {
+			return 0, err
+		}
+		if makeLinks {
+			if err := os.Link(filepath.Join(targetPath, fileName), filepath.Join(targetPath, fileName+"-link")); err != nil {
+				return 0, err
+			}
+		}
+	}
+	totalSize := numberOfFiles * len(fileData)
+	return totalSize, nil
+}
+
+func BenchmarkTarUntar(b *testing.B) {
+	origin, err := os.MkdirTemp("", "docker-test-untar-origin")
+	if err != nil {
+		b.Fatal(err)
+	}
+	tempDir, err := os.MkdirTemp("", "docker-test-untar-destination")
+	if err != nil {
+		b.Fatal(err)
+	}
+	target := filepath.Join(tempDir, "dest")
+	n, err := prepareUntarSourceDirectory(100, origin, false)
+	if err != nil {
+		b.Fatal(err)
+	}
+	defer os.RemoveAll(origin)
+	defer os.RemoveAll(tempDir)
+
+	b.ResetTimer()
+	b.SetBytes(int64(n))
+	for n := 0; n < b.N; n++ {
+		err := defaultTarUntar(origin, target)
+		if err != nil {
+			b.Fatal(err)
+		}
+		os.RemoveAll(target)
+	}
+}
+
+func BenchmarkTarUntarWithLinks(b *testing.B) {
+	origin, err := os.MkdirTemp("", "docker-test-untar-origin")
+	if err != nil {
+		b.Fatal(err)
+	}
+	tempDir, err := os.MkdirTemp("", "docker-test-untar-destination")
+	if err != nil {
+		b.Fatal(err)
+	}
+	target := filepath.Join(tempDir, "dest")
+	n, err := prepareUntarSourceDirectory(100, origin, true)
+	if err != nil {
+		b.Fatal(err)
+	}
+	defer os.RemoveAll(origin)
+	defer os.RemoveAll(tempDir)
+
+	b.ResetTimer()
+	b.SetBytes(int64(n))
+	for n := 0; n < b.N; n++ {
+		err := defaultTarUntar(origin, target)
+		if err != nil {
+			b.Fatal(err)
+		}
+		os.RemoveAll(target)
+	}
+}
+
+func TestUntarInvalidFilenames(t *testing.T) {
+	for i, headers := range [][]*tar.Header{
+		{
+			{
+				Name:     "../victim/dotdot",
+				Typeflag: tar.TypeReg,
+				Mode:     0o644,
+			},
+		},
+		{
+			{
+				// Note the leading slash
+				Name:     "/../victim/slash-dotdot",
+				Typeflag: tar.TypeReg,
+				Mode:     0o644,
+			},
+		},
+	} {
+		if err := testBreakout("untar", "docker-TestUntarInvalidFilenames", headers); err != nil {
+			t.Fatalf("i=%d. %v", i, err)
+		}
+	}
+}
+
+func TestUntarHardlinkToSymlink(t *testing.T) {
+	skip.If(t, runtime.GOOS != "windows" && os.Getuid() != 0, "skipping test that requires root")
+	for i, headers := range [][]*tar.Header{
+		{
+			{
+				Name:     "symlink1",
+				Typeflag: tar.TypeSymlink,
+				Linkname: "regfile",
+				Mode:     0o644,
+			},
+			{
+				Name:     "symlink2",
+				Typeflag: tar.TypeLink,
+				Linkname: "symlink1",
+				Mode:     0o644,
+			},
+			{
+				Name:     "regfile",
+				Typeflag: tar.TypeReg,
+				Mode:     0o644,
+			},
+		},
+	} {
+		if err := testBreakout("untar", "docker-TestUntarHardlinkToSymlink", headers); err != nil {
+			t.Fatalf("i=%d. %v", i, err)
+		}
+	}
+}
+
+func TestUntarInvalidHardlink(t *testing.T) {
+	for i, headers := range [][]*tar.Header{
+		{ // try reading victim/hello (../)
+			{
+				Name:     "dotdot",
+				Typeflag: tar.TypeLink,
+				Linkname: "../victim/hello",
+				Mode:     0o644,
+			},
+		},
+		{ // try reading victim/hello (/../)
+			{
+				Name:     "slash-dotdot",
+				Typeflag: tar.TypeLink,
+				// Note the leading slash
+				Linkname: "/../victim/hello",
+				Mode:     0o644,
+			},
+		},
+		{ // try writing victim/file
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeLink,
+				Linkname: "../victim",
+				Mode:     0o755,
+			},
+			{
+				Name:     "loophole-victim/file",
+				Typeflag: tar.TypeReg,
+				Mode:     0o644,
+			},
+		},
+		{ // try reading victim/hello (hardlink, symlink)
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeLink,
+				Linkname: "../victim",
+				Mode:     0o755,
+			},
+			{
+				Name:     "symlink",
+				Typeflag: tar.TypeSymlink,
+				Linkname: "loophole-victim/hello",
+				Mode:     0o644,
+			},
+		},
+		{ // Try reading victim/hello (hardlink, hardlink)
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeLink,
+				Linkname: "../victim",
+				Mode:     0o755,
+			},
+			{
+				Name:     "hardlink",
+				Typeflag: tar.TypeLink,
+				Linkname: "loophole-victim/hello",
+				Mode:     0o644,
+			},
+		},
+		{ // Try removing victim directory (hardlink)
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeLink,
+				Linkname: "../victim",
+				Mode:     0o755,
+			},
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeReg,
+				Mode:     0o644,
+			},
+		},
+	} {
+		if err := testBreakout("untar", "docker-TestUntarInvalidHardlink", headers); err != nil {
+			t.Fatalf("i=%d. %v", i, err)
+		}
+	}
+}
+
+func TestUntarInvalidSymlink(t *testing.T) {
+	for i, headers := range [][]*tar.Header{
+		{ // try reading victim/hello (../)
+			{
+				Name:     "dotdot",
+				Typeflag: tar.TypeSymlink,
+				Linkname: "../victim/hello",
+				Mode:     0o644,
+			},
+		},
+		{ // try reading victim/hello (/../)
+			{
+				Name:     "slash-dotdot",
+				Typeflag: tar.TypeSymlink,
+				// Note the leading slash
+				Linkname: "/../victim/hello",
+				Mode:     0o644,
+			},
+		},
+		{ // try writing victim/file
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeSymlink,
+				Linkname: "../victim",
+				Mode:     0o755,
+			},
+			{
+				Name:     "loophole-victim/file",
+				Typeflag: tar.TypeReg,
+				Mode:     0o644,
+			},
+		},
+		{ // try reading victim/hello (symlink, symlink)
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeSymlink,
+				Linkname: "../victim",
+				Mode:     0o755,
+			},
+			{
+				Name:     "symlink",
+				Typeflag: tar.TypeSymlink,
+				Linkname: "loophole-victim/hello",
+				Mode:     0o644,
+			},
+		},
+		{ // try reading victim/hello (symlink, hardlink)
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeSymlink,
+				Linkname: "../victim",
+				Mode:     0o755,
+			},
+			{
+				Name:     "hardlink",
+				Typeflag: tar.TypeLink,
+				Linkname: "loophole-victim/hello",
+				Mode:     0o644,
+			},
+		},
+		{ // try removing victim directory (symlink)
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeSymlink,
+				Linkname: "../victim",
+				Mode:     0o755,
+			},
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeReg,
+				Mode:     0o644,
+			},
+		},
+		{ // try writing to victim/newdir/newfile with a symlink in the path
+			{
+				// this header needs to be before the next one, or else there is an error
+				Name:     "dir/loophole",
+				Typeflag: tar.TypeSymlink,
+				Linkname: "../../victim",
+				Mode:     0o755,
+			},
+			{
+				Name:     "dir/loophole/newdir/newfile",
+				Typeflag: tar.TypeReg,
+				Mode:     0o644,
+			},
+		},
+	} {
+		if err := testBreakout("untar", "docker-TestUntarInvalidSymlink", headers); err != nil {
+			t.Fatalf("i=%d. %v", i, err)
+		}
+	}
+}
+
+func TestTempArchiveCloseMultipleTimes(t *testing.T) {
+	reader := io.NopCloser(strings.NewReader("hello"))
+	tmpArchive, err := newTempArchive(reader, "")
+	assert.NilError(t, err)
+	buf := make([]byte, 10)
+	n, err := tmpArchive.Read(buf)
+	assert.NilError(t, err)
+	if n != 5 {
+		t.Fatalf("Expected to read 5 bytes. Read %d instead", n)
+	}
+	for i := 0; i < 3; i++ {
+		if err = tmpArchive.Close(); err != nil {
+			t.Fatalf("i=%d. Unexpected error closing temp archive: %v", i, err)
+		}
+	}
+}
+
+// TestXGlobalNoParent is a regression test to check parent directories are not created for PAX headers
+func TestXGlobalNoParent(t *testing.T) {
+	buf := &bytes.Buffer{}
+	w := tar.NewWriter(buf)
+	err := w.WriteHeader(&tar.Header{
+		Name:     "foo/bar",
+		Typeflag: tar.TypeXGlobalHeader,
+	})
+	assert.NilError(t, err)
+	tmpDir, err := os.MkdirTemp("", "pax-test")
+	assert.NilError(t, err)
+	defer os.RemoveAll(tmpDir)
+	err = Untar(buf, tmpDir, nil)
+	assert.NilError(t, err)
+
+	_, err = os.Lstat(filepath.Join(tmpDir, "foo"))
+	assert.Check(t, err != nil)
+	assert.Check(t, is.ErrorIs(err, os.ErrNotExist))
+}
+
+// TestImpliedDirectoryPermissions ensures that directories implied by paths in the tar file, but without their own
+// header entries are created recursively with the default mode (permissions) stored in ImpliedDirectoryMode. This test
+// also verifies that the permissions of explicit directories are respected.
+func TestImpliedDirectoryPermissions(t *testing.T) {
+	skip.If(t, runtime.GOOS == "windows", "skipping test that requires Unix permissions")
+
+	buf := &bytes.Buffer{}
+	headers := []tar.Header{{
+		Name: "deeply/nested/and/implied",
+	}, {
+		Name: "explicit/",
+		Mode: 0o644,
+	}, {
+		Name: "explicit/permissions/",
+		Mode: 0o600,
+	}, {
+		Name: "explicit/permissions/specified",
+		Mode: 0o400,
+	}}
+
+	w := tar.NewWriter(buf)
+	for _, header := range headers {
+		err := w.WriteHeader(&header)
+		assert.NilError(t, err)
+	}
+
+	tmpDir := t.TempDir()
+
+	err := Untar(buf, tmpDir, nil)
+	assert.NilError(t, err)
+
+	assertMode := func(path string, expected uint32) {
+		t.Helper()
+		stat, err := os.Lstat(filepath.Join(tmpDir, path))
+		assert.Check(t, err)
+		assert.Check(t, is.Equal(stat.Mode().Perm(), fs.FileMode(expected)))
+	}
+
+	assertMode("deeply", ImpliedDirectoryMode)
+	assertMode("deeply/nested", ImpliedDirectoryMode)
+	assertMode("deeply/nested/and", ImpliedDirectoryMode)
+
+	assertMode("explicit", 0o644)
+	assertMode("explicit/permissions", 0o600)
+	assertMode("explicit/permissions/specified", 0o400)
+}
+
+func TestReplaceFileTarWrapper(t *testing.T) {
+	filesInArchive := 20
+	tests := []struct {
+		doc       string
+		filename  string
+		modifier  TarModifierFunc
+		expected  string
+		fileCount int
+	}{
+		{
+			doc:       "Modifier creates a new file",
+			filename:  "newfile",
+			modifier:  createModifier(t),
+			expected:  "the new content",
+			fileCount: filesInArchive + 1,
+		},
+		{
+			doc:       "Modifier replaces a file",
+			filename:  "file-2",
+			modifier:  createOrReplaceModifier,
+			expected:  "the new content",
+			fileCount: filesInArchive,
+		},
+		{
+			doc:       "Modifier replaces the last file",
+			filename:  fmt.Sprintf("file-%d", filesInArchive-1),
+			modifier:  createOrReplaceModifier,
+			expected:  "the new content",
+			fileCount: filesInArchive,
+		},
+		{
+			doc:       "Modifier appends to a file",
+			filename:  "file-3",
+			modifier:  appendModifier,
+			expected:  "fooo\nnext line",
+			fileCount: filesInArchive,
+		},
+	}
+
+	for _, tc := range tests {
+		sourceArchive, cleanup := buildSourceArchive(t, filesInArchive)
+		defer cleanup()
+
+		resultArchive := ReplaceFileTarWrapper(
+			sourceArchive,
+			map[string]TarModifierFunc{tc.filename: tc.modifier})
+
+		actual := readFileFromArchive(t, resultArchive, tc.filename, tc.fileCount, tc.doc)
+		assert.Check(t, is.Equal(tc.expected, actual), tc.doc)
+	}
+}
+
+// TestPrefixHeaderReadable tests that files that could be created with the
+// version of this package that was built with <=go17 are still readable.
+func TestPrefixHeaderReadable(t *testing.T) {
+	skip.If(t, runtime.GOOS != "windows" && os.Getuid() != 0, "skipping test that requires root")
+	skip.If(t, userns.RunningInUserNS(), "skipping test that requires more than 010000000 UIDs, which is unlikely to be satisfied when running in userns")
+	// https://gist.github.com/stevvooe/e2a790ad4e97425896206c0816e1a882#file-out-go
+	testFile := []byte("\x1f\x8b\x08\x08\x44\x21\x68\x59\x00\x03\x74\x2e\x74\x61\x72\x00\x4b\xcb\xcf\x67\xa0\x35\x30\x80\x00\x86\x06\x10\x47\x01\xc1\x37\x40\x00\x54\xb6\xb1\xa1\xa9\x99\x09\x48\x25\x1d\x40\x69\x71\x49\x62\x91\x02\xe5\x76\xa1\x79\x84\x21\x91\xd6\x80\x72\xaf\x8f\x82\x51\x30\x0a\x46\x36\x00\x00\xf0\x1c\x1e\x95\x00\x06\x00\x00")
+
+	tmpDir, err := os.MkdirTemp("", "prefix-test")
+	assert.NilError(t, err)
+	defer os.RemoveAll(tmpDir)
+	err = Untar(bytes.NewReader(testFile), tmpDir, nil)
+	assert.NilError(t, err)
+
+	baseName := "foo"
+	pth := strings.Repeat("a", 100-len(baseName)) + "/" + baseName
+
+	_, err = os.Lstat(filepath.Join(tmpDir, pth))
+	assert.NilError(t, err)
+}
+
+func buildSourceArchive(t *testing.T, numberOfFiles int) (io.ReadCloser, func()) {
+	srcDir, err := os.MkdirTemp("", "docker-test-srcDir")
+	assert.NilError(t, err)
+
+	_, err = prepareUntarSourceDirectory(numberOfFiles, srcDir, false)
+	assert.NilError(t, err)
+
+	sourceArchive, err := TarWithOptions(srcDir, &TarOptions{})
+	assert.NilError(t, err)
+	return sourceArchive, func() {
+		os.RemoveAll(srcDir)
+		sourceArchive.Close()
+	}
+}
+
+func createOrReplaceModifier(path string, header *tar.Header, content io.Reader) (*tar.Header, []byte, error) {
+	return &tar.Header{
+		Mode:     0o600,
+		Typeflag: tar.TypeReg,
+	}, []byte("the new content"), nil
+}
+
+func createModifier(t *testing.T) TarModifierFunc {
+	return func(path string, header *tar.Header, content io.Reader) (*tar.Header, []byte, error) {
+		assert.Check(t, is.Nil(content))
+		return createOrReplaceModifier(path, header, content)
+	}
+}
+
+func appendModifier(path string, header *tar.Header, content io.Reader) (*tar.Header, []byte, error) {
+	buffer := bytes.Buffer{}
+	if content != nil {
+		if _, err := buffer.ReadFrom(content); err != nil {
+			return nil, nil, err
+		}
+	}
+	buffer.WriteString("\nnext line")
+	return &tar.Header{Mode: 0o600, Typeflag: tar.TypeReg}, buffer.Bytes(), nil
+}
+
+func readFileFromArchive(t *testing.T, archive io.ReadCloser, name string, expectedCount int, doc string) string {
+	skip.If(t, runtime.GOOS != "windows" && os.Getuid() != 0, "skipping test that requires root")
+	destDir, err := os.MkdirTemp("", "docker-test-destDir")
+	assert.NilError(t, err)
+	defer os.RemoveAll(destDir)
+
+	err = Untar(archive, destDir, nil)
+	assert.NilError(t, err)
+
+	files, _ := os.ReadDir(destDir)
+	assert.Check(t, is.Len(files, expectedCount), doc)
+
+	content, err := os.ReadFile(filepath.Join(destDir, name))
+	assert.Check(t, err)
+	return string(content)
+}
+
+func TestDisablePigz(t *testing.T) {
+	_, err := exec.LookPath("unpigz")
+	if err != nil {
+		t.Log("Test will not check full path when Pigz not installed")
+	}
+
+	t.Setenv("MOBY_DISABLE_PIGZ", "true")
+
+	r := testDecompressStream(t, "gz", "gzip -f")
+
+	// wrapped in closer to cancel contex and release buffer to pool
+	wrapper := r.(*readCloserWrapper)
+
+	assert.Equal(t, reflect.TypeOf(wrapper.Reader), reflect.TypeOf(&gzip.Reader{}))
+}
+
+func TestPigz(t *testing.T) {
+	r := testDecompressStream(t, "gz", "gzip -f")
+	// wrapper for buffered reader and context cancel
+	wrapper := r.(*readCloserWrapper)
+
+	_, err := exec.LookPath("unpigz")
+	if err == nil {
+		t.Log("Tested whether Pigz is used, as it installed")
+		// For the command wait wrapper
+		cmdWaitCloserWrapper := wrapper.Reader.(*readCloserWrapper)
+		assert.Equal(t, reflect.TypeOf(cmdWaitCloserWrapper.Reader), reflect.TypeOf(&io.PipeReader{}))
+	} else {
+		t.Log("Tested whether Pigz is not used, as it not installed")
+		assert.Equal(t, reflect.TypeOf(wrapper.Reader), reflect.TypeOf(&gzip.Reader{}))
+	}
+}
+
+func TestNosysFileInfo(t *testing.T) {
+	st, err := os.Stat("archive_test.go")
+	assert.NilError(t, err)
+	h, err := tar.FileInfoHeader(nosysFileInfo{st}, "")
+	assert.NilError(t, err)
+	assert.Check(t, h.Uname == "")
+	assert.Check(t, h.Gname == "")
+}
diff --git a/vendor/github.com/moby/go-archive/archive_unix.go b/pkg/archive/archive_unix.go
similarity index 93%
rename from vendor/github.com/moby/go-archive/archive_unix.go
rename to pkg/archive/archive_unix.go
index 715ac4c672..bc6b25ae07 100644
--- a/vendor/github.com/moby/go-archive/archive_unix.go
+++ b/pkg/archive/archive_unix.go
@@ -11,6 +11,7 @@ import (
 	"strings"
 	"syscall"
 
+	"github.com/docker/docker/pkg/idtools"
 	"golang.org/x/sys/unix"
 )
 
@@ -81,13 +82,13 @@ func getInodeFromStat(stat interface{}) (uint64, error) {
 	return s.Ino, nil
 }
 
-func getFileUIDGID(stat interface{}) (int, int, error) {
+func getFileUIDGID(stat interface{}) (idtools.Identity, error) {
 	s, ok := stat.(*syscall.Stat_t)
 
 	if !ok {
-		return 0, 0, errors.New("cannot convert stat value to syscall.Stat_t")
+		return idtools.Identity{}, errors.New("cannot convert stat value to syscall.Stat_t")
 	}
-	return int(s.Uid), int(s.Gid), nil
+	return idtools.Identity{UID: int(s.Uid), GID: int(s.Gid)}, nil
 }
 
 // handleTarTypeBlockCharFifo is an OS-specific helper function used by
diff --git a/pkg/archive/archive_unix_test.go b/pkg/archive/archive_unix_test.go
new file mode 100644
index 0000000000..3d63436033
--- /dev/null
+++ b/pkg/archive/archive_unix_test.go
@@ -0,0 +1,351 @@
+//go:build !windows
+
+package archive
+
+import (
+	"archive/tar"
+	"bytes"
+	"fmt"
+	"io"
+	"os"
+	"os/exec"
+	"path/filepath"
+	"strings"
+	"syscall"
+	"testing"
+
+	"github.com/moby/sys/userns"
+	"golang.org/x/sys/unix"
+	"gotest.tools/v3/assert"
+	is "gotest.tools/v3/assert/cmp"
+	"gotest.tools/v3/skip"
+)
+
+func TestCanonicalTarName(t *testing.T) {
+	cases := []struct {
+		in       string
+		isDir    bool
+		expected string
+	}{
+		{"foo", false, "foo"},
+		{"foo", true, "foo/"},
+		{"foo/bar", false, "foo/bar"},
+		{"foo/bar", true, "foo/bar/"},
+	}
+	for _, v := range cases {
+		if canonicalTarName(v.in, v.isDir) != v.expected {
+			t.Fatalf("wrong canonical tar name. expected:%s got:%s", v.expected, canonicalTarName(v.in, v.isDir))
+		}
+	}
+}
+
+func TestChmodTarEntry(t *testing.T) {
+	cases := []struct {
+		in, expected os.FileMode
+	}{
+		{0o000, 0o000},
+		{0o777, 0o777},
+		{0o644, 0o644},
+		{0o755, 0o755},
+		{0o444, 0o444},
+	}
+	for _, v := range cases {
+		if out := chmodTarEntry(v.in); out != v.expected {
+			t.Fatalf("wrong chmod. expected:%v got:%v", v.expected, out)
+		}
+	}
+}
+
+func TestTarWithHardLink(t *testing.T) {
+	origin, err := os.MkdirTemp("", "docker-test-tar-hardlink")
+	assert.NilError(t, err)
+	defer os.RemoveAll(origin)
+
+	err = os.WriteFile(filepath.Join(origin, "1"), []byte("hello world"), 0o700)
+	assert.NilError(t, err)
+
+	err = os.Link(filepath.Join(origin, "1"), filepath.Join(origin, "2"))
+	assert.NilError(t, err)
+
+	var i1, i2 uint64
+	i1, err = getNlink(filepath.Join(origin, "1"))
+	assert.NilError(t, err)
+
+	// sanity check that we can hardlink
+	if i1 != 2 {
+		t.Skipf("skipping since hardlinks don't work here; expected 2 links, got %d", i1)
+	}
+
+	dest, err := os.MkdirTemp("", "docker-test-tar-hardlink-dest")
+	assert.NilError(t, err)
+	defer os.RemoveAll(dest)
+
+	// we'll do this in two steps to separate failure
+	fh, err := Tar(origin, Uncompressed)
+	assert.NilError(t, err)
+
+	// ensure we can read the whole thing with no error, before writing back out
+	buf, err := io.ReadAll(fh)
+	assert.NilError(t, err)
+
+	bRdr := bytes.NewReader(buf)
+	err = Untar(bRdr, dest, &TarOptions{Compression: Uncompressed})
+	assert.NilError(t, err)
+
+	i1, err = getInode(filepath.Join(dest, "1"))
+	assert.NilError(t, err)
+
+	i2, err = getInode(filepath.Join(dest, "2"))
+	assert.NilError(t, err)
+
+	assert.Check(t, is.Equal(i1, i2))
+}
+
+func TestTarWithHardLinkAndRebase(t *testing.T) {
+	tmpDir, err := os.MkdirTemp("", "docker-test-tar-hardlink-rebase")
+	assert.NilError(t, err)
+	defer os.RemoveAll(tmpDir)
+
+	origin := filepath.Join(tmpDir, "origin")
+	err = os.Mkdir(origin, 0o700)
+	assert.NilError(t, err)
+
+	err = os.WriteFile(filepath.Join(origin, "1"), []byte("hello world"), 0o700)
+	assert.NilError(t, err)
+
+	err = os.Link(filepath.Join(origin, "1"), filepath.Join(origin, "2"))
+	assert.NilError(t, err)
+
+	var i1, i2 uint64
+	i1, err = getNlink(filepath.Join(origin, "1"))
+	assert.NilError(t, err)
+
+	// sanity check that we can hardlink
+	if i1 != 2 {
+		t.Skipf("skipping since hardlinks don't work here; expected 2 links, got %d", i1)
+	}
+
+	dest := filepath.Join(tmpDir, "dest")
+	bRdr, err := TarResourceRebase(origin, "origin")
+	assert.NilError(t, err)
+
+	dstDir, srcBase := SplitPathDirEntry(origin)
+	_, dstBase := SplitPathDirEntry(dest)
+	content := RebaseArchiveEntries(bRdr, srcBase, dstBase)
+	err = Untar(content, dstDir, &TarOptions{Compression: Uncompressed, NoLchown: true, NoOverwriteDirNonDir: true})
+	assert.NilError(t, err)
+
+	i1, err = getInode(filepath.Join(dest, "1"))
+	assert.NilError(t, err)
+	i2, err = getInode(filepath.Join(dest, "2"))
+	assert.NilError(t, err)
+
+	assert.Check(t, is.Equal(i1, i2))
+}
+
+// TestUntarParentPathPermissions is a regression test to check that missing
+// parent directories are created with the expected permissions
+func TestUntarParentPathPermissions(t *testing.T) {
+	skip.If(t, os.Getuid() != 0, "skipping test that requires root")
+	buf := &bytes.Buffer{}
+	w := tar.NewWriter(buf)
+	err := w.WriteHeader(&tar.Header{Name: "foo/bar"})
+	assert.NilError(t, err)
+	tmpDir, err := os.MkdirTemp("", t.Name())
+	assert.NilError(t, err)
+	defer os.RemoveAll(tmpDir)
+	err = Untar(buf, tmpDir, nil)
+	assert.NilError(t, err)
+
+	fi, err := os.Lstat(filepath.Join(tmpDir, "foo"))
+	assert.NilError(t, err)
+	assert.Equal(t, fi.Mode(), 0o755|os.ModeDir)
+}
+
+func getNlink(path string) (uint64, error) {
+	stat, err := os.Stat(path)
+	if err != nil {
+		return 0, err
+	}
+	statT, ok := stat.Sys().(*syscall.Stat_t)
+	if !ok {
+		return 0, fmt.Errorf("expected type *syscall.Stat_t, got %t", stat.Sys())
+	}
+	// We need this conversion on ARM64
+	//nolint: unconvert
+	return uint64(statT.Nlink), nil
+}
+
+func getInode(path string) (uint64, error) {
+	stat, err := os.Stat(path)
+	if err != nil {
+		return 0, err
+	}
+	statT, ok := stat.Sys().(*syscall.Stat_t)
+	if !ok {
+		return 0, fmt.Errorf("expected type *syscall.Stat_t, got %t", stat.Sys())
+	}
+	return statT.Ino, nil
+}
+
+func TestTarWithBlockCharFifo(t *testing.T) {
+	skip.If(t, os.Getuid() != 0, "skipping test that requires root")
+	skip.If(t, userns.RunningInUserNS(), "skipping test that requires initial userns")
+	origin, err := os.MkdirTemp("", "docker-test-tar-hardlink")
+	assert.NilError(t, err)
+
+	defer os.RemoveAll(origin)
+	err = os.WriteFile(filepath.Join(origin, "1"), []byte("hello world"), 0o700)
+	assert.NilError(t, err)
+
+	err = mknod(filepath.Join(origin, "2"), unix.S_IFBLK, unix.Mkdev(uint32(12), uint32(5)))
+	assert.NilError(t, err)
+	err = mknod(filepath.Join(origin, "3"), unix.S_IFCHR, unix.Mkdev(uint32(12), uint32(5)))
+	assert.NilError(t, err)
+	err = mknod(filepath.Join(origin, "4"), unix.S_IFIFO, unix.Mkdev(uint32(12), uint32(5)))
+	assert.NilError(t, err)
+
+	dest, err := os.MkdirTemp("", "docker-test-tar-hardlink-dest")
+	assert.NilError(t, err)
+	defer os.RemoveAll(dest)
+
+	// we'll do this in two steps to separate failure
+	fh, err := Tar(origin, Uncompressed)
+	assert.NilError(t, err)
+
+	// ensure we can read the whole thing with no error, before writing back out
+	buf, err := io.ReadAll(fh)
+	assert.NilError(t, err)
+
+	bRdr := bytes.NewReader(buf)
+	err = Untar(bRdr, dest, &TarOptions{Compression: Uncompressed})
+	assert.NilError(t, err)
+
+	changes, err := ChangesDirs(origin, dest)
+	assert.NilError(t, err)
+
+	if len(changes) > 0 {
+		t.Fatalf("Tar with special device (block, char, fifo) should keep them (recreate them when untar) : %v", changes)
+	}
+}
+
+// TestTarUntarWithXattr is Unix as Lsetxattr is not supported on Windows
+func TestTarUntarWithXattr(t *testing.T) {
+	skip.If(t, os.Getuid() != 0, "skipping test that requires root")
+	if _, err := exec.LookPath("setcap"); err != nil {
+		t.Skip("setcap not installed")
+	}
+	if _, err := exec.LookPath("getcap"); err != nil {
+		t.Skip("getcap not installed")
+	}
+
+	origin, err := os.MkdirTemp("", "docker-test-untar-origin")
+	assert.NilError(t, err)
+	defer os.RemoveAll(origin)
+	err = os.WriteFile(filepath.Join(origin, "1"), []byte("hello world"), 0o700)
+	assert.NilError(t, err)
+
+	err = os.WriteFile(filepath.Join(origin, "2"), []byte("welcome!"), 0o700)
+	assert.NilError(t, err)
+	err = os.WriteFile(filepath.Join(origin, "3"), []byte("will be ignored"), 0o700)
+	assert.NilError(t, err)
+	// there is no known Go implementation of setcap/getcap with support for v3 file capability
+	out, err := exec.Command("setcap", "cap_block_suspend+ep", filepath.Join(origin, "2")).CombinedOutput()
+	assert.NilError(t, err, string(out))
+
+	tarball, err := Tar(origin, Uncompressed)
+	assert.NilError(t, err)
+	defer tarball.Close()
+	rdr := tar.NewReader(tarball)
+	for {
+		h, err := rdr.Next()
+		if err == io.EOF {
+			break
+		}
+		assert.NilError(t, err)
+		capability, hasxattr := h.PAXRecords["SCHILY.xattr.security.capability"]
+		switch h.Name {
+		case "2":
+			if assert.Check(t, hasxattr, "tar entry %q should have the 'security.capability' xattr", h.Name) {
+				assert.Check(t, len(capability) > 0, "tar entry %q has a blank 'security.capability' xattr value")
+			}
+		default:
+			assert.Check(t, !hasxattr, "tar entry %q should not have the 'security.capability' xattr", h.Name)
+		}
+	}
+
+	for _, c := range []Compression{
+		Uncompressed,
+		Gzip,
+	} {
+		changes, err := tarUntar(t, origin, &TarOptions{
+			Compression:     c,
+			ExcludePatterns: []string{"3"},
+		})
+		if err != nil {
+			t.Fatalf("Error tar/untar for compression %s: %s", c.Extension(), err)
+		}
+
+		if len(changes) != 1 || changes[0].Path != "/3" {
+			t.Fatalf("Unexpected differences after tarUntar: %v", changes)
+		}
+		out, err := exec.Command("getcap", filepath.Join(origin, "2")).CombinedOutput()
+		assert.NilError(t, err, string(out))
+		assert.Check(t, is.Contains(string(out), "cap_block_suspend=ep"), "untar should have kept the 'security.capability' xattr")
+	}
+}
+
+func TestCopyInfoDestinationPathSymlink(t *testing.T) {
+	tmpDir, _ := getTestTempDirs(t)
+	defer removeAllPaths(tmpDir)
+
+	root := strings.TrimRight(tmpDir, "/") + "/"
+
+	type FileTestData struct {
+		resource FileData
+		file     string
+		expected CopyInfo
+	}
+
+	testData := []FileTestData{
+		// Create a directory: /tmp/archive-copy-test*/dir1
+		// Test will "copy" file1 to dir1
+		{resource: FileData{filetype: Dir, path: "dir1", permissions: 0o740}, file: "file1", expected: CopyInfo{Path: root + "dir1/file1", Exists: false, IsDir: false}},
+
+		// Create a symlink directory to dir1: /tmp/archive-copy-test*/dirSymlink -> dir1
+		// Test will "copy" file2 to dirSymlink
+		{resource: FileData{filetype: Symlink, path: "dirSymlink", contents: root + "dir1", permissions: 0o600}, file: "file2", expected: CopyInfo{Path: root + "dirSymlink/file2", Exists: false, IsDir: false}},
+
+		// Create a file in tmp directory: /tmp/archive-copy-test*/file1
+		// Test to cover when the full file path already exists.
+		{resource: FileData{filetype: Regular, path: "file1", permissions: 0o600}, file: "", expected: CopyInfo{Path: root + "file1", Exists: true}},
+
+		// Create a directory: /tmp/archive-copy*/dir2
+		// Test to cover when the full directory path already exists
+		{resource: FileData{filetype: Dir, path: "dir2", permissions: 0o740}, file: "", expected: CopyInfo{Path: root + "dir2", Exists: true, IsDir: true}},
+
+		// Create a symlink to a non-existent target: /tmp/archive-copy*/symlink1 -> noSuchTarget
+		// Negative test to cover symlinking to a target that does not exit
+		{resource: FileData{filetype: Symlink, path: "symlink1", contents: "noSuchTarget", permissions: 0o600}, file: "", expected: CopyInfo{Path: root + "noSuchTarget", Exists: false}},
+
+		// Create a file in tmp directory for next test: /tmp/existingfile
+		{resource: FileData{filetype: Regular, path: "existingfile", permissions: 0o600}, file: "", expected: CopyInfo{Path: root + "existingfile", Exists: true}},
+
+		// Create a symlink to an existing file: /tmp/archive-copy*/symlink2 -> /tmp/existingfile
+		// Test to cover when the parent directory of a new file is a symlink
+		{resource: FileData{filetype: Symlink, path: "symlink2", contents: "existingfile", permissions: 0o600}, file: "", expected: CopyInfo{Path: root + "existingfile", Exists: true}},
+	}
+
+	var dirs []FileData
+	for _, data := range testData {
+		dirs = append(dirs, data.resource)
+	}
+	provisionSampleDir(t, tmpDir, dirs)
+
+	for _, info := range testData {
+		p := filepath.Join(tmpDir, info.resource.path, info.file)
+		ci, err := CopyInfoDestinationPath(p)
+		assert.Check(t, err)
+		assert.Check(t, is.DeepEqual(info.expected, ci))
+	}
+}
diff --git a/vendor/github.com/moby/go-archive/archive_windows.go b/pkg/archive/archive_windows.go
similarity index 92%
rename from vendor/github.com/moby/go-archive/archive_windows.go
rename to pkg/archive/archive_windows.go
index 108ee5d1fc..fd2546eab7 100644
--- a/vendor/github.com/moby/go-archive/archive_windows.go
+++ b/pkg/archive/archive_windows.go
@@ -5,6 +5,8 @@ import (
 	"os"
 	"path/filepath"
 	"strings"
+
+	"github.com/docker/docker/pkg/idtools"
 )
 
 // longPathPrefix is the longpath prefix for Windows file paths.
@@ -61,7 +63,7 @@ func handleLChmod(hdr *tar.Header, path string, hdrInfo os.FileInfo) error {
 	return nil
 }
 
-func getFileUIDGID(stat interface{}) (int, int, error) {
+func getFileUIDGID(stat interface{}) (idtools.Identity, error) {
 	// no notion of file ownership mapping yet on Windows
-	return 0, 0, nil
+	return idtools.Identity{UID: 0, GID: 0}, nil
 }
diff --git a/pkg/archive/archive_windows_test.go b/pkg/archive/archive_windows_test.go
new file mode 100644
index 0000000000..79c6cdf348
--- /dev/null
+++ b/pkg/archive/archive_windows_test.go
@@ -0,0 +1,68 @@
+//go:build windows
+
+package archive
+
+import (
+	"os"
+	"path/filepath"
+	"testing"
+)
+
+func TestCopyFileWithInvalidDest(t *testing.T) {
+	// TODO Windows: This is currently failing. Not sure what has
+	// recently changed in CopyWithTar as used to pass. Further investigation
+	// is required.
+	t.Skip("Currently fails")
+	folder, err := os.MkdirTemp("", "docker-archive-test")
+	if err != nil {
+		t.Fatal(err)
+	}
+	defer os.RemoveAll(folder)
+	dest := "c:dest"
+	srcFolder := filepath.Join(folder, "src")
+	src := filepath.Join(folder, "src", "src")
+	err = os.MkdirAll(srcFolder, 0o740)
+	if err != nil {
+		t.Fatal(err)
+	}
+	os.WriteFile(src, []byte("content"), 0o777)
+	err = defaultCopyWithTar(src, dest)
+	if err == nil {
+		t.Fatalf("archiver.CopyWithTar should throw an error on invalid dest.")
+	}
+}
+
+func TestCanonicalTarName(t *testing.T) {
+	cases := []struct {
+		in       string
+		isDir    bool
+		expected string
+	}{
+		{"foo", false, "foo"},
+		{"foo", true, "foo/"},
+		{`foo\bar`, false, "foo/bar"},
+		{`foo\bar`, true, "foo/bar/"},
+	}
+	for _, v := range cases {
+		if canonicalTarName(v.in, v.isDir) != v.expected {
+			t.Fatalf("wrong canonical tar name. expected:%s got:%s", v.expected, canonicalTarName(v.in, v.isDir))
+		}
+	}
+}
+
+func TestChmodTarEntry(t *testing.T) {
+	cases := []struct {
+		in, expected os.FileMode
+	}{
+		{0o000, 0o111},
+		{0o777, 0o755},
+		{0o644, 0o755},
+		{0o755, 0o755},
+		{0o444, 0o555},
+	}
+	for _, v := range cases {
+		if out := chmodTarEntry(v.in); out != v.expected {
+			t.Fatalf("wrong chmod. expected:%v got:%v", v.expected, out)
+		}
+	}
+}
diff --git a/vendor/github.com/moby/go-archive/changes.go b/pkg/archive/changes.go
similarity index 97%
rename from vendor/github.com/moby/go-archive/changes.go
rename to pkg/archive/changes.go
index 036a1b0985..5d14f3a28e 100644
--- a/vendor/github.com/moby/go-archive/changes.go
+++ b/pkg/archive/changes.go
@@ -14,7 +14,7 @@ import (
 	"time"
 
 	"github.com/containerd/log"
-	"github.com/moby/sys/user"
+	"github.com/docker/docker/pkg/idtools"
 )
 
 // ChangeType represents the change type.
@@ -75,7 +75,7 @@ func sameFsTime(a, b time.Time) bool {
 // Changes walks the path rw and determines changes for the files in the path,
 // with respect to the parent layers
 func Changes(layers []string, rw string) ([]Change, error) {
-	return changes(layers, rw, aufsDeletedFile, aufsMetadataSkip)
+	return collectChanges(layers, rw, aufsDeletedFile, aufsMetadataSkip)
 }
 
 func aufsMetadataSkip(path string) (skip bool, err error) {
@@ -103,7 +103,7 @@ type (
 	deleteChange func(string, string, os.FileInfo) (string, error)
 )
 
-func changes(layers []string, rw string, dc deleteChange, sc skipChange) ([]Change, error) {
+func collectChanges(layers []string, rw string, dc deleteChange, sc skipChange) ([]Change, error) {
 	var (
 		changes     []Change
 		changedDirs = make(map[string]struct{})
@@ -383,7 +383,7 @@ func ChangesSize(newDir string, changes []Change) int64 {
 }
 
 // ExportChanges produces an Archive from the provided changes, relative to dir.
-func ExportChanges(dir string, changes []Change, idMap user.IdentityMapping) (io.ReadCloser, error) {
+func ExportChanges(dir string, changes []Change, idMap idtools.IdentityMapping) (io.ReadCloser, error) {
 	reader, writer := io.Pipe()
 	go func() {
 		ta := newTarAppender(idMap, writer, nil)
diff --git a/pkg/archive/changes_deprecated.go b/pkg/archive/changes_deprecated.go
deleted file mode 100644
index 48c75235c3..0000000000
--- a/pkg/archive/changes_deprecated.go
+++ /dev/null
@@ -1,56 +0,0 @@
-package archive
-
-import (
-	"io"
-
-	"github.com/docker/docker/pkg/idtools"
-	"github.com/moby/go-archive"
-)
-
-// ChangeType represents the change
-//
-// Deprecated: use [archive.ChangeType] instead.
-type ChangeType = archive.ChangeType
-
-const (
-	ChangeModify = archive.ChangeModify // Deprecated: use [archive.ChangeModify] instead.
-	ChangeAdd    = archive.ChangeAdd    // Deprecated: use [archive.ChangeAdd] instead.
-	ChangeDelete = archive.ChangeDelete // Deprecated: use [archive.ChangeDelete] instead.
-)
-
-// Change represents a change.
-//
-// Deprecated: use [archive.Change] instead.
-type Change = archive.Change
-
-// Changes walks the path rw and determines changes for the files in the path,
-// with respect to the parent layers
-//
-// Deprecated: use [archive.Changes] instead.
-func Changes(layers []string, rw string) ([]archive.Change, error) {
-	return archive.Changes(layers, rw)
-}
-
-// FileInfo describes the information of a file.
-//
-// Deprecated: use [archive.FileInfo] instead.
-type FileInfo = archive.FileInfo
-
-// ChangesDirs compares two directories and generates an array of Change objects describing the changes.
-//
-// Deprecated: use [archive.ChangesDirs] instead.
-func ChangesDirs(newDir, oldDir string) ([]archive.Change, error) {
-	return archive.ChangesDirs(newDir, oldDir)
-}
-
-// ChangesSize calculates the size in bytes of the provided changes, based on newDir.
-//
-// Deprecated: use [archive.ChangesSize] instead.
-func ChangesSize(newDir string, changes []archive.Change) int64 {
-	return archive.ChangesSize(newDir, changes)
-}
-
-// ExportChanges produces an Archive from the provided changes, relative to dir.
-func ExportChanges(dir string, changes []archive.Change, idMap idtools.IdentityMapping) (io.ReadCloser, error) {
-	return archive.ExportChanges(dir, changes, idtools.ToUserIdentityMapping(idMap))
-}
diff --git a/vendor/github.com/moby/go-archive/changes_linux.go b/pkg/archive/changes_linux.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/changes_linux.go
rename to pkg/archive/changes_linux.go
diff --git a/vendor/github.com/moby/go-archive/changes_other.go b/pkg/archive/changes_other.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/changes_other.go
rename to pkg/archive/changes_other.go
diff --git a/pkg/archive/changes_posix_test.go b/pkg/archive/changes_posix_test.go
new file mode 100644
index 0000000000..cc54a83cb1
--- /dev/null
+++ b/pkg/archive/changes_posix_test.go
@@ -0,0 +1,123 @@
+package archive
+
+import (
+	"archive/tar"
+	"fmt"
+	"io"
+	"os"
+	"path"
+	"sort"
+	"testing"
+
+	"github.com/docker/docker/pkg/idtools"
+)
+
+func TestHardLinkOrder(t *testing.T) {
+	names := []string{"file1.txt", "file2.txt", "file3.txt"}
+	msg := []byte("Hey y'all")
+
+	// Create dir
+	src, err := os.MkdirTemp("", "docker-hardlink-test-src-")
+	if err != nil {
+		t.Fatal(err)
+	}
+	defer os.RemoveAll(src)
+	for _, name := range names {
+		func() {
+			err := os.WriteFile(path.Join(src, name), msg, 0o666)
+			if err != nil {
+				t.Fatal(err)
+			}
+		}()
+	}
+	// Create dest, with changes that includes hardlinks
+	dest, err := os.MkdirTemp("", "docker-hardlink-test-dest-")
+	if err != nil {
+		t.Fatal(err)
+	}
+	os.RemoveAll(dest) // we just want the name, at first
+	if err := copyDir(src, dest); err != nil {
+		t.Fatal(err)
+	}
+	defer os.RemoveAll(dest)
+	for _, name := range names {
+		for i := 0; i < 5; i++ {
+			if err := os.Link(path.Join(dest, name), path.Join(dest, fmt.Sprintf("%s.link%d", name, i))); err != nil {
+				t.Fatal(err)
+			}
+		}
+	}
+
+	// get changes
+	changes, err := ChangesDirs(dest, src)
+	if err != nil {
+		t.Fatal(err)
+	}
+
+	// sort
+	sort.Sort(changesByPath(changes))
+
+	// ExportChanges
+	ar, err := ExportChanges(dest, changes, idtools.IdentityMapping{})
+	if err != nil {
+		t.Fatal(err)
+	}
+	hdrs, err := walkHeaders(ar)
+	if err != nil {
+		t.Fatal(err)
+	}
+
+	// reverse sort
+	sort.Sort(sort.Reverse(changesByPath(changes)))
+	// ExportChanges
+	arRev, err := ExportChanges(dest, changes, idtools.IdentityMapping{})
+	if err != nil {
+		t.Fatal(err)
+	}
+	hdrsRev, err := walkHeaders(arRev)
+	if err != nil {
+		t.Fatal(err)
+	}
+
+	// line up the two sets
+	sort.Sort(tarHeaders(hdrs))
+	sort.Sort(tarHeaders(hdrsRev))
+
+	// compare Size and LinkName
+	for i := range hdrs {
+		if hdrs[i].Name != hdrsRev[i].Name {
+			t.Errorf("headers - expected name %q; but got %q", hdrs[i].Name, hdrsRev[i].Name)
+		}
+		if hdrs[i].Size != hdrsRev[i].Size {
+			t.Errorf("headers - %q expected size %d; but got %d", hdrs[i].Name, hdrs[i].Size, hdrsRev[i].Size)
+		}
+		if hdrs[i].Typeflag != hdrsRev[i].Typeflag {
+			t.Errorf("headers - %q expected type %d; but got %d", hdrs[i].Name, hdrs[i].Typeflag, hdrsRev[i].Typeflag)
+		}
+		if hdrs[i].Linkname != hdrsRev[i].Linkname {
+			t.Errorf("headers - %q expected linkname %q; but got %q", hdrs[i].Name, hdrs[i].Linkname, hdrsRev[i].Linkname)
+		}
+	}
+}
+
+type tarHeaders []tar.Header
+
+func (th tarHeaders) Len() int           { return len(th) }
+func (th tarHeaders) Swap(i, j int)      { th[j], th[i] = th[i], th[j] }
+func (th tarHeaders) Less(i, j int) bool { return th[i].Name < th[j].Name }
+
+func walkHeaders(r io.Reader) ([]tar.Header, error) {
+	t := tar.NewReader(r)
+	var headers []tar.Header
+	for {
+		hdr, err := t.Next()
+		if err != nil {
+			if err == io.EOF {
+				break
+			}
+			return headers, err
+		}
+		headers = append(headers, *hdr)
+	}
+	return headers, nil
+}
diff --git a/pkg/archive/changes_test.go b/pkg/archive/changes_test.go
new file mode 100644
index 0000000000..bb6950d733
--- /dev/null
+++ b/pkg/archive/changes_test.go
@@ -0,0 +1,524 @@
+package archive
+
+import (
+	"os"
+	"os/exec"
+	"path"
+	"path/filepath"
+	"runtime"
+	"sort"
+	"syscall"
+	"testing"
+	"time"
+
+	"github.com/docker/docker/pkg/idtools"
+	"gotest.tools/v3/assert"
+	"gotest.tools/v3/skip"
+)
+
+func maxInt(x, y int) int {
+	if x >= y {
+		return x
+	}
+	return y
+}
+
+func copyDir(src, dst string) error {
+	if runtime.GOOS != "windows" {
+		return exec.Command("cp", "-a", src, dst).Run()
+	}
+
+	// Could have used xcopy src dst /E /I /H /Y /B. However, xcopy has the
+	// unfortunate side effect of not preserving timestamps of newly created
+	// directories in the target directory, so we don't get accurate changes.
+	// Use robocopy instead. Note this isn't available in microsoft/nanoserver.
+	// But it has gotchas. See https://weblogs.sqlteam.com/robv/archive/2010/02/17/61106.aspx
+	err := exec.Command("robocopy", filepath.FromSlash(src), filepath.FromSlash(dst), "/SL", "/COPYALL", "/MIR").Run()
+	if exiterr, ok := err.(*exec.ExitError); ok {
+		if status, ok := exiterr.Sys().(syscall.WaitStatus); ok {
+			if status.ExitStatus()&24 == 0 {
+				return nil
+			}
+		}
+	}
+	return err
+}
+
+type FileType uint32
+
+const (
+	Regular FileType = 0
+	Dir     FileType = 1
+	Symlink FileType = 2
+)
+
+type FileData struct {
+	filetype    FileType
+	path        string
+	contents    string
+	permissions os.FileMode
+}
+
+func createSampleDir(t *testing.T, root string) {
+	files := []FileData{
+		{filetype: Regular, path: "file1", contents: "file1\n", permissions: 0o600},
+		{filetype: Regular, path: "file2", contents: "file2\n", permissions: 0o666},
+		{filetype: Regular, path: "file3", contents: "file3\n", permissions: 0o404},
+		{filetype: Regular, path: "file4", contents: "file4\n", permissions: 0o600},
+		{filetype: Regular, path: "file5", contents: "file5\n", permissions: 0o600},
+		{filetype: Regular, path: "file6", contents: "file6\n", permissions: 0o600},
+		{filetype: Regular, path: "file7", contents: "file7\n", permissions: 0o600},
+		{filetype: Dir, path: "dir1", contents: "", permissions: 0o740},
+		{filetype: Regular, path: "dir1/file1-1", contents: "file1-1\n", permissions: 0o1444},
+		{filetype: Regular, path: "dir1/file1-2", contents: "file1-2\n", permissions: 0o666},
+		{filetype: Dir, path: "dir2", contents: "", permissions: 0o700},
+		{filetype: Regular, path: "dir2/file2-1", contents: "file2-1\n", permissions: 0o666},
+		{filetype: Regular, path: "dir2/file2-2", contents: "file2-2\n", permissions: 0o666},
+		{filetype: Dir, path: "dir3", contents: "", permissions: 0o700},
+		{filetype: Regular, path: "dir3/file3-1", contents: "file3-1\n", permissions: 0o666},
+		{filetype: Regular, path: "dir3/file3-2", contents: "file3-2\n", permissions: 0o666},
+		{filetype: Dir, path: "dir4", contents: "", permissions: 0o700},
+		{filetype: Regular, path: "dir4/file3-1", contents: "file4-1\n", permissions: 0o666},
+		{filetype: Regular, path: "dir4/file3-2", contents: "file4-2\n", permissions: 0o666},
+		{filetype: Symlink, path: "symlink1", contents: "target1", permissions: 0o666},
+		{filetype: Symlink, path: "symlink2", contents: "target2", permissions: 0o666},
+		{filetype: Symlink, path: "symlink3", contents: root + "/file1", permissions: 0o666},
+		{filetype: Symlink, path: "symlink4", contents: root + "/symlink3", permissions: 0o666},
+		{filetype: Symlink, path: "dirSymlink", contents: root + "/dir1", permissions: 0o740},
+	}
+	provisionSampleDir(t, root, files)
+}
+
+func provisionSampleDir(t *testing.T, root string, files []FileData) {
+	now := time.Now()
+	for _, info := range files {
+		p := path.Join(root, info.path)
+		if info.filetype == Dir {
+			err := os.MkdirAll(p, info.permissions)
+			assert.NilError(t, err)
+		} else if info.filetype == Regular {
+			err := os.WriteFile(p, []byte(info.contents), info.permissions)
+			assert.NilError(t, err)
+		} else if info.filetype == Symlink {
+			err := os.Symlink(info.contents, p)
+			assert.NilError(t, err)
+		}
+
+		if info.filetype != Symlink {
+			// Set a consistent ctime, atime for all files and dirs
+			err := chtimes(p, now, now)
+			assert.NilError(t, err)
+		}
+	}
+}
+
+func TestChangeString(t *testing.T) {
+	actual := (&Change{Path: "change", Kind: ChangeModify}).String()
+	if actual != "C change" {
+		t.Fatalf("String() of a change with ChangeModify Kind should have been %s but was %s", "C change", actual)
+	}
+	actual = (&Change{Path: "change", Kind: ChangeAdd}).String()
+	if actual != "A change" {
+		t.Fatalf("String() of a change with ChangeAdd Kind should have been %s but was %s", "A change", actual)
+	}
+	actual = (&Change{Path: "change", Kind: ChangeDelete}).String()
+	if actual != "D change" {
+		t.Fatalf("String() of a change with ChangeDelete Kind should have been %s but was %s", "D change", actual)
+	}
+}
+
+func TestChangesWithNoChanges(t *testing.T) {
+	rwLayer, err := os.MkdirTemp("", "docker-changes-test")
+	assert.NilError(t, err)
+	defer os.RemoveAll(rwLayer)
+	layer, err := os.MkdirTemp("", "docker-changes-test-layer")
+	assert.NilError(t, err)
+	defer os.RemoveAll(layer)
+	createSampleDir(t, layer)
+	changes, err := Changes([]string{layer}, rwLayer)
+	assert.NilError(t, err)
+	if len(changes) != 0 {
+		t.Fatalf("Changes with no difference should have detect no changes, but detected %d", len(changes))
+	}
+}
+
+func TestChangesWithChanges(t *testing.T) {
+	// Mock the readonly layer
+	layer, err := os.MkdirTemp("", "docker-changes-test-layer")
+	assert.NilError(t, err)
+	defer os.RemoveAll(layer)
+	createSampleDir(t, layer)
+	os.MkdirAll(path.Join(layer, "dir1/subfolder"), 0o740)
+
+	// Mock the RW layer
+	rwLayer, err := os.MkdirTemp("", "docker-changes-test")
+	assert.NilError(t, err)
+	defer os.RemoveAll(rwLayer)
+
+	// Create a folder in RW layer
+	dir1 := path.Join(rwLayer, "dir1")
+	os.MkdirAll(dir1, 0o740)
+	deletedFile := path.Join(dir1, ".wh.file1-2")
+	os.WriteFile(deletedFile, []byte{}, 0o600)
+	modifiedFile := path.Join(dir1, "file1-1")
+	os.WriteFile(modifiedFile, []byte{0x00}, 0o1444)
+	// Let's add a subfolder for a newFile
+	subfolder := path.Join(dir1, "subfolder")
+	os.MkdirAll(subfolder, 0o740)
+	newFile := path.Join(subfolder, "newFile")
+	os.WriteFile(newFile, []byte{}, 0o740)
+
+	changes, err := Changes([]string{layer}, rwLayer)
+	assert.NilError(t, err)
+
+	expectedChanges := []Change{
+		{Path: filepath.FromSlash("/dir1"), Kind: ChangeModify},
+		{Path: filepath.FromSlash("/dir1/file1-1"), Kind: ChangeModify},
+		{Path: filepath.FromSlash("/dir1/file1-2"), Kind: ChangeDelete},
+		{Path: filepath.FromSlash("/dir1/subfolder"), Kind: ChangeModify},
+		{Path: filepath.FromSlash("/dir1/subfolder/newFile"), Kind: ChangeAdd},
+	}
+	checkChanges(expectedChanges, changes, t)
+}
+
+// See https://github.com/docker/docker/pull/13590
+func TestChangesWithChangesGH13590(t *testing.T) {
+	// TODO Windows. Needs further investigation to identify the failure
+	if runtime.GOOS == "windows" {
+		t.Skip("needs more investigation")
+	}
+	baseLayer, err := os.MkdirTemp("", "docker-changes-test.")
+	assert.NilError(t, err)
+	defer os.RemoveAll(baseLayer)
+
+	dir3 := path.Join(baseLayer, "dir1/dir2/dir3")
+	os.MkdirAll(dir3, 0o7400)
+
+	file := path.Join(dir3, "file.txt")
+	os.WriteFile(file, []byte("hello"), 0o666)
+
+	layer, err := os.MkdirTemp("", "docker-changes-test2.")
+	assert.NilError(t, err)
+	defer os.RemoveAll(layer)
+
+	// Test creating a new file
+	if err := copyDir(baseLayer+"/dir1", layer+"/"); err != nil {
+		t.Fatalf("Cmd failed: %q", err)
+	}
+
+	os.Remove(path.Join(layer, "dir1/dir2/dir3/file.txt"))
+	file = path.Join(layer, "dir1/dir2/dir3/file1.txt")
+	os.WriteFile(file, []byte("bye"), 0o666)
+
+	changes, err := Changes([]string{baseLayer}, layer)
+	assert.NilError(t, err)
+
+	expectedChanges := []Change{
+		{Path: "/dir1/dir2/dir3", Kind: ChangeModify},
+		{Path: "/dir1/dir2/dir3/file1.txt", Kind: ChangeAdd},
+	}
+	checkChanges(expectedChanges, changes, t)
+
+	// Now test changing a file
+	layer, err = os.MkdirTemp("", "docker-changes-test3.")
+	assert.NilError(t, err)
+	defer os.RemoveAll(layer)
+
+	if err := copyDir(baseLayer+"/dir1", layer+"/"); err != nil {
+		t.Fatalf("Cmd failed: %q", err)
+	}
+
+	file = path.Join(layer, "dir1/dir2/dir3/file.txt")
+	os.WriteFile(file, []byte("bye"), 0o666)
+
+	changes, err = Changes([]string{baseLayer}, layer)
+	assert.NilError(t, err)
+
+	expectedChanges = []Change{
+		{Path: "/dir1/dir2/dir3/file.txt", Kind: ChangeModify},
+	}
+	checkChanges(expectedChanges, changes, t)
+}
+
+// Create a directory, copy it, make sure we report no changes between the two
+func TestChangesDirsEmpty(t *testing.T) {
+	if runtime.GOOS == "windows" {
+		t.Skip("FIXME: broken on Windows 1903 and up; see https://github.com/moby/moby/pull/39846")
+	}
+
+	src, err := os.MkdirTemp("", "docker-changes-test")
+	assert.NilError(t, err)
+	defer os.RemoveAll(src)
+	createSampleDir(t, src)
+	dst := src + "-copy"
+	err = copyDir(src, dst)
+	assert.NilError(t, err)
+	defer os.RemoveAll(dst)
+	changes, err := ChangesDirs(dst, src)
+	assert.NilError(t, err)
+
+	if len(changes) != 0 {
+		t.Fatalf("Reported changes for identical dirs: %v", changes)
+	}
+	os.RemoveAll(src)
+	os.RemoveAll(dst)
+}
+
+func mutateSampleDir(t *testing.T, root string) {
+	// Remove a regular file
+	err := os.RemoveAll(path.Join(root, "file1"))
+	assert.NilError(t, err)
+
+	// Remove a directory
+	err = os.RemoveAll(path.Join(root, "dir1"))
+	assert.NilError(t, err)
+
+	// Remove a symlink
+	err = os.RemoveAll(path.Join(root, "symlink1"))
+	assert.NilError(t, err)
+
+	// Rewrite a file
+	err = os.WriteFile(path.Join(root, "file2"), []byte("fileNN\n"), 0o777)
+	assert.NilError(t, err)
+
+	// Replace a file
+	err = os.RemoveAll(path.Join(root, "file3"))
+	assert.NilError(t, err)
+	err = os.WriteFile(path.Join(root, "file3"), []byte("fileMM\n"), 0o404)
+	assert.NilError(t, err)
+
+	// Touch file
+	err = chtimes(path.Join(root, "file4"), time.Now().Add(time.Second), time.Now().Add(time.Second))
+	assert.NilError(t, err)
+
+	// Replace file with dir
+	err = os.RemoveAll(path.Join(root, "file5"))
+	assert.NilError(t, err)
+	err = os.MkdirAll(path.Join(root, "file5"), 0o666)
+	assert.NilError(t, err)
+
+	// Create new file
+	err = os.WriteFile(path.Join(root, "filenew"), []byte("filenew\n"), 0o777)
+	assert.NilError(t, err)
+
+	// Create new dir
+	err = os.MkdirAll(path.Join(root, "dirnew"), 0o766)
+	assert.NilError(t, err)
+
+	// Create a new symlink
+	err = os.Symlink("targetnew", path.Join(root, "symlinknew"))
+	assert.NilError(t, err)
+
+	// Change a symlink
+	err = os.RemoveAll(path.Join(root, "symlink2"))
+	assert.NilError(t, err)
+
+	err = os.Symlink("target2change", path.Join(root, "symlink2"))
+	assert.NilError(t, err)
+
+	// Replace dir with file
+	err = os.RemoveAll(path.Join(root, "dir2"))
+	assert.NilError(t, err)
+	err = os.WriteFile(path.Join(root, "dir2"), []byte("dir2\n"), 0o777)
+	assert.NilError(t, err)
+
+	// Touch dir
+	err = chtimes(path.Join(root, "dir3"), time.Now().Add(time.Second), time.Now().Add(time.Second))
+	assert.NilError(t, err)
+}
+
+func TestChangesDirsMutated(t *testing.T) {
+	if runtime.GOOS == "windows" {
+		t.Skip("FIXME: broken on Windows 1903 and up; see https://github.com/moby/moby/pull/39846")
+	}
+
+	src, err := os.MkdirTemp("", "docker-changes-test")
+	assert.NilError(t, err)
+	createSampleDir(t, src)
+	dst := src + "-copy"
+	err = copyDir(src, dst)
+	assert.NilError(t, err)
+	defer os.RemoveAll(src)
+	defer os.RemoveAll(dst)
+
+	mutateSampleDir(t, dst)
+
+	changes, err := ChangesDirs(dst, src)
+	assert.NilError(t, err)
+
+	sort.Sort(changesByPath(changes))
+
+	expectedChanges := []Change{
+		{Path: filepath.FromSlash("/dir1"), Kind: ChangeDelete},
+		{Path: filepath.FromSlash("/dir2"), Kind: ChangeModify},
+	}
+
+	// Note there is slight difference between the Linux and Windows
+	// implementations here. Due to https://github.com/moby/moby/issues/9874,
+	// and the fix at https://github.com/moby/moby/pull/11422, Linux does not
+	// consider a change to the directory time as a change. Windows on NTFS
+	// does. See https://github.com/moby/moby/pull/37982 for more information.
+	//
+	// Note also: https://github.com/moby/moby/pull/37982#discussion_r223523114
+	// that differences are ordered in the way the test is currently written, hence
+	// this is in the middle of the list of changes rather than at the start or
+	// end. Potentially can be addressed later.
+	if runtime.GOOS == "windows" {
+		expectedChanges = append(expectedChanges, Change{Path: filepath.FromSlash("/dir3"), Kind: ChangeModify})
+	}
+
+	expectedChanges = append(expectedChanges, []Change{
+		{Path: filepath.FromSlash("/dirnew"), Kind: ChangeAdd},
+		{Path: filepath.FromSlash("/file1"), Kind: ChangeDelete},
+		{Path: filepath.FromSlash("/file2"), Kind: ChangeModify},
+		{Path: filepath.FromSlash("/file3"), Kind: ChangeModify},
+		{Path: filepath.FromSlash("/file4"), Kind: ChangeModify},
+		{Path: filepath.FromSlash("/file5"), Kind: ChangeModify},
+		{Path: filepath.FromSlash("/filenew"), Kind: ChangeAdd},
+		{Path: filepath.FromSlash("/symlink1"), Kind: ChangeDelete},
+		{Path: filepath.FromSlash("/symlink2"), Kind: ChangeModify},
+		{Path: filepath.FromSlash("/symlinknew"), Kind: ChangeAdd},
+	}...)
+
+	for i := 0; i < maxInt(len(changes), len(expectedChanges)); i++ {
+		if i >= len(expectedChanges) {
+			t.Fatalf("unexpected change %s\n", changes[i].String())
+		}
+		if i >= len(changes) {
+			t.Fatalf("no change for expected change %s\n", expectedChanges[i].String())
+		}
+		if changes[i].Path == expectedChanges[i].Path {
+			if changes[i] != expectedChanges[i] {
+				t.Fatalf("Wrong change for %s, expected %s, got %s\n", changes[i].Path, changes[i].String(), expectedChanges[i].String())
+			}
+		} else if changes[i].Path < expectedChanges[i].Path {
+			t.Fatalf("unexpected change %q %q\n", changes[i].String(), expectedChanges[i].Path)
+		} else {
+			t.Fatalf("no change for expected change %s != %s\n", expectedChanges[i].String(), changes[i].String())
+		}
+	}
+}
+
+func TestApplyLayer(t *testing.T) {
+	// TODO Windows. This is very close to working, but it fails with changes
+	// to \symlinknew and \symlink2. The destination has an updated
+	// Access/Modify/Change/Birth date to the source (~3/100th sec different).
+	// Needs further investigation as to why, but I currently believe this is
+	// just the way NTFS works. I don't think it's a bug in this test or archive.
+	if runtime.GOOS == "windows" {
+		t.Skip("needs further investigation")
+	}
+	src, err := os.MkdirTemp("", "docker-changes-test")
+	assert.NilError(t, err)
+	createSampleDir(t, src)
+	defer os.RemoveAll(src)
+	dst := src + "-copy"
+	err = copyDir(src, dst)
+	assert.NilError(t, err)
+	mutateSampleDir(t, dst)
+	defer os.RemoveAll(dst)
+
+	changes, err := ChangesDirs(dst, src)
+	assert.NilError(t, err)
+
+	layer, err := ExportChanges(dst, changes, idtools.IdentityMapping{})
+	assert.NilError(t, err)
+
+	layerCopy, err := newTempArchive(layer, "")
+	assert.NilError(t, err)
+
+	_, err = ApplyLayer(src, layerCopy)
+	assert.NilError(t, err)
+
+	changes2, err := ChangesDirs(src, dst)
+	assert.NilError(t, err)
+
+	if len(changes2) != 0 {
+		t.Fatalf("Unexpected differences after reapplying mutation: %v", changes2)
+	}
+}
+
+func TestChangesSizeWithHardlinks(t *testing.T) {
+	// TODO Windows. Needs further investigation. Likely in ChangeSizes not
+	// coping correctly with hardlinks on Windows.
+	if runtime.GOOS == "windows" {
+		t.Skip("needs further investigation")
+	}
+	srcDir, err := os.MkdirTemp("", "docker-test-srcDir")
+	assert.NilError(t, err)
+	defer os.RemoveAll(srcDir)
+
+	destDir, err := os.MkdirTemp("", "docker-test-destDir")
+	assert.NilError(t, err)
+	defer os.RemoveAll(destDir)
+
+	creationSize, err := prepareUntarSourceDirectory(100, destDir, true)
+	assert.NilError(t, err)
+
+	changes, err := ChangesDirs(destDir, srcDir)
+	assert.NilError(t, err)
+
+	got := ChangesSize(destDir, changes)
+	if got != int64(creationSize) {
+		t.Errorf("Expected %d bytes of changes, got %d", creationSize, got)
+	}
+}
+
+func TestChangesSizeWithNoChanges(t *testing.T) {
+	size := ChangesSize("/tmp", nil)
+	if size != 0 {
+		t.Fatalf("ChangesSizes with no changes should be 0, was %d", size)
+	}
+}
+
+func TestChangesSizeWithOnlyDeleteChanges(t *testing.T) {
+	size := ChangesSize("/tmp", []Change{
+		{Path: "deletedPath", Kind: ChangeDelete},
+	})
+	if size != 0 {
+		t.Fatalf("ChangesSizes with only delete changes should be 0, was %d", size)
+	}
+}
+
+func TestChangesSize(t *testing.T) {
+	parentPath, err := os.MkdirTemp("", "docker-changes-test")
+	assert.NilError(t, err)
+	defer os.RemoveAll(parentPath)
+	addition := path.Join(parentPath, "addition")
+	err = os.WriteFile(addition, []byte{0x01, 0x01, 0x01}, 0o744)
+	assert.NilError(t, err)
+	modification := path.Join(parentPath, "modification")
+	err = os.WriteFile(modification, []byte{0x01, 0x01, 0x01}, 0o744)
+	assert.NilError(t, err)
+
+	size := ChangesSize(parentPath, []Change{
+		{Path: "addition", Kind: ChangeAdd},
+		{Path: "modification", Kind: ChangeModify},
+	})
+	if size != 6 {
+		t.Fatalf("Expected 6 bytes of changes, got %d", size)
+	}
+}
+
+func checkChanges(expectedChanges, changes []Change, t *testing.T) {
+	skip.If(t, runtime.GOOS != "windows" && os.Getuid() != 0, "skipping test that requires root")
+	sort.Sort(changesByPath(expectedChanges))
+	sort.Sort(changesByPath(changes))
+	for i := 0; i < maxInt(len(changes), len(expectedChanges)); i++ {
+		if i >= len(expectedChanges) {
+			t.Fatalf("unexpected change %s\n", changes[i].String())
+		}
+		if i >= len(changes) {
+			t.Fatalf("no change for expected change %s\n", expectedChanges[i].String())
+		}
+		if changes[i].Path == expectedChanges[i].Path {
+			if changes[i] != expectedChanges[i] {
+				t.Fatalf("Wrong change for %s, expected %s, got %s\n", changes[i].Path, changes[i].String(), expectedChanges[i].String())
+			}
+		} else if changes[i].Path < expectedChanges[i].Path {
+			t.Fatalf("unexpected change %s\n", changes[i].String())
+		} else {
+			t.Fatalf("no change for expected change %s != %s\n", expectedChanges[i].String(), changes[i].String())
+		}
+	}
+}
diff --git a/vendor/github.com/moby/go-archive/changes_unix.go b/pkg/archive/changes_unix.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/changes_unix.go
rename to pkg/archive/changes_unix.go
diff --git a/vendor/github.com/moby/go-archive/changes_windows.go b/pkg/archive/changes_windows.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/changes_windows.go
rename to pkg/archive/changes_windows.go
diff --git a/vendor/github.com/moby/go-archive/copy.go b/pkg/archive/copy.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/copy.go
rename to pkg/archive/copy.go
diff --git a/pkg/archive/copy_deprecated.go b/pkg/archive/copy_deprecated.go
deleted file mode 100644
index 83e467fb18..0000000000
--- a/pkg/archive/copy_deprecated.go
+++ /dev/null
@@ -1,129 +0,0 @@
-package archive
-
-import (
-	"io"
-
-	"github.com/moby/go-archive"
-)
-
-var (
-	ErrNotDirectory      = archive.ErrNotDirectory      // Deprecated: use [archive.ErrNotDirectory] instead.
-	ErrDirNotExists      = archive.ErrDirNotExists      // Deprecated: use [archive.ErrDirNotExists] instead.
-	ErrCannotCopyDir     = archive.ErrCannotCopyDir     // Deprecated: use [archive.ErrCannotCopyDir] instead.
-	ErrInvalidCopySource = archive.ErrInvalidCopySource // Deprecated: use [archive.ErrInvalidCopySource] instead.
-)
-
-// PreserveTrailingDotOrSeparator returns the given cleaned path.
-//
-// Deprecated: use [archive.PreserveTrailingDotOrSeparator] instead.
-func PreserveTrailingDotOrSeparator(cleanedPath string, originalPath string) string {
-	return archive.PreserveTrailingDotOrSeparator(cleanedPath, originalPath)
-}
-
-// SplitPathDirEntry splits the given path between its directory name and its
-// basename.
-//
-// Deprecated: use [archive.SplitPathDirEntry] instead.
-func SplitPathDirEntry(path string) (dir, base string) {
-	return archive.SplitPathDirEntry(path)
-}
-
-// TarResource archives the resource described by the given CopyInfo to a Tar
-// archive.
-//
-// Deprecated: use [archive.TarResource] instead.
-func TarResource(sourceInfo archive.CopyInfo) (content io.ReadCloser, err error) {
-	return archive.TarResource(sourceInfo)
-}
-
-// TarResourceRebase is like TarResource but renames the first path element of
-// items in the resulting tar archive to match the given rebaseName if not "".
-//
-// Deprecated: use [archive.TarResourceRebase] instead.
-func TarResourceRebase(sourcePath, rebaseName string) (content io.ReadCloser, _ error) {
-	return archive.TarResourceRebase(sourcePath, rebaseName)
-}
-
-// TarResourceRebaseOpts does not preform the Tar, but instead just creates the rebase
-// parameters to be sent to TarWithOptions.
-//
-// Deprecated: use [archive.TarResourceRebaseOpts] instead.
-func TarResourceRebaseOpts(sourceBase string, rebaseName string) *TarOptions {
-	filter := []string{sourceBase}
-	return &TarOptions{
-		Compression:      archive.Uncompressed,
-		IncludeFiles:     filter,
-		IncludeSourceDir: true,
-		RebaseNames: map[string]string{
-			sourceBase: rebaseName,
-		},
-	}
-}
-
-// CopyInfo holds basic info about the source or destination path of a copy operation.
-//
-// Deprecated: use [archive.CopyInfo] instead.
-type CopyInfo = archive.CopyInfo
-
-// CopyInfoSourcePath stats the given path to create a CopyInfo struct.
-// struct representing that resource for the source of an archive copy
-// operation.
-//
-// Deprecated: use [archive.CopyInfoSourcePath] instead.
-func CopyInfoSourcePath(path string, followLink bool) (archive.CopyInfo, error) {
-	return archive.CopyInfoSourcePath(path, followLink)
-}
-
-// CopyInfoDestinationPath stats the given path to create a CopyInfo
-// struct representing that resource for the destination of an archive copy
-// operation.
-//
-// Deprecated: use [archive.CopyInfoDestinationPath] instead.
-func CopyInfoDestinationPath(path string) (info archive.CopyInfo, err error) {
-	return archive.CopyInfoDestinationPath(path)
-}
-
-// PrepareArchiveCopy prepares the given srcContent archive.
-//
-// Deprecated: use [archive.PrepareArchiveCopy] instead.
-func PrepareArchiveCopy(srcContent io.Reader, srcInfo, dstInfo archive.CopyInfo) (dstDir string, content io.ReadCloser, err error) {
-	return archive.PrepareArchiveCopy(srcContent, srcInfo, dstInfo)
-}
-
-// RebaseArchiveEntries rewrites the given srcContent archive replacing
-// an occurrence of oldBase with newBase at the beginning of entry names.
-//
-// Deprecated: use [archive.RebaseArchiveEntries] instead.
-func RebaseArchiveEntries(srcContent io.Reader, oldBase, newBase string) io.ReadCloser {
-	return archive.RebaseArchiveEntries(srcContent, oldBase, newBase)
-}
-
-// CopyResource performs an archive copy from the given source path to the
-// given destination path.
-//
-// Deprecated: use [archive.CopyResource] instead.
-func CopyResource(srcPath, dstPath string, followLink bool) error {
-	return archive.CopyResource(srcPath, dstPath, followLink)
-}
-
-// CopyTo handles extracting the given content whose
-// entries should be sourced from srcInfo to dstPath.
-//
-// Deprecated: use [archive.CopyTo] instead.
-func CopyTo(content io.Reader, srcInfo archive.CopyInfo, dstPath string) error {
-	return archive.CopyTo(content, srcInfo, dstPath)
-}
-
-// ResolveHostSourcePath decides real path need to be copied.
-//
-// Deprecated: use [archive.ResolveHostSourcePath] instead.
-func ResolveHostSourcePath(path string, followLink bool) (resolvedPath, rebaseName string, _ error) {
-	return archive.ResolveHostSourcePath(path, followLink)
-}
-
-// GetRebaseName normalizes and compares path and resolvedPath.
-//
-// Deprecated: use [archive.GetRebaseName] instead.
-func GetRebaseName(path, resolvedPath string) (string, string) {
-	return archive.GetRebaseName(path, resolvedPath)
-}
diff --git a/vendor/github.com/moby/go-archive/copy_unix.go b/pkg/archive/copy_unix.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/copy_unix.go
rename to pkg/archive/copy_unix.go
diff --git a/pkg/archive/copy_unix_test.go b/pkg/archive/copy_unix_test.go
new file mode 100644
index 0000000000..180be43811
--- /dev/null
+++ b/pkg/archive/copy_unix_test.go
@@ -0,0 +1,987 @@
+//go:build !windows
+
+// TODO Windows: Some of these tests may be salvageable and portable to Windows.
+
+package archive
+
+import (
+	"bytes"
+	"crypto/sha256"
+	"encoding/hex"
+	"fmt"
+	"io"
+	"os"
+	"path/filepath"
+	"strings"
+	"testing"
+
+	"gotest.tools/v3/assert"
+)
+
+func removeAllPaths(paths ...string) {
+	for _, path := range paths {
+		os.RemoveAll(path)
+	}
+}
+
+func getTestTempDirs(t *testing.T) (tmpDirA, tmpDirB string) {
+	var err error
+
+	tmpDirA, err = os.MkdirTemp("", "archive-copy-test")
+	assert.NilError(t, err)
+
+	tmpDirB, err = os.MkdirTemp("", "archive-copy-test")
+	assert.NilError(t, err)
+
+	return tmpDirA, tmpDirB
+}
+
+func isNotDir(err error) bool {
+	return strings.Contains(err.Error(), "not a directory")
+}
+
+func joinTrailingSep(pathElements ...string) string {
+	joined := filepath.Join(pathElements...)
+
+	return fmt.Sprintf("%s%c", joined, filepath.Separator)
+}
+
+func fileContentsEqual(t *testing.T, filenameA, filenameB string) error {
+	t.Logf("checking for equal file contents: %q and %q\n", filenameA, filenameB)
+
+	fileA, err := os.Open(filenameA)
+	if err != nil {
+		return err
+	}
+	defer fileA.Close()
+
+	fileB, err := os.Open(filenameB)
+	if err != nil {
+		return err
+	}
+	defer fileB.Close()
+
+	hasher := sha256.New()
+
+	if _, err := io.Copy(hasher, fileA); err != nil {
+		return err
+	}
+
+	hashA := hasher.Sum(nil)
+	hasher.Reset()
+
+	if _, err := io.Copy(hasher, fileB); err != nil {
+		return err
+	}
+
+	hashB := hasher.Sum(nil)
+
+	if !bytes.Equal(hashA, hashB) {
+		return fmt.Errorf("file content hashes not equal - expected %s, got %s", hex.EncodeToString(hashA), hex.EncodeToString(hashB))
+	}
+
+	return nil
+}
+
+func dirContentsEqual(t *testing.T, newDir, oldDir string) error {
+	t.Logf("checking for equal directory contents: %q and %q", newDir, oldDir)
+
+	c, err := ChangesDirs(newDir, oldDir)
+	if err != nil {
+		return err
+	}
+
+	if len(c) != 0 {
+		return fmt.Errorf("expected no changes between directories, but got: %v", c)
+	}
+
+	return nil
+}
+
+func logDirContents(t *testing.T, dirPath string) {
+	t.Logf("logging directory contents: %q", dirPath)
+	err := filepath.WalkDir(dirPath, func(path string, info os.DirEntry, err error) error {
+		if err != nil {
+			t.Errorf("stat error for path %q: %s", path, err)
+			return nil
+		}
+
+		if info.IsDir() {
+			path = joinTrailingSep(path)
+		}
+
+		t.Logf("\t%s", path)
+
+		return nil
+	})
+	assert.NilError(t, err)
+}
+
+func testCopyHelper(t *testing.T, srcPath, dstPath string) (err error) {
+	t.Logf("copying from %q to %q (not follow symbol link)", srcPath, dstPath)
+
+	return CopyResource(srcPath, dstPath, false)
+}
+
+func testCopyHelperFSym(t *testing.T, srcPath, dstPath string) (err error) {
+	t.Logf("copying from %q to %q (follow symbol link)", srcPath, dstPath)
+
+	return CopyResource(srcPath, dstPath, true)
+}
+
+// Basic assumptions about SRC and DST:
+// 1. SRC must exist.
+// 2. If SRC ends with a trailing separator, it must be a directory.
+// 3. DST parent directory must exist.
+// 4. If DST exists as a file, it must not end with a trailing separator.
+
+// First get these easy error cases out of the way.
+
+// Test for error when SRC does not exist.
+func TestCopyErrSrcNotExists(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	if _, err := CopyInfoSourcePath(filepath.Join(tmpDirA, "file1"), false); !os.IsNotExist(err) {
+		t.Fatalf("expected IsNotExist error, but got %T: %s", err, err)
+	}
+}
+
+// Test for error when SRC ends in a trailing
+// path separator but it exists as a file.
+func TestCopyErrSrcNotDir(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+
+	if _, err := CopyInfoSourcePath(joinTrailingSep(tmpDirA, "file1"), false); !isNotDir(err) {
+		t.Fatalf("expected IsNotDir error, but got %T: %s", err, err)
+	}
+}
+
+// Test for error when SRC is a valid file or directory,
+// but the DST parent directory does not exist.
+func TestCopyErrDstParentNotExists(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+
+	srcInfo := CopyInfo{Path: filepath.Join(tmpDirA, "file1"), Exists: true, IsDir: false}
+
+	// Try with a file source.
+	content, err := TarResource(srcInfo)
+	if err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+	defer content.Close()
+
+	// Copy to a file whose parent does not exist.
+	if err = CopyTo(content, srcInfo, filepath.Join(tmpDirB, "fakeParentDir", "file1")); err == nil {
+		t.Fatal("expected IsNotExist error, but got nil instead")
+	}
+
+	if !os.IsNotExist(err) {
+		t.Fatalf("expected IsNotExist error, but got %T: %s", err, err)
+	}
+
+	// Try with a directory source.
+	srcInfo = CopyInfo{Path: filepath.Join(tmpDirA, "dir1"), Exists: true, IsDir: true}
+
+	content, err = TarResource(srcInfo)
+	if err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+	defer content.Close()
+
+	// Copy to a directory whose parent does not exist.
+	if err = CopyTo(content, srcInfo, joinTrailingSep(tmpDirB, "fakeParentDir", "fakeDstDir")); err == nil {
+		t.Fatal("expected IsNotExist error, but got nil instead")
+	}
+
+	if !os.IsNotExist(err) {
+		t.Fatalf("expected IsNotExist error, but got %T: %s", err, err)
+	}
+}
+
+// Test for error when DST ends in a trailing
+// path separator but exists as a file.
+func TestCopyErrDstNotDir(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A and B with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+	createSampleDir(t, tmpDirB)
+
+	// Try with a file source.
+	srcInfo := CopyInfo{Path: filepath.Join(tmpDirA, "file1"), Exists: true, IsDir: false}
+
+	content, err := TarResource(srcInfo)
+	if err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+	defer content.Close()
+
+	if err = CopyTo(content, srcInfo, joinTrailingSep(tmpDirB, "file1")); err == nil {
+		t.Fatal("expected IsNotDir error, but got nil instead")
+	}
+
+	if !isNotDir(err) {
+		t.Fatalf("expected IsNotDir error, but got %T: %s", err, err)
+	}
+
+	// Try with a directory source.
+	srcInfo = CopyInfo{Path: filepath.Join(tmpDirA, "dir1"), Exists: true, IsDir: true}
+
+	content, err = TarResource(srcInfo)
+	if err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+	defer content.Close()
+
+	if err = CopyTo(content, srcInfo, joinTrailingSep(tmpDirB, "file1")); err == nil {
+		t.Fatal("expected IsNotDir error, but got nil instead")
+	}
+
+	if !isNotDir(err) {
+		t.Fatalf("expected IsNotDir error, but got %T: %s", err, err)
+	}
+}
+
+// Test to check if CopyTo works with a long (>100 characters) destination file name.
+// This is a regression (see https://github.com/docker/for-linux/issues/484).
+func TestCopyLongDstFilename(t *testing.T) {
+	const longName = "a_very_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx_long_filename_that_is_101_characters"
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+
+	srcInfo := CopyInfo{Path: filepath.Join(tmpDirA, "file1"), Exists: true, IsDir: false}
+
+	content, err := TarResource(srcInfo)
+	if err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+	defer content.Close()
+
+	err = CopyTo(content, srcInfo, filepath.Join(tmpDirB, longName))
+	if err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+}
+
+// Possibilities are reduced to the remaining 10 cases:
+//
+//  case | srcIsDir | onlyDirContents | dstExists | dstIsDir | dstTrSep | action
+// ===================================================================================================
+//   A   |  no      |  -              |  no       |  -       |  no      |  create file
+//   B   |  no      |  -              |  no       |  -       |  yes     |  error
+//   C   |  no      |  -              |  yes      |  no      |  -       |  overwrite file
+//   D   |  no      |  -              |  yes      |  yes     |  -       |  create file in dst dir
+//   E   |  yes     |  no             |  no       |  -       |  -       |  create dir, copy contents
+//   F   |  yes     |  no             |  yes      |  no      |  -       |  error
+//   G   |  yes     |  no             |  yes      |  yes     |  -       |  copy dir and contents
+//   H   |  yes     |  yes            |  no       |  -       |  -       |  create dir, copy contents
+//   I   |  yes     |  yes            |  yes      |  no      |  -       |  error
+//   J   |  yes     |  yes            |  yes      |  yes     |  -       |  copy dir contents
+//
+
+// A. SRC specifies a file and DST (no trailing path separator) doesn't exist.
+//
+// This should create a file with the name DST and copy the contents of the source
+// file into it.
+func TestCopyCaseA(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+
+	srcPath := filepath.Join(tmpDirA, "file1")
+	dstPath := filepath.Join(tmpDirB, "itWorks.txt")
+
+	var err error
+
+	if err = testCopyHelper(t, srcPath, dstPath); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = fileContentsEqual(t, srcPath, dstPath)
+	assert.NilError(t, err)
+	os.Remove(dstPath)
+
+	symlinkPath := filepath.Join(tmpDirA, "symlink3")
+	symlinkPath1 := filepath.Join(tmpDirA, "symlink4")
+	linkTarget := filepath.Join(tmpDirA, "file1")
+
+	if err = testCopyHelperFSym(t, symlinkPath, dstPath); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = fileContentsEqual(t, linkTarget, dstPath)
+	assert.NilError(t, err)
+	os.Remove(dstPath)
+	if err = testCopyHelperFSym(t, symlinkPath1, dstPath); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = fileContentsEqual(t, linkTarget, dstPath)
+	assert.NilError(t, err)
+}
+
+// B. SRC specifies a file and DST (with trailing path separator) doesn't exist.
+//
+// This should cause an error because the copy operation cannot create a directory
+// when copying a single file.
+func TestCopyCaseB(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+
+	srcPath := filepath.Join(tmpDirA, "file1")
+	dstDir := joinTrailingSep(tmpDirB, "testDir")
+
+	var err error
+
+	if err = testCopyHelper(t, srcPath, dstDir); err == nil {
+		t.Fatal("expected ErrDirNotExists error, but got nil instead")
+	}
+
+	if err != ErrDirNotExists {
+		t.Fatalf("expected ErrDirNotExists error, but got %T: %s", err, err)
+	}
+
+	symlinkPath := filepath.Join(tmpDirA, "symlink3")
+
+	if err = testCopyHelperFSym(t, symlinkPath, dstDir); err == nil {
+		t.Fatal("expected ErrDirNotExists error, but got nil instead")
+	}
+	if err != ErrDirNotExists {
+		t.Fatalf("expected ErrDirNotExists error, but got %T: %s", err, err)
+	}
+}
+
+// C. SRC specifies a file and DST exists as a file.
+//
+// This should overwrite the file at DST with the contents of the source file.
+func TestCopyCaseC(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A and B with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+	createSampleDir(t, tmpDirB)
+
+	srcPath := filepath.Join(tmpDirA, "file1")
+	dstPath := filepath.Join(tmpDirB, "file2")
+
+	var err error
+
+	// Ensure they start out different.
+	if err = fileContentsEqual(t, srcPath, dstPath); err == nil {
+		t.Fatal("expected different file contents")
+	}
+
+	if err = testCopyHelper(t, srcPath, dstPath); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = fileContentsEqual(t, srcPath, dstPath)
+	assert.NilError(t, err)
+}
+
+// C. Symbol link following version: SRC specifies a file and DST exists as a file.
+//
+// This should overwrite the file at DST with the contents of the source file.
+func TestCopyCaseCFSym(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A and B with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+	createSampleDir(t, tmpDirB)
+
+	symlinkPathBad := filepath.Join(tmpDirA, "symlink1")
+	symlinkPath := filepath.Join(tmpDirA, "symlink3")
+	linkTarget := filepath.Join(tmpDirA, "file1")
+	dstPath := filepath.Join(tmpDirB, "file2")
+
+	var err error
+
+	// first to test broken link
+	if err = testCopyHelperFSym(t, symlinkPathBad, dstPath); err == nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	// test symbol link -> symbol link -> target
+	// Ensure they start out different.
+	if err = fileContentsEqual(t, linkTarget, dstPath); err == nil {
+		t.Fatal("expected different file contents")
+	}
+
+	if err = testCopyHelperFSym(t, symlinkPath, dstPath); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = fileContentsEqual(t, linkTarget, dstPath)
+	assert.NilError(t, err)
+}
+
+// D. SRC specifies a file and DST exists as a directory.
+//
+// This should place a copy of the source file inside it using the basename from
+// SRC. Ensure this works whether DST has a trailing path separator or not.
+func TestCopyCaseD(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A and B with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+	createSampleDir(t, tmpDirB)
+
+	srcPath := filepath.Join(tmpDirA, "file1")
+	dstDir := filepath.Join(tmpDirB, "dir1")
+	dstPath := filepath.Join(dstDir, "file1")
+
+	var err error
+
+	// Ensure that dstPath doesn't exist.
+	if _, err = os.Stat(dstPath); !os.IsNotExist(err) {
+		t.Fatalf("did not expect dstPath %q to exist", dstPath)
+	}
+
+	if err = testCopyHelper(t, srcPath, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = fileContentsEqual(t, srcPath, dstPath)
+	assert.NilError(t, err)
+
+	// Now try again but using a trailing path separator for dstDir.
+
+	if err = os.RemoveAll(dstDir); err != nil {
+		t.Fatalf("unable to remove dstDir: %s", err)
+	}
+
+	if err = os.MkdirAll(dstDir, os.FileMode(0o755)); err != nil {
+		t.Fatalf("unable to make dstDir: %s", err)
+	}
+
+	dstDir = joinTrailingSep(tmpDirB, "dir1")
+
+	if err = testCopyHelper(t, srcPath, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = fileContentsEqual(t, srcPath, dstPath)
+	assert.NilError(t, err)
+}
+
+// D. Symbol link following version: SRC specifies a file and DST exists as a directory.
+//
+// This should place a copy of the source file inside it using the basename from
+// SRC. Ensure this works whether DST has a trailing path separator or not.
+func TestCopyCaseDFSym(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A and B with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+	createSampleDir(t, tmpDirB)
+
+	srcPath := filepath.Join(tmpDirA, "symlink4")
+	linkTarget := filepath.Join(tmpDirA, "file1")
+	dstDir := filepath.Join(tmpDirB, "dir1")
+	dstPath := filepath.Join(dstDir, "symlink4")
+
+	var err error
+
+	// Ensure that dstPath doesn't exist.
+	if _, err = os.Stat(dstPath); !os.IsNotExist(err) {
+		t.Fatalf("did not expect dstPath %q to exist", dstPath)
+	}
+
+	if err = testCopyHelperFSym(t, srcPath, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = fileContentsEqual(t, linkTarget, dstPath)
+	assert.NilError(t, err)
+
+	// Now try again but using a trailing path separator for dstDir.
+
+	if err = os.RemoveAll(dstDir); err != nil {
+		t.Fatalf("unable to remove dstDir: %s", err)
+	}
+
+	if err = os.MkdirAll(dstDir, os.FileMode(0o755)); err != nil {
+		t.Fatalf("unable to make dstDir: %s", err)
+	}
+
+	dstDir = joinTrailingSep(tmpDirB, "dir1")
+
+	if err = testCopyHelperFSym(t, srcPath, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = fileContentsEqual(t, linkTarget, dstPath)
+	assert.NilError(t, err)
+}
+
+// E. SRC specifies a directory and DST does not exist.
+//
+// This should create a directory at DST and copy the contents of the SRC directory
+// into the DST directory. Ensure this works whether DST has a trailing path
+// separator or not.
+func TestCopyCaseE(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+
+	srcDir := filepath.Join(tmpDirA, "dir1")
+	dstDir := filepath.Join(tmpDirB, "testDir")
+
+	var err error
+
+	if err = testCopyHelper(t, srcDir, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	if err = dirContentsEqual(t, dstDir, srcDir); err != nil {
+		t.Log("dir contents not equal")
+		logDirContents(t, tmpDirA)
+		logDirContents(t, tmpDirB)
+		t.Fatal(err)
+	}
+
+	// Now try again but using a trailing path separator for dstDir.
+
+	if err = os.RemoveAll(dstDir); err != nil {
+		t.Fatalf("unable to remove dstDir: %s", err)
+	}
+
+	dstDir = joinTrailingSep(tmpDirB, "testDir")
+
+	if err = testCopyHelper(t, srcDir, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = dirContentsEqual(t, dstDir, srcDir)
+	assert.NilError(t, err)
+}
+
+// E. Symbol link following version: SRC specifies a directory and DST does not exist.
+//
+// This should create a directory at DST and copy the contents of the SRC directory
+// into the DST directory. Ensure this works whether DST has a trailing path
+// separator or	not.
+func TestCopyCaseEFSym(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+
+	srcDir := filepath.Join(tmpDirA, "dirSymlink")
+	linkTarget := filepath.Join(tmpDirA, "dir1")
+	dstDir := filepath.Join(tmpDirB, "testDir")
+
+	var err error
+
+	if err = testCopyHelperFSym(t, srcDir, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	if err = dirContentsEqual(t, dstDir, linkTarget); err != nil {
+		t.Log("dir contents not equal")
+		logDirContents(t, tmpDirA)
+		logDirContents(t, tmpDirB)
+		t.Fatal(err)
+	}
+
+	// Now try again but using a trailing path separator for dstDir.
+
+	if err = os.RemoveAll(dstDir); err != nil {
+		t.Fatalf("unable to remove dstDir: %s", err)
+	}
+
+	dstDir = joinTrailingSep(tmpDirB, "testDir")
+
+	if err = testCopyHelperFSym(t, srcDir, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = dirContentsEqual(t, dstDir, linkTarget)
+	assert.NilError(t, err)
+}
+
+// F. SRC specifies a directory and DST exists as a file.
+//
+// This should cause an	error as it is not possible to overwrite a file with a
+// directory.
+func TestCopyCaseF(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A and B with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+	createSampleDir(t, tmpDirB)
+
+	srcDir := filepath.Join(tmpDirA, "dir1")
+	symSrcDir := filepath.Join(tmpDirA, "dirSymlink")
+	dstFile := filepath.Join(tmpDirB, "file1")
+
+	var err error
+
+	if err = testCopyHelper(t, srcDir, dstFile); err == nil {
+		t.Fatal("expected ErrCannotCopyDir error, but got nil instead")
+	}
+
+	if err != ErrCannotCopyDir {
+		t.Fatalf("expected ErrCannotCopyDir error, but got %T: %s", err, err)
+	}
+
+	// now test with symbol link
+	if err = testCopyHelperFSym(t, symSrcDir, dstFile); err == nil {
+		t.Fatal("expected ErrCannotCopyDir error, but got nil instead")
+	}
+
+	if err != ErrCannotCopyDir {
+		t.Fatalf("expected ErrCannotCopyDir error, but got %T: %s", err, err)
+	}
+}
+
+// G. SRC specifies a directory and DST exists as a directory.
+//
+// This should copy	the SRC directory and all its contents to the DST directory.
+// Ensure this works whether DST has a trailing path separator or not.
+func TestCopyCaseG(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A and B with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+	createSampleDir(t, tmpDirB)
+
+	srcDir := filepath.Join(tmpDirA, "dir1")
+	dstDir := filepath.Join(tmpDirB, "dir2")
+	resultDir := filepath.Join(dstDir, "dir1")
+
+	var err error
+
+	if err = testCopyHelper(t, srcDir, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = dirContentsEqual(t, resultDir, srcDir)
+	assert.NilError(t, err)
+
+	// Now try again but using a trailing path separator for dstDir.
+
+	if err = os.RemoveAll(dstDir); err != nil {
+		t.Fatalf("unable to remove dstDir: %s", err)
+	}
+
+	if err = os.MkdirAll(dstDir, os.FileMode(0o755)); err != nil {
+		t.Fatalf("unable to make dstDir: %s", err)
+	}
+
+	dstDir = joinTrailingSep(tmpDirB, "dir2")
+
+	if err = testCopyHelper(t, srcDir, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = dirContentsEqual(t, resultDir, srcDir)
+	assert.NilError(t, err)
+}
+
+// G. Symbol link version: SRC specifies a directory and DST exists as a directory.
+//
+// This should copy the SRC directory and all its contents to the DST directory.
+// Ensure this works whether DST has a trailing path separator or not.
+func TestCopyCaseGFSym(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A and B with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+	createSampleDir(t, tmpDirB)
+
+	srcDir := filepath.Join(tmpDirA, "dirSymlink")
+	linkTarget := filepath.Join(tmpDirA, "dir1")
+	dstDir := filepath.Join(tmpDirB, "dir2")
+	resultDir := filepath.Join(dstDir, "dirSymlink")
+
+	var err error
+
+	if err = testCopyHelperFSym(t, srcDir, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = dirContentsEqual(t, resultDir, linkTarget)
+	assert.NilError(t, err)
+
+	// Now try again but using a trailing path separator for dstDir.
+
+	if err = os.RemoveAll(dstDir); err != nil {
+		t.Fatalf("unable to remove dstDir: %s", err)
+	}
+
+	if err = os.MkdirAll(dstDir, os.FileMode(0o755)); err != nil {
+		t.Fatalf("unable to make dstDir: %s", err)
+	}
+
+	dstDir = joinTrailingSep(tmpDirB, "dir2")
+
+	if err = testCopyHelperFSym(t, srcDir, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = dirContentsEqual(t, resultDir, linkTarget)
+	assert.NilError(t, err)
+}
+
+// H. SRC specifies a directory's contents only and DST does not exist.
+//
+// This	should create a directory at DST and copy the contents of the SRC
+// directory (but not the directory itself) into the DST directory. Ensure
+// this works whether DST has a trailing path separator or not.
+func TestCopyCaseH(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+
+	srcDir := joinTrailingSep(tmpDirA, "dir1") + "."
+	dstDir := filepath.Join(tmpDirB, "testDir")
+
+	var err error
+
+	if err = testCopyHelper(t, srcDir, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	if err = dirContentsEqual(t, dstDir, srcDir); err != nil {
+		t.Log("dir contents not equal")
+		logDirContents(t, tmpDirA)
+		logDirContents(t, tmpDirB)
+		t.Fatal(err)
+	}
+
+	// Now try again but using a trailing path separator for dstDir.
+
+	if err = os.RemoveAll(dstDir); err != nil {
+		t.Fatalf("unable to remove dstDir: %s", err)
+	}
+
+	dstDir = joinTrailingSep(tmpDirB, "testDir")
+
+	if err = testCopyHelper(t, srcDir, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	if err = dirContentsEqual(t, dstDir, srcDir); err != nil {
+		t.Log("dir contents not equal")
+		logDirContents(t, tmpDirA)
+		logDirContents(t, tmpDirB)
+		t.Fatal(err)
+	}
+}
+
+// H. Symbol link following version: SRC specifies a directory's contents only and DST does not exist.
+//
+// This	should create a directory at DST and copy the contents of the SRC
+// directory (but not the directory itself) into the DST directory. Ensure
+// this works whether DST has a trailing path separator or not.
+func TestCopyCaseHFSym(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+
+	srcDir := joinTrailingSep(tmpDirA, "dirSymlink") + "."
+	linkTarget := filepath.Join(tmpDirA, "dir1")
+	dstDir := filepath.Join(tmpDirB, "testDir")
+
+	var err error
+
+	if err = testCopyHelperFSym(t, srcDir, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	if err = dirContentsEqual(t, dstDir, linkTarget); err != nil {
+		t.Log("dir contents not equal")
+		logDirContents(t, tmpDirA)
+		logDirContents(t, tmpDirB)
+		t.Fatal(err)
+	}
+
+	// Now try again but using a trailing path separator for dstDir.
+
+	if err = os.RemoveAll(dstDir); err != nil {
+		t.Fatalf("unable to remove dstDir: %s", err)
+	}
+
+	dstDir = joinTrailingSep(tmpDirB, "testDir")
+
+	if err = testCopyHelperFSym(t, srcDir, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	if err = dirContentsEqual(t, dstDir, linkTarget); err != nil {
+		t.Log("dir contents not equal")
+		logDirContents(t, tmpDirA)
+		logDirContents(t, tmpDirB)
+		t.Fatal(err)
+	}
+}
+
+// I. SRC specifies a directory's contents only and DST exists as a file.
+//
+// This	should cause an error as it is not possible to overwrite a file with a
+// directory.
+func TestCopyCaseI(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A and B with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+	createSampleDir(t, tmpDirB)
+
+	srcDir := joinTrailingSep(tmpDirA, "dir1") + "."
+	symSrcDir := filepath.Join(tmpDirB, "dirSymlink")
+	dstFile := filepath.Join(tmpDirB, "file1")
+
+	var err error
+
+	if err = testCopyHelper(t, srcDir, dstFile); err == nil {
+		t.Fatal("expected ErrCannotCopyDir error, but got nil instead")
+	}
+
+	if err != ErrCannotCopyDir {
+		t.Fatalf("expected ErrCannotCopyDir error, but got %T: %s", err, err)
+	}
+
+	// now try with symbol link of dir
+	if err = testCopyHelperFSym(t, symSrcDir, dstFile); err == nil {
+		t.Fatal("expected ErrCannotCopyDir error, but got nil instead")
+	}
+
+	if err != ErrCannotCopyDir {
+		t.Fatalf("expected ErrCannotCopyDir error, but got %T: %s", err, err)
+	}
+}
+
+// J. SRC specifies a directory's contents only and DST exists as a directory.
+//
+// This should copy the contents of the SRC directory (but not the directory
+// itself) into the DST directory. Ensure this works whether DST has a
+// trailing path separator or not.
+func TestCopyCaseJ(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A and B with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+	createSampleDir(t, tmpDirB)
+
+	srcDir := joinTrailingSep(tmpDirA, "dir1") + "."
+	dstDir := filepath.Join(tmpDirB, "dir5")
+
+	var err error
+
+	// first to create an empty dir
+	if err = os.MkdirAll(dstDir, os.FileMode(0o755)); err != nil {
+		t.Fatalf("unable to make dstDir: %s", err)
+	}
+
+	if err = testCopyHelper(t, srcDir, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = dirContentsEqual(t, dstDir, srcDir)
+	assert.NilError(t, err)
+
+	// Now try again but using a trailing path separator for dstDir.
+
+	if err = os.RemoveAll(dstDir); err != nil {
+		t.Fatalf("unable to remove dstDir: %s", err)
+	}
+
+	if err = os.MkdirAll(dstDir, os.FileMode(0o755)); err != nil {
+		t.Fatalf("unable to make dstDir: %s", err)
+	}
+
+	dstDir = joinTrailingSep(tmpDirB, "dir5")
+
+	if err = testCopyHelper(t, srcDir, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = dirContentsEqual(t, dstDir, srcDir)
+	assert.NilError(t, err)
+}
+
+// J. Symbol link following version: SRC specifies a directory's contents only and DST exists as a directory.
+//
+// This should copy the contents of the SRC directory (but not the directory
+// itself) into the DST directory. Ensure this works whether DST has a
+// trailing path separator or not.
+func TestCopyCaseJFSym(t *testing.T) {
+	tmpDirA, tmpDirB := getTestTempDirs(t)
+	defer removeAllPaths(tmpDirA, tmpDirB)
+
+	// Load A and B with some sample files and directories.
+	createSampleDir(t, tmpDirA)
+	createSampleDir(t, tmpDirB)
+
+	srcDir := joinTrailingSep(tmpDirA, "dirSymlink") + "."
+	linkTarget := filepath.Join(tmpDirA, "dir1")
+	dstDir := filepath.Join(tmpDirB, "dir5")
+
+	var err error
+
+	// first to create an empty dir
+	if err = os.MkdirAll(dstDir, os.FileMode(0o755)); err != nil {
+		t.Fatalf("unable to make dstDir: %s", err)
+	}
+
+	if err = testCopyHelperFSym(t, srcDir, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = dirContentsEqual(t, dstDir, linkTarget)
+	assert.NilError(t, err)
+
+	// Now try again but using a trailing path separator for dstDir.
+
+	if err = os.RemoveAll(dstDir); err != nil {
+		t.Fatalf("unable to remove dstDir: %s", err)
+	}
+
+	if err = os.MkdirAll(dstDir, os.FileMode(0o755)); err != nil {
+		t.Fatalf("unable to make dstDir: %s", err)
+	}
+
+	dstDir = joinTrailingSep(tmpDirB, "dir5")
+
+	if err = testCopyHelperFSym(t, srcDir, dstDir); err != nil {
+		t.Fatalf("unexpected error %T: %s", err, err)
+	}
+
+	err = dirContentsEqual(t, dstDir, linkTarget)
+	assert.NilError(t, err)
+}
diff --git a/vendor/github.com/moby/go-archive/copy_windows.go b/pkg/archive/copy_windows.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/copy_windows.go
rename to pkg/archive/copy_windows.go
diff --git a/vendor/github.com/moby/go-archive/dev_freebsd.go b/pkg/archive/dev_freebsd.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/dev_freebsd.go
rename to pkg/archive/dev_freebsd.go
diff --git a/vendor/github.com/moby/go-archive/dev_unix.go b/pkg/archive/dev_unix.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/dev_unix.go
rename to pkg/archive/dev_unix.go
diff --git a/vendor/github.com/moby/go-archive/diff.go b/pkg/archive/diff.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/diff.go
rename to pkg/archive/diff.go
diff --git a/pkg/archive/diff_deprecated.go b/pkg/archive/diff_deprecated.go
deleted file mode 100644
index dd5e0d5ef5..0000000000
--- a/pkg/archive/diff_deprecated.go
+++ /dev/null
@@ -1,37 +0,0 @@
-package archive
-
-import (
-	"io"
-
-	"github.com/moby/go-archive"
-)
-
-// UnpackLayer unpack `layer` to a `dest`.
-//
-// Deprecated: use [archive.UnpackLayer] instead.
-func UnpackLayer(dest string, layer io.Reader, options *TarOptions) (size int64, err error) {
-	return archive.UnpackLayer(dest, layer, toArchiveOpt(options))
-}
-
-// ApplyLayer parses a diff in the standard layer format from `layer`,
-// and applies it to the directory `dest`.
-//
-// Deprecated: use [archive.ApplyLayer] instead.
-func ApplyLayer(dest string, layer io.Reader) (int64, error) {
-	return archive.ApplyLayer(dest, layer)
-}
-
-// ApplyUncompressedLayer parses a diff in the standard layer format from
-// `layer`, and applies it to the directory `dest`.
-//
-// Deprecated: use [archive.ApplyUncompressedLayer] instead.
-func ApplyUncompressedLayer(dest string, layer io.Reader, options *TarOptions) (int64, error) {
-	return archive.ApplyUncompressedLayer(dest, layer, toArchiveOpt(options))
-}
-
-// IsEmpty checks if the tar archive is empty (doesn't contain any entries).
-//
-// Deprecated: use [archive.IsEmpty] instead.
-func IsEmpty(rd io.Reader) (bool, error) {
-	return archive.IsEmpty(rd)
-}
diff --git a/pkg/archive/diff_test.go b/pkg/archive/diff_test.go
new file mode 100644
index 0000000000..b7a205fe75
--- /dev/null
+++ b/pkg/archive/diff_test.go
@@ -0,0 +1,372 @@
+package archive
+
+import (
+	"archive/tar"
+	"io"
+	"os"
+	"path/filepath"
+	"reflect"
+	"testing"
+)
+
+func TestApplyLayerInvalidFilenames(t *testing.T) {
+	for i, headers := range [][]*tar.Header{
+		{
+			{
+				Name:     "../victim/dotdot",
+				Typeflag: tar.TypeReg,
+				Mode:     0o644,
+			},
+		},
+		{
+			{
+				// Note the leading slash
+				Name:     "/../victim/slash-dotdot",
+				Typeflag: tar.TypeReg,
+				Mode:     0o644,
+			},
+		},
+	} {
+		if err := testBreakout("applylayer", "docker-TestApplyLayerInvalidFilenames", headers); err != nil {
+			t.Fatalf("i=%d. %v", i, err)
+		}
+	}
+}
+
+func TestApplyLayerInvalidHardlink(t *testing.T) {
+	for i, headers := range [][]*tar.Header{
+		{ // try reading victim/hello (../)
+			{
+				Name:     "dotdot",
+				Typeflag: tar.TypeLink,
+				Linkname: "../victim/hello",
+				Mode:     0o644,
+			},
+		},
+		{ // try reading victim/hello (/../)
+			{
+				Name:     "slash-dotdot",
+				Typeflag: tar.TypeLink,
+				// Note the leading slash
+				Linkname: "/../victim/hello",
+				Mode:     0o644,
+			},
+		},
+		{ // try writing victim/file
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeLink,
+				Linkname: "../victim",
+				Mode:     0o755,
+			},
+			{
+				Name:     "loophole-victim/file",
+				Typeflag: tar.TypeReg,
+				Mode:     0o644,
+			},
+		},
+		{ // try reading victim/hello (hardlink, symlink)
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeLink,
+				Linkname: "../victim",
+				Mode:     0o755,
+			},
+			{
+				Name:     "symlink",
+				Typeflag: tar.TypeSymlink,
+				Linkname: "loophole-victim/hello",
+				Mode:     0o644,
+			},
+		},
+		{ // Try reading victim/hello (hardlink, hardlink)
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeLink,
+				Linkname: "../victim",
+				Mode:     0o755,
+			},
+			{
+				Name:     "hardlink",
+				Typeflag: tar.TypeLink,
+				Linkname: "loophole-victim/hello",
+				Mode:     0o644,
+			},
+		},
+		{ // Try removing victim directory (hardlink)
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeLink,
+				Linkname: "../victim",
+				Mode:     0o755,
+			},
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeReg,
+				Mode:     0o644,
+			},
+		},
+	} {
+		if err := testBreakout("applylayer", "docker-TestApplyLayerInvalidHardlink", headers); err != nil {
+			t.Fatalf("i=%d. %v", i, err)
+		}
+	}
+}
+
+func TestApplyLayerInvalidSymlink(t *testing.T) {
+	for i, headers := range [][]*tar.Header{
+		{ // try reading victim/hello (../)
+			{
+				Name:     "dotdot",
+				Typeflag: tar.TypeSymlink,
+				Linkname: "../victim/hello",
+				Mode:     0o644,
+			},
+		},
+		{ // try reading victim/hello (/../)
+			{
+				Name:     "slash-dotdot",
+				Typeflag: tar.TypeSymlink,
+				// Note the leading slash
+				Linkname: "/../victim/hello",
+				Mode:     0o644,
+			},
+		},
+		{ // try writing victim/file
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeSymlink,
+				Linkname: "../victim",
+				Mode:     0o755,
+			},
+			{
+				Name:     "loophole-victim/file",
+				Typeflag: tar.TypeReg,
+				Mode:     0o644,
+			},
+		},
+		{ // try reading victim/hello (symlink, symlink)
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeSymlink,
+				Linkname: "../victim",
+				Mode:     0o755,
+			},
+			{
+				Name:     "symlink",
+				Typeflag: tar.TypeSymlink,
+				Linkname: "loophole-victim/hello",
+				Mode:     0o644,
+			},
+		},
+		{ // try reading victim/hello (symlink, hardlink)
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeSymlink,
+				Linkname: "../victim",
+				Mode:     0o755,
+			},
+			{
+				Name:     "hardlink",
+				Typeflag: tar.TypeLink,
+				Linkname: "loophole-victim/hello",
+				Mode:     0o644,
+			},
+		},
+		{ // try removing victim directory (symlink)
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeSymlink,
+				Linkname: "../victim",
+				Mode:     0o755,
+			},
+			{
+				Name:     "loophole-victim",
+				Typeflag: tar.TypeReg,
+				Mode:     0o644,
+			},
+		},
+	} {
+		if err := testBreakout("applylayer", "docker-TestApplyLayerInvalidSymlink", headers); err != nil {
+			t.Fatalf("i=%d. %v", i, err)
+		}
+	}
+}
+
+func TestApplyLayerWhiteouts(t *testing.T) {
+	wd, err := os.MkdirTemp("", "graphdriver-test-whiteouts")
+	if err != nil {
+		return
+	}
+	defer os.RemoveAll(wd)
+
+	base := []string{
+		".baz",
+		"bar/",
+		"bar/bax",
+		"bar/bay/",
+		"baz",
+		"foo/",
+		"foo/.abc",
+		"foo/.bcd/",
+		"foo/.bcd/a",
+		"foo/cde/",
+		"foo/cde/def",
+		"foo/cde/efg",
+		"foo/fgh",
+		"foobar",
+	}
+
+	type tcase struct {
+		change, expected []string
+	}
+
+	tcases := []tcase{
+		{
+			change:   base,
+			expected: base,
+		},
+		{
+			change: []string{
+				".bay",
+				".wh.baz",
+				"foo/",
+				"foo/.bce",
+				"foo/.wh..wh..opq",
+				"foo/cde/",
+				"foo/cde/efg",
+			},
+			expected: []string{
+				".bay",
+				".baz",
+				"bar/",
+				"bar/bax",
+				"bar/bay/",
+				"foo/",
+				"foo/.bce",
+				"foo/cde/",
+				"foo/cde/efg",
+				"foobar",
+			},
+		},
+		{
+			change: []string{
+				".bay",
+				".wh..baz",
+				".wh.foobar",
+				"foo/",
+				"foo/.abc",
+				"foo/.wh.cde",
+				"bar/",
+			},
+			expected: []string{
+				".bay",
+				"bar/",
+				"bar/bax",
+				"bar/bay/",
+				"foo/",
+				"foo/.abc",
+				"foo/.bce",
+			},
+		},
+		{
+			change: []string{
+				".abc",
+				".wh..wh..opq",
+				"foobar",
+			},
+			expected: []string{
+				".abc",
+				"foobar",
+			},
+		},
+	}
+
+	for i, tc := range tcases {
+		l, err := makeTestLayer(tc.change)
+		if err != nil {
+			t.Fatal(err)
+		}
+
+		_, err = UnpackLayer(wd, l, nil)
+		if err != nil {
+			t.Fatal(err)
+		}
+		err = l.Close()
+		if err != nil {
+			t.Fatal(err)
+		}
+
+		paths, err := readDirContents(wd)
+		if err != nil {
+			t.Fatal(err)
+		}
+
+		if !reflect.DeepEqual(tc.expected, paths) {
+			t.Fatalf("invalid files for layer %d: expected %q, got %q", i, tc.expected, paths)
+		}
+	}
+}
+
+func makeTestLayer(paths []string) (_ io.ReadCloser, retErr error) {
+	tmpDir, err := os.MkdirTemp("", "graphdriver-test-mklayer")
+	if err != nil {
+		return nil, err
+	}
+	defer func() {
+		if retErr != nil {
+			os.RemoveAll(tmpDir)
+		}
+	}()
+	for _, p := range paths {
+		// Source files are always in Unix format. But we use filepath on
+		// creation to be platform agnostic.
+		if p[len(p)-1] == '/' {
+			if err = os.MkdirAll(filepath.Join(tmpDir, p), 0o700); err != nil {
+				return nil, err
+			}
+		} else {
+			if err = os.WriteFile(filepath.Join(tmpDir, p), nil, 0o600); err != nil {
+				return nil, err
+			}
+		}
+	}
+	archive, err := Tar(tmpDir, Uncompressed)
+	if err != nil {
+		return nil, err
+	}
+	return &readCloserWrapper{
+		Reader: archive,
+		closer: func() error {
+			err := archive.Close()
+			os.RemoveAll(tmpDir)
+			return err
+		},
+	}, nil
+}
+
+func readDirContents(root string) ([]string, error) {
+	var files []string
+	err := filepath.Walk(root, func(path string, info os.FileInfo, err error) error {
+		if err != nil {
+			return err
+		}
+		if path == root {
+			return nil
+		}
+		rel, err := filepath.Rel(root, path)
+		if err != nil {
+			return err
+		}
+		if info.IsDir() {
+			rel = rel + string(filepath.Separator)
+		}
+		// Append in Unix semantics
+		files = append(files, filepath.ToSlash(rel))
+		return nil
+	})
+	if err != nil {
+		return nil, err
+	}
+	return files, nil
+}
diff --git a/vendor/github.com/moby/go-archive/diff_unix.go b/pkg/archive/diff_unix.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/diff_unix.go
rename to pkg/archive/diff_unix.go
diff --git a/vendor/github.com/moby/go-archive/diff_windows.go b/pkg/archive/diff_windows.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/diff_windows.go
rename to pkg/archive/diff_windows.go
diff --git a/pkg/archive/example_changes.go b/pkg/archive/example_changes.go
new file mode 100644
index 0000000000..44ad1ee2da
--- /dev/null
+++ b/pkg/archive/example_changes.go
@@ -0,0 +1,96 @@
+//go:build ignore
+
+// Simple tool to create an archive stream from an old and new directory
+//
+// By default it will stream the comparison of two temporary directories with junk files
+package main
+
+import (
+	"flag"
+	"fmt"
+	"io"
+	"os"
+	"path"
+
+	"github.com/containerd/log"
+	"github.com/docker/docker/pkg/archive"
+)
+
+var (
+	flDebug  = flag.Bool("D", false, "debugging output")
+	flNewDir = flag.String("newdir", "", "")
+	flOldDir = flag.String("olddir", "", "")
+	log      = log.G(ctx).New()
+)
+
+func main() {
+	flag.Usage = func() {
+		fmt.Println("Produce a tar from comparing two directory paths. By default a demo tar is created of around 200 files (including hardlinks)")
+		fmt.Printf("%s [OPTIONS]\n", os.Args[0])
+		flag.PrintDefaults()
+	}
+	flag.Parse()
+	log.Out = os.Stderr
+	if (len(os.Getenv("DEBUG")) > 0) || *flDebug {
+		log.G(ctx).SetLevel(logrus.DebugLevel)
+	}
+	var newDir, oldDir string
+
+	if len(*flNewDir) == 0 {
+		var err error
+		newDir, err = os.MkdirTemp("", "docker-test-newDir")
+		if err != nil {
+			log.Fatal(err)
+		}
+		defer os.RemoveAll(newDir)
+		if _, err := prepareUntarSourceDirectory(100, newDir, true); err != nil {
+			log.Fatal(err)
+		}
+	} else {
+		newDir = *flNewDir
+	}
+
+	if len(*flOldDir) == 0 {
+		oldDir, err := os.MkdirTemp("", "docker-test-oldDir")
+		if err != nil {
+			log.Fatal(err)
+		}
+		defer os.RemoveAll(oldDir)
+	} else {
+		oldDir = *flOldDir
+	}
+
+	changes, err := archive.ChangesDirs(newDir, oldDir)
+	if err != nil {
+		log.Fatal(err)
+	}
+
+	a, err := archive.ExportChanges(newDir, changes)
+	if err != nil {
+		log.Fatal(err)
+	}
+	defer a.Close()
+
+	i, err := io.Copy(os.Stdout, a)
+	if err != nil && err != io.EOF {
+		log.Fatal(err)
+	}
+	fmt.Fprintf(os.Stderr, "wrote archive of %d bytes", i)
+}
+
+func prepareUntarSourceDirectory(numberOfFiles int, targetPath string, makeLinks bool) (int, error) {
+	fileData := []byte("fooo")
+	for n := 0; n < numberOfFiles; n++ {
+		fileName := fmt.Sprintf("file-%d", n)
+		if err := os.WriteFile(path.Join(targetPath, fileName), fileData, 0o700); err != nil {
+			return 0, err
+		}
+		if makeLinks {
+			if err := os.Link(path.Join(targetPath, fileName), path.Join(targetPath, fileName+"-link")); err != nil {
+				return 0, err
+			}
+		}
+	}
+	totalSize := numberOfFiles * len(fileData)
+	return totalSize, nil
+}
diff --git a/pkg/archive/fuzz_test.go b/pkg/archive/fuzz_test.go
new file mode 100644
index 0000000000..011e175f79
--- /dev/null
+++ b/pkg/archive/fuzz_test.go
@@ -0,0 +1,39 @@
+package archive
+
+import (
+	"bytes"
+	"testing"
+
+	fuzz "github.com/AdaLogics/go-fuzz-headers"
+)
+
+func FuzzDecompressStream(f *testing.F) {
+	f.Fuzz(func(t *testing.T, data []byte) {
+		r := bytes.NewReader(data)
+		_, _ = DecompressStream(r)
+	})
+}
+
+func FuzzUntar(f *testing.F) {
+	f.Fuzz(func(t *testing.T, data []byte) {
+		ff := fuzz.NewConsumer(data)
+		tarBytes, err := ff.TarBytes()
+		if err != nil {
+			return
+		}
+		options := &TarOptions{}
+		err = ff.GenerateStruct(options)
+		if err != nil {
+			return
+		}
+		tmpDir := t.TempDir()
+		Untar(bytes.NewReader(tarBytes), tmpDir, options)
+	})
+}
+
+func FuzzApplyLayer(f *testing.F) {
+	f.Fuzz(func(t *testing.T, data []byte) {
+		tmpDir := t.TempDir()
+		_, _ = ApplyLayer(tmpDir, bytes.NewReader(data))
+	})
+}
diff --git a/vendor/github.com/moby/go-archive/path.go b/pkg/archive/path.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/path.go
rename to pkg/archive/path.go
diff --git a/pkg/archive/path_deprecated.go b/pkg/archive/path_deprecated.go
deleted file mode 100644
index 0fa74de68f..0000000000
--- a/pkg/archive/path_deprecated.go
+++ /dev/null
@@ -1,10 +0,0 @@
-package archive
-
-import "github.com/moby/go-archive"
-
-// CheckSystemDriveAndRemoveDriveLetter verifies that a path is the system drive.
-//
-// Deprecated: use [archive.CheckSystemDriveAndRemoveDriveLetter] instead.
-func CheckSystemDriveAndRemoveDriveLetter(path string) (string, error) {
-	return archive.CheckSystemDriveAndRemoveDriveLetter(path)
-}
diff --git a/vendor/github.com/moby/go-archive/path_unix.go b/pkg/archive/path_unix.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/path_unix.go
rename to pkg/archive/path_unix.go
diff --git a/vendor/github.com/moby/go-archive/path_windows.go b/pkg/archive/path_windows.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/path_windows.go
rename to pkg/archive/path_windows.go
diff --git a/pkg/archive/path_windows_test.go b/pkg/archive/path_windows_test.go
new file mode 100644
index 0000000000..27d7c9a8f5
--- /dev/null
+++ b/pkg/archive/path_windows_test.go
@@ -0,0 +1,79 @@
+package archive
+
+import (
+	"testing"
+)
+
+// TestCheckSystemDriveAndRemoveDriveLetter tests CheckSystemDriveAndRemoveDriveLetter
+func TestCheckSystemDriveAndRemoveDriveLetter(t *testing.T) {
+	// Fails if not C drive.
+	_, err := CheckSystemDriveAndRemoveDriveLetter(`d:\`)
+	if err == nil || err.Error() != "the specified path is not on the system drive (C:)" {
+		t.Fatalf("Expected error for d:")
+	}
+
+	// Single character is unchanged
+	var path string
+	if path, err = CheckSystemDriveAndRemoveDriveLetter("z"); err != nil {
+		t.Fatalf("Single character should pass")
+	}
+	if path != "z" {
+		t.Fatalf("Single character should be unchanged")
+	}
+
+	// Two characters without colon is unchanged
+	if path, err = CheckSystemDriveAndRemoveDriveLetter("AB"); err != nil {
+		t.Fatalf("2 characters without colon should pass")
+	}
+	if path != "AB" {
+		t.Fatalf("2 characters without colon should be unchanged")
+	}
+
+	// Abs path without drive letter
+	if path, err = CheckSystemDriveAndRemoveDriveLetter(`\l`); err != nil {
+		t.Fatalf("abs path no drive letter should pass")
+	}
+	if path != `\l` {
+		t.Fatalf("abs path without drive letter should be unchanged")
+	}
+
+	// Abs path without drive letter, linux style
+	if path, err = CheckSystemDriveAndRemoveDriveLetter(`/l`); err != nil {
+		t.Fatalf("abs path no drive letter linux style should pass")
+	}
+	if path != `\l` {
+		t.Fatalf("abs path without drive letter linux failed %s", path)
+	}
+
+	// Drive-colon should be stripped
+	if path, err = CheckSystemDriveAndRemoveDriveLetter(`c:\`); err != nil {
+		t.Fatalf("An absolute path should pass")
+	}
+	if path != `\` {
+		t.Fatalf(`An absolute path should have been shortened to \ %s`, path)
+	}
+
+	// Verify with a linux-style path
+	if path, err = CheckSystemDriveAndRemoveDriveLetter(`c:/`); err != nil {
+		t.Fatalf("An absolute path should pass")
+	}
+	if path != `\` {
+		t.Fatalf(`A linux style absolute path should have been shortened to \ %s`, path)
+	}
+
+	// Failure on c:
+	if path, err = CheckSystemDriveAndRemoveDriveLetter(`c:`); err == nil {
+		t.Fatalf("c: should fail")
+	}
+	if err.Error() != `no relative path specified in "c:"` {
+		t.Fatalf(path, err)
+	}
+
+	// Failure on d:
+	if path, err = CheckSystemDriveAndRemoveDriveLetter(`d:`); err == nil {
+		t.Fatalf("c: should fail")
+	}
+	if err.Error() != `no relative path specified in "d:"` {
+		t.Fatalf(path, err)
+	}
+}
diff --git a/pkg/archive/testdata/broken.tar b/pkg/archive/testdata/broken.tar
new file mode 100644
index 0000000000..8f10ea6b87
Binary files /dev/null and b/pkg/archive/testdata/broken.tar differ
diff --git a/vendor/github.com/moby/go-archive/time.go b/pkg/archive/time.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/time.go
rename to pkg/archive/time.go
diff --git a/vendor/github.com/moby/go-archive/time_nonwindows.go b/pkg/archive/time_nonwindows.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/time_nonwindows.go
rename to pkg/archive/time_nonwindows.go
diff --git a/vendor/github.com/moby/go-archive/time_windows.go b/pkg/archive/time_windows.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/time_windows.go
rename to pkg/archive/time_windows.go
diff --git a/pkg/archive/utils.go b/pkg/archive/utils.go
deleted file mode 100644
index 692cf1602d..0000000000
--- a/pkg/archive/utils.go
+++ /dev/null
@@ -1,42 +0,0 @@
-package archive
-
-import (
-	"github.com/docker/docker/pkg/idtools"
-	"github.com/moby/go-archive"
-)
-
-// ToArchiveOpt converts an [TarOptions] to a [archive.TarOptions].
-//
-// Deprecated: use [archive.TarOptions] instead, this utility is for internal use to transition to the [github.com/moby/go-archive] module.
-func ToArchiveOpt(options *TarOptions) *archive.TarOptions {
-	return toArchiveOpt(options)
-}
-
-func toArchiveOpt(options *TarOptions) *archive.TarOptions {
-	if options == nil {
-		return nil
-	}
-
-	var chownOpts *archive.ChownOpts
-	if options.ChownOpts != nil {
-		chownOpts = &archive.ChownOpts{
-			UID: options.ChownOpts.UID,
-			GID: options.ChownOpts.GID,
-		}
-	}
-
-	return &archive.TarOptions{
-		IncludeFiles:         options.IncludeFiles,
-		ExcludePatterns:      options.ExcludePatterns,
-		Compression:          options.Compression,
-		NoLchown:             options.NoLchown,
-		IDMap:                idtools.ToUserIdentityMapping(options.IDMap),
-		ChownOpts:            chownOpts,
-		IncludeSourceDir:     options.IncludeSourceDir,
-		WhiteoutFormat:       options.WhiteoutFormat,
-		NoOverwriteDirNonDir: options.NoOverwriteDirNonDir,
-		RebaseNames:          options.RebaseNames,
-		InUserNS:             options.InUserNS,
-		BestEffortXattrs:     options.BestEffortXattrs,
-	}
-}
diff --git a/pkg/archive/utils_test.go b/pkg/archive/utils_test.go
new file mode 100644
index 0000000000..8e08b0252d
--- /dev/null
+++ b/pkg/archive/utils_test.go
@@ -0,0 +1,218 @@
+package archive
+
+import (
+	"archive/tar"
+	"bytes"
+	"fmt"
+	"io"
+	"os"
+	"path/filepath"
+	"time"
+)
+
+var testUntarFns = map[string]func(string, io.Reader) error{
+	"untar": func(dest string, r io.Reader) error {
+		return Untar(r, dest, nil)
+	},
+	"applylayer": func(dest string, r io.Reader) error {
+		_, err := ApplyLayer(dest, r)
+		return err
+	},
+}
+
+// testBreakout is a helper function that, within the provided `tmpdir` directory,
+// creates a `victim` folder with a generated `hello` file in it.
+// `untar` extracts to a directory named `dest`, the tar file created from `headers`.
+//
+// Here are the tested scenarios:
+// - removed `victim` folder				(write)
+// - removed files from `victim` folder			(write)
+// - new files in `victim` folder			(write)
+// - modified files in `victim` folder			(write)
+// - file in `dest` with same content as `victim/hello` (read)
+//
+// When using testBreakout make sure you cover one of the scenarios listed above.
+func testBreakout(untarFn string, tmpdir string, headers []*tar.Header) error {
+	tmpdir, err := os.MkdirTemp("", tmpdir)
+	if err != nil {
+		return err
+	}
+	defer os.RemoveAll(tmpdir)
+
+	dest := filepath.Join(tmpdir, "dest")
+	if err := os.Mkdir(dest, 0o755); err != nil {
+		return err
+	}
+
+	victim := filepath.Join(tmpdir, "victim")
+	if err := os.Mkdir(victim, 0o755); err != nil {
+		return err
+	}
+	hello := filepath.Join(victim, "hello")
+	helloData, err := time.Now().MarshalText()
+	if err != nil {
+		return err
+	}
+	if err := os.WriteFile(hello, helloData, 0o644); err != nil {
+		return err
+	}
+	helloStat, err := os.Stat(hello)
+	if err != nil {
+		return err
+	}
+
+	reader, writer := io.Pipe()
+	go func() {
+		t := tar.NewWriter(writer)
+		for _, hdr := range headers {
+			t.WriteHeader(hdr)
+		}
+		t.Close()
+	}()
+
+	untar := testUntarFns[untarFn]
+	if untar == nil {
+		return fmt.Errorf("could not find untar function %q in testUntarFns", untarFn)
+	}
+	if err := untar(dest, reader); err != nil {
+		if _, ok := err.(breakoutError); !ok {
+			// If untar returns an error unrelated to an archive breakout,
+			// then consider this an unexpected error and abort.
+			return err
+		}
+		// Here, untar detected the breakout.
+		// Let's move on verifying that indeed there was no breakout.
+		fmt.Printf("breakoutError: %v\n", err)
+	}
+
+	// Check victim folder
+	f, err := os.Open(victim)
+	if err != nil {
+		// codepath taken if victim folder was removed
+		return fmt.Errorf("archive breakout: error reading %q: %v", victim, err)
+	}
+	defer f.Close()
+
+	// Check contents of victim folder
+	//
+	// We are only interested in getting 2 files from the victim folder, because if all is well
+	// we expect only one result, the `hello` file. If there is a second result, it cannot
+	// hold the same name `hello` and we assume that a new file got created in the victim folder.
+	// That is enough to detect an archive breakout.
+	names, err := f.Readdirnames(2)
+	if err != nil {
+		// codepath taken if victim is not a folder
+		return fmt.Errorf("archive breakout: error reading directory content of %q: %v", victim, err)
+	}
+	for _, name := range names {
+		if name != "hello" {
+			// codepath taken if new file was created in victim folder
+			return fmt.Errorf("archive breakout: new file %q", name)
+		}
+	}
+
+	// Check victim/hello
+	f, err = os.Open(hello)
+	if err != nil {
+		// codepath taken if read permissions were removed
+		return fmt.Errorf("archive breakout: could not lstat %q: %v", hello, err)
+	}
+	defer f.Close()
+	b, err := io.ReadAll(f)
+	if err != nil {
+		return err
+	}
+	fi, err := f.Stat()
+	if err != nil {
+		return err
+	}
+	if helloStat.IsDir() != fi.IsDir() ||
+		// TODO: cannot check for fi.ModTime() change
+		helloStat.Mode() != fi.Mode() ||
+		helloStat.Size() != fi.Size() ||
+		!bytes.Equal(helloData, b) {
+		// codepath taken if hello has been modified
+		return fmt.Errorf("archive breakout: file %q has been modified. Contents: expected=%q, got=%q. FileInfo: expected=%#v, got=%#v", hello, helloData, b, helloStat, fi)
+	}
+
+	// Check that nothing in dest/ has the same content as victim/hello.
+	// Since victim/hello was generated with time.Now(), it is safe to assume
+	// that any file whose content matches exactly victim/hello, managed somehow
+	// to access victim/hello.
+	return filepath.WalkDir(dest, func(path string, info os.DirEntry, err error) error {
+		if info.IsDir() {
+			if err != nil {
+				// skip directory if error
+				return filepath.SkipDir
+			}
+			// enter directory
+			return nil
+		}
+		if err != nil {
+			// skip file if error
+			return nil
+		}
+		b, err := os.ReadFile(path)
+		if err != nil {
+			// Houston, we have a problem. Aborting (space)walk.
+			return err
+		}
+		if bytes.Equal(helloData, b) {
+			return fmt.Errorf("archive breakout: file %q has been accessed via %q", hello, path)
+		}
+		return nil
+	})
+}
+
+// newTempArchive reads the content of src into a temporary file, and returns the contents
+// of that file as an archive. The archive can only be read once - as soon as reading completes,
+// the file will be deleted.
+func newTempArchive(src io.Reader, dir string) (*tempArchive, error) {
+	f, err := os.CreateTemp(dir, "")
+	if err != nil {
+		return nil, err
+	}
+	if _, err := io.Copy(f, src); err != nil {
+		return nil, err
+	}
+	if _, err := f.Seek(0, 0); err != nil {
+		return nil, err
+	}
+	st, err := f.Stat()
+	if err != nil {
+		return nil, err
+	}
+	size := st.Size()
+	return &tempArchive{File: f, Size: size}, nil
+}
+
+// tempArchive is a temporary archive. The archive can only be read once - as soon as reading completes,
+// the file will be deleted.
+type tempArchive struct {
+	*os.File
+	Size   int64 // Pre-computed from Stat().Size() as a convenience
+	read   int64
+	closed bool
+}
+
+// Close closes the underlying file if it's still open, or does a no-op
+// to allow callers to try to close the tempArchive multiple times safely.
+func (archive *tempArchive) Close() error {
+	if archive.closed {
+		return nil
+	}
+
+	archive.closed = true
+
+	return archive.File.Close()
+}
+
+func (archive *tempArchive) Read(data []byte) (int, error) {
+	n, err := archive.File.Read(data)
+	archive.read += int64(n)
+	if err != nil || archive.read == archive.Size {
+		_ = archive.Close()
+		_ = os.Remove(archive.File.Name())
+	}
+	return n, err
+}
diff --git a/vendor/github.com/moby/go-archive/whiteouts.go b/pkg/archive/whiteouts.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/whiteouts.go
rename to pkg/archive/whiteouts.go
diff --git a/pkg/archive/whiteouts_deprecated.go b/pkg/archive/whiteouts_deprecated.go
deleted file mode 100644
index 0ab8590b14..0000000000
--- a/pkg/archive/whiteouts_deprecated.go
+++ /dev/null
@@ -1,10 +0,0 @@
-package archive
-
-import "github.com/moby/go-archive"
-
-const (
-	WhiteoutPrefix     = archive.WhiteoutPrefix     // Deprecated: use [archive.WhiteoutPrefix] instead.
-	WhiteoutMetaPrefix = archive.WhiteoutMetaPrefix // Deprecated: use [archive.WhiteoutMetaPrefix] instead.
-	WhiteoutLinkDir    = archive.WhiteoutLinkDir    // Deprecated: use [archive.WhiteoutLinkDir] instead.
-	WhiteoutOpaqueDir  = archive.WhiteoutOpaqueDir  // Deprecated: use [archive.WhiteoutOpaqueDir] instead.
-)
diff --git a/vendor/github.com/moby/go-archive/wrap.go b/pkg/archive/wrap.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/wrap.go
rename to pkg/archive/wrap.go
diff --git a/pkg/archive/wrap_deprecated.go b/pkg/archive/wrap_deprecated.go
deleted file mode 100644
index e5d3fa9a95..0000000000
--- a/pkg/archive/wrap_deprecated.go
+++ /dev/null
@@ -1,14 +0,0 @@
-package archive
-
-import (
-	"io"
-
-	"github.com/moby/go-archive"
-)
-
-// Generate generates a new archive from the content provided as input.
-//
-// Deprecated: use [archive.Generate] instead.
-func Generate(input ...string) (io.Reader, error) {
-	return archive.Generate(input...)
-}
diff --git a/pkg/archive/wrap_test.go b/pkg/archive/wrap_test.go
new file mode 100644
index 0000000000..6f62cea0dc
--- /dev/null
+++ b/pkg/archive/wrap_test.go
@@ -0,0 +1,92 @@
+package archive
+
+import (
+	"archive/tar"
+	"bytes"
+	"io"
+	"testing"
+
+	"gotest.tools/v3/assert"
+)
+
+func TestGenerateEmptyFile(t *testing.T) {
+	archive, err := Generate("emptyFile")
+	assert.NilError(t, err)
+	if archive == nil {
+		t.Fatal("The generated archive should not be nil.")
+	}
+
+	expectedFiles := [][]string{
+		{"emptyFile", ""},
+	}
+
+	tr := tar.NewReader(archive)
+	actualFiles := make([][]string, 0, 10)
+	i := 0
+	for {
+		hdr, err := tr.Next()
+		if err == io.EOF {
+			break
+		}
+		assert.NilError(t, err)
+		buf := new(bytes.Buffer)
+		buf.ReadFrom(tr)
+		content := buf.String()
+		actualFiles = append(actualFiles, []string{hdr.Name, content})
+		i++
+	}
+	if len(actualFiles) != len(expectedFiles) {
+		t.Fatalf("Number of expected file %d, got %d.", len(expectedFiles), len(actualFiles))
+	}
+	for i := 0; i < len(expectedFiles); i++ {
+		actual := actualFiles[i]
+		expected := expectedFiles[i]
+		if actual[0] != expected[0] {
+			t.Fatalf("Expected name '%s', Actual name '%s'", expected[0], actual[0])
+		}
+		if actual[1] != expected[1] {
+			t.Fatalf("Expected content '%s', Actual content '%s'", expected[1], actual[1])
+		}
+	}
+}
+
+func TestGenerateWithContent(t *testing.T) {
+	archive, err := Generate("file", "content")
+	assert.NilError(t, err)
+	if archive == nil {
+		t.Fatal("The generated archive should not be nil.")
+	}
+
+	expectedFiles := [][]string{
+		{"file", "content"},
+	}
+
+	tr := tar.NewReader(archive)
+	actualFiles := make([][]string, 0, 10)
+	i := 0
+	for {
+		hdr, err := tr.Next()
+		if err == io.EOF {
+			break
+		}
+		assert.NilError(t, err)
+		buf := new(bytes.Buffer)
+		buf.ReadFrom(tr)
+		content := buf.String()
+		actualFiles = append(actualFiles, []string{hdr.Name, content})
+		i++
+	}
+	if len(actualFiles) != len(expectedFiles) {
+		t.Fatalf("Number of expected file %d, got %d.", len(expectedFiles), len(actualFiles))
+	}
+	for i := 0; i < len(expectedFiles); i++ {
+		actual := actualFiles[i]
+		expected := expectedFiles[i]
+		if actual[0] != expected[0] {
+			t.Fatalf("Expected name '%s', Actual name '%s'", expected[0], actual[0])
+		}
+		if actual[1] != expected[1] {
+			t.Fatalf("Expected content '%s', Actual content '%s'", expected[1], actual[1])
+		}
+	}
+}
diff --git a/vendor/github.com/moby/go-archive/xattr_supported.go b/pkg/archive/xattr_supported.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/xattr_supported.go
rename to pkg/archive/xattr_supported.go
diff --git a/vendor/github.com/moby/go-archive/xattr_supported_linux.go b/pkg/archive/xattr_supported_linux.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/xattr_supported_linux.go
rename to pkg/archive/xattr_supported_linux.go
diff --git a/vendor/github.com/moby/go-archive/xattr_supported_unix.go b/pkg/archive/xattr_supported_unix.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/xattr_supported_unix.go
rename to pkg/archive/xattr_supported_unix.go
diff --git a/vendor/github.com/moby/go-archive/xattr_unsupported.go b/pkg/archive/xattr_unsupported.go
similarity index 100%
rename from vendor/github.com/moby/go-archive/xattr_unsupported.go
rename to pkg/archive/xattr_unsupported.go
diff --git a/vendor/github.com/moby/go-archive/chrootarchive/archive.go b/pkg/chrootarchive/archive.go
similarity index 91%
rename from vendor/github.com/moby/go-archive/chrootarchive/archive.go
rename to pkg/chrootarchive/archive.go
index a253429193..7f082586e2 100644
--- a/vendor/github.com/moby/go-archive/chrootarchive/archive.go
+++ b/pkg/chrootarchive/archive.go
@@ -6,13 +6,12 @@ import (
 	"os"
 	"path/filepath"
 
-	"github.com/moby/sys/user"
-
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
+	"github.com/docker/docker/pkg/idtools"
 )
 
 // NewArchiver returns a new Archiver which uses chrootarchive.Untar
-func NewArchiver(idMapping user.IdentityMapping) *archive.Archiver {
+func NewArchiver(idMapping idtools.IdentityMapping) *archive.Archiver {
 	return &archive.Archiver{
 		Untar:     Untar,
 		IDMapping: idMapping,
@@ -65,11 +64,11 @@ func untarHandler(tarArchive io.Reader, dest string, options *archive.TarOptions
 	// If dest is inside a root then directory is created within chroot by extractor.
 	// This case is only currently used by cp.
 	if dest == root {
-		uid, gid := options.IDMap.RootPair()
+		rootIDs := options.IDMap.RootPair()
 
 		dest = filepath.Clean(dest)
 		if _, err := os.Stat(dest); os.IsNotExist(err) {
-			if err := user.MkdirAllAndChown(dest, 0o755, uid, gid, user.WithOnlyNew); err != nil {
+			if err := idtools.MkdirAllAndChownNew(dest, 0o755, rootIDs); err != nil {
 				return err
 			}
 		}
diff --git a/pkg/chrootarchive/archive_deprecated.go b/pkg/chrootarchive/archive_deprecated.go
deleted file mode 100644
index 7e5d40a27f..0000000000
--- a/pkg/chrootarchive/archive_deprecated.go
+++ /dev/null
@@ -1,49 +0,0 @@
-package chrootarchive
-
-import (
-	"io"
-
-	"github.com/docker/docker/pkg/archive"
-	"github.com/docker/docker/pkg/idtools"
-	"github.com/moby/go-archive/chrootarchive"
-)
-
-// NewArchiver returns a new Archiver which uses chrootarchive.Untar
-//
-// Deprecated: use [chrootarchive.NewArchiver] instead.
-func NewArchiver(idMapping idtools.IdentityMapping) *archive.Archiver {
-	return &archive.Archiver{
-		Untar:     Untar,
-		IDMapping: idMapping,
-	}
-}
-
-// Untar reads a stream of bytes from `archive`, parses it as a tar archive,
-// and unpacks it into the directory at `dest`.
-//
-// Deprecated: use [chrootarchive.Untar] instead.
-func Untar(tarArchive io.Reader, dest string, options *archive.TarOptions) error {
-	return chrootarchive.Untar(tarArchive, dest, archive.ToArchiveOpt(options))
-}
-
-// UntarWithRoot is the same as [Untar], but allows you to pass in a root directory.
-//
-// Deprecated: use [chrootarchive.UntarWithRoot] instead.
-func UntarWithRoot(tarArchive io.Reader, dest string, options *archive.TarOptions, root string) error {
-	return chrootarchive.UntarWithRoot(tarArchive, dest, archive.ToArchiveOpt(options), root)
-}
-
-// UntarUncompressed reads a stream of bytes from tarArchive, parses it as a tar archive,
-// and unpacks it into the directory at dest.
-//
-// Deprecated: use [chrootarchive.UntarUncompressed] instead.
-func UntarUncompressed(tarArchive io.Reader, dest string, options *archive.TarOptions) error {
-	return chrootarchive.UntarUncompressed(tarArchive, dest, archive.ToArchiveOpt(options))
-}
-
-// Tar tars the requested path while chrooted to the specified root.
-//
-// Deprecated: use [chrootarchive.Tar] instead.
-func Tar(srcPath string, options *archive.TarOptions, root string) (io.ReadCloser, error) {
-	return chrootarchive.Tar(srcPath, archive.ToArchiveOpt(options), root)
-}
diff --git a/vendor/github.com/moby/go-archive/chrootarchive/archive_linux.go b/pkg/chrootarchive/archive_linux.go
similarity index 96%
rename from vendor/github.com/moby/go-archive/chrootarchive/archive_linux.go
rename to pkg/chrootarchive/archive_linux.go
index a3b73676d2..0c4f1c0473 100644
--- a/vendor/github.com/moby/go-archive/chrootarchive/archive_linux.go
+++ b/pkg/chrootarchive/archive_linux.go
@@ -4,9 +4,8 @@ import (
 	"fmt"
 	"io"
 
+	"github.com/docker/docker/pkg/archive"
 	"golang.org/x/sys/unix"
-
-	"github.com/moby/go-archive"
 )
 
 func doUnpack(decompressedArchive io.Reader, relDest, root string, options *archive.TarOptions) error {
diff --git a/pkg/chrootarchive/archive_test.go b/pkg/chrootarchive/archive_test.go
new file mode 100644
index 0000000000..d83d335751
--- /dev/null
+++ b/pkg/chrootarchive/archive_test.go
@@ -0,0 +1,367 @@
+package chrootarchive
+
+import (
+	"bytes"
+	"fmt"
+	"hash/crc32"
+	"io"
+	"os"
+	"path/filepath"
+	"runtime"
+	"strings"
+	"testing"
+	"time"
+
+	"github.com/docker/docker/pkg/archive"
+	"github.com/docker/docker/pkg/idtools"
+	"gotest.tools/v3/skip"
+)
+
+var chrootArchiver = NewArchiver(idtools.IdentityMapping{})
+
+func TarUntar(src, dst string) error {
+	return chrootArchiver.TarUntar(src, dst)
+}
+
+func CopyFileWithTar(src, dst string) (err error) {
+	return chrootArchiver.CopyFileWithTar(src, dst)
+}
+
+func UntarPath(src, dst string) error {
+	return chrootArchiver.UntarPath(src, dst)
+}
+
+func CopyWithTar(src, dst string) error {
+	return chrootArchiver.CopyWithTar(src, dst)
+}
+
+func TestChrootTarUntar(t *testing.T) {
+	skip.If(t, os.Getuid() != 0, "skipping test that requires root")
+	tmpdir := t.TempDir()
+	src := filepath.Join(tmpdir, "src")
+	if err := os.Mkdir(src, 0o700); err != nil {
+		t.Fatal(err)
+	}
+	if err := os.WriteFile(filepath.Join(src, "toto"), []byte("hello toto"), 0o644); err != nil {
+		t.Fatal(err)
+	}
+	if err := os.WriteFile(filepath.Join(src, "lolo"), []byte("hello lolo"), 0o644); err != nil {
+		t.Fatal(err)
+	}
+	stream, err := archive.Tar(src, archive.Uncompressed)
+	if err != nil {
+		t.Fatal(err)
+	}
+	dest := filepath.Join(tmpdir, "dest")
+	if err := os.Mkdir(dest, 0o700); err != nil {
+		t.Fatal(err)
+	}
+	if err := Untar(stream, dest, &archive.TarOptions{ExcludePatterns: []string{"lolo"}}); err != nil {
+		t.Fatal(err)
+	}
+}
+
+// gh#10426: Verify the fix for having a huge excludes list (like on `docker load` with large # of
+// local images)
+func TestChrootUntarWithHugeExcludesList(t *testing.T) {
+	skip.If(t, os.Getuid() != 0, "skipping test that requires root")
+	tmpdir := t.TempDir()
+	src := filepath.Join(tmpdir, "src")
+	if err := os.Mkdir(src, 0o700); err != nil {
+		t.Fatal(err)
+	}
+	if err := os.WriteFile(filepath.Join(src, "toto"), []byte("hello toto"), 0o644); err != nil {
+		t.Fatal(err)
+	}
+	stream, err := archive.Tar(src, archive.Uncompressed)
+	if err != nil {
+		t.Fatal(err)
+	}
+	dest := filepath.Join(tmpdir, "dest")
+	if err := os.Mkdir(dest, 0o700); err != nil {
+		t.Fatal(err)
+	}
+	options := &archive.TarOptions{}
+	// 65534 entries of 64-byte strings ~= 4MB of environment space which should overflow
+	// on most systems when passed via environment or command line arguments
+	excludes := make([]string, 65534)
+	var i rune
+	for i = 0; i < 65534; i++ {
+		excludes[i] = strings.Repeat(string(i), 64)
+	}
+	options.ExcludePatterns = excludes
+	if err := Untar(stream, dest, options); err != nil {
+		t.Fatal(err)
+	}
+}
+
+func TestChrootUntarEmptyArchive(t *testing.T) {
+	if err := Untar(nil, t.TempDir(), nil); err == nil {
+		t.Fatal("expected error on empty archive")
+	}
+}
+
+func prepareSourceDirectory(numberOfFiles int, targetPath string, makeSymLinks bool) (int, error) {
+	fileData := []byte("fooo")
+	for n := 0; n < numberOfFiles; n++ {
+		fileName := fmt.Sprintf("file-%d", n)
+		if err := os.WriteFile(filepath.Join(targetPath, fileName), fileData, 0o700); err != nil {
+			return 0, err
+		}
+		if makeSymLinks {
+			if err := os.Symlink(filepath.Join(targetPath, fileName), filepath.Join(targetPath, fileName+"-link")); err != nil {
+				return 0, err
+			}
+		}
+	}
+	totalSize := numberOfFiles * len(fileData)
+	return totalSize, nil
+}
+
+func getHash(filename string) (uint32, error) {
+	stream, err := os.ReadFile(filename)
+	if err != nil {
+		return 0, err
+	}
+	hash := crc32.NewIEEE()
+	hash.Write(stream)
+	return hash.Sum32(), nil
+}
+
+func compareDirectories(src string, dest string) error {
+	changes, err := archive.ChangesDirs(dest, src)
+	if err != nil {
+		return err
+	}
+	if len(changes) > 0 {
+		return fmt.Errorf("Unexpected differences after untar: %v", changes)
+	}
+	return nil
+}
+
+func compareFiles(src string, dest string) error {
+	srcHash, err := getHash(src)
+	if err != nil {
+		return err
+	}
+	destHash, err := getHash(dest)
+	if err != nil {
+		return err
+	}
+	if srcHash != destHash {
+		return fmt.Errorf("%s is different from %s", src, dest)
+	}
+	return nil
+}
+
+func TestChrootTarUntarWithSymlink(t *testing.T) {
+	skip.If(t, runtime.GOOS == "windows", "FIXME: figure out why this is failing")
+	skip.If(t, os.Getuid() != 0, "skipping test that requires root")
+	tmpdir := t.TempDir()
+	src := filepath.Join(tmpdir, "src")
+	if err := os.Mkdir(src, 0o700); err != nil {
+		t.Fatal(err)
+	}
+	if _, err := prepareSourceDirectory(10, src, false); err != nil {
+		t.Fatal(err)
+	}
+	dest := filepath.Join(tmpdir, "dest")
+	if err := TarUntar(src, dest); err != nil {
+		t.Fatal(err)
+	}
+	if err := compareDirectories(src, dest); err != nil {
+		t.Fatal(err)
+	}
+}
+
+func TestChrootCopyWithTar(t *testing.T) {
+	skip.If(t, runtime.GOOS == "windows", "FIXME: figure out why this is failing")
+	skip.If(t, os.Getuid() != 0, "skipping test that requires root")
+	tmpdir := t.TempDir()
+	src := filepath.Join(tmpdir, "src")
+	if err := os.Mkdir(src, 0o700); err != nil {
+		t.Fatal(err)
+	}
+	if _, err := prepareSourceDirectory(10, src, true); err != nil {
+		t.Fatal(err)
+	}
+
+	// Copy directory
+	dest := filepath.Join(tmpdir, "dest")
+	if err := CopyWithTar(src, dest); err != nil {
+		t.Fatal(err)
+	}
+	if err := compareDirectories(src, dest); err != nil {
+		t.Fatal(err)
+	}
+
+	// Copy file
+	srcfile := filepath.Join(src, "file-1")
+	dest = filepath.Join(tmpdir, "destFile")
+	destfile := filepath.Join(dest, "file-1")
+	if err := CopyWithTar(srcfile, destfile); err != nil {
+		t.Fatal(err)
+	}
+	if err := compareFiles(srcfile, destfile); err != nil {
+		t.Fatal(err)
+	}
+
+	// Copy symbolic link
+	srcLinkfile := filepath.Join(src, "file-1-link")
+	dest = filepath.Join(tmpdir, "destSymlink")
+	destLinkfile := filepath.Join(dest, "file-1-link")
+	if err := CopyWithTar(srcLinkfile, destLinkfile); err != nil {
+		t.Fatal(err)
+	}
+	if err := compareFiles(srcLinkfile, destLinkfile); err != nil {
+		t.Fatal(err)
+	}
+}
+
+func TestChrootCopyFileWithTar(t *testing.T) {
+	skip.If(t, os.Getuid() != 0, "skipping test that requires root")
+	tmpdir := t.TempDir()
+	src := filepath.Join(tmpdir, "src")
+	if err := os.Mkdir(src, 0o700); err != nil {
+		t.Fatal(err)
+	}
+	if _, err := prepareSourceDirectory(10, src, true); err != nil {
+		t.Fatal(err)
+	}
+
+	// Copy directory
+	dest := filepath.Join(tmpdir, "dest")
+	if err := CopyFileWithTar(src, dest); err == nil {
+		t.Fatal("Expected error on copying directory")
+	}
+
+	// Copy file
+	srcfile := filepath.Join(src, "file-1")
+	dest = filepath.Join(tmpdir, "destFile")
+	destfile := filepath.Join(dest, "file-1")
+	if err := CopyFileWithTar(srcfile, destfile); err != nil {
+		t.Fatal(err)
+	}
+	if err := compareFiles(srcfile, destfile); err != nil {
+		t.Fatal(err)
+	}
+
+	// Copy symbolic link
+	srcLinkfile := filepath.Join(src, "file-1-link")
+	dest = filepath.Join(tmpdir, "destSymlink")
+	destLinkfile := filepath.Join(dest, "file-1-link")
+	if err := CopyFileWithTar(srcLinkfile, destLinkfile); err != nil {
+		t.Fatal(err)
+	}
+	if err := compareFiles(srcLinkfile, destLinkfile); err != nil {
+		t.Fatal(err)
+	}
+}
+
+func TestChrootUntarPath(t *testing.T) {
+	skip.If(t, runtime.GOOS == "windows", "FIXME: figure out why this is failing")
+	skip.If(t, os.Getuid() != 0, "skipping test that requires root")
+	tmpdir := t.TempDir()
+	src := filepath.Join(tmpdir, "src")
+	if err := os.Mkdir(src, 0o700); err != nil {
+		t.Fatal(err)
+	}
+	if _, err := prepareSourceDirectory(10, src, false); err != nil {
+		t.Fatal(err)
+	}
+	dest := filepath.Join(tmpdir, "dest")
+	// Untar a directory
+	if err := UntarPath(src, dest); err == nil {
+		t.Fatal("Expected error on untaring a directory")
+	}
+
+	// Untar a tar file
+	stream, err := archive.Tar(src, archive.Uncompressed)
+	if err != nil {
+		t.Fatal(err)
+	}
+	buf := new(bytes.Buffer)
+	buf.ReadFrom(stream)
+	tarfile := filepath.Join(tmpdir, "src.tar")
+	if err := os.WriteFile(tarfile, buf.Bytes(), 0o644); err != nil {
+		t.Fatal(err)
+	}
+	if err := UntarPath(tarfile, dest); err != nil {
+		t.Fatal(err)
+	}
+	if err := compareDirectories(src, dest); err != nil {
+		t.Fatal(err)
+	}
+}
+
+type slowEmptyTarReader struct {
+	size      int
+	offset    int
+	chunkSize int
+}
+
+// Read is a slow reader of an empty tar (like the output of "tar c --files-from /dev/null")
+func (s *slowEmptyTarReader) Read(p []byte) (int, error) {
+	time.Sleep(100 * time.Millisecond)
+	count := s.chunkSize
+	if len(p) < s.chunkSize {
+		count = len(p)
+	}
+	for i := 0; i < count; i++ {
+		p[i] = 0
+	}
+	s.offset += count
+	if s.offset > s.size {
+		return count, io.EOF
+	}
+	return count, nil
+}
+
+func TestChrootUntarEmptyArchiveFromSlowReader(t *testing.T) {
+	skip.If(t, os.Getuid() != 0, "skipping test that requires root")
+	tmpdir := t.TempDir()
+	dest := filepath.Join(tmpdir, "dest")
+	if err := os.Mkdir(dest, 0o700); err != nil {
+		t.Fatal(err)
+	}
+	stream := &slowEmptyTarReader{size: 10240, chunkSize: 1024}
+	if err := Untar(stream, dest, nil); err != nil {
+		t.Fatal(err)
+	}
+}
+
+func TestChrootApplyEmptyArchiveFromSlowReader(t *testing.T) {
+	skip.If(t, os.Getuid() != 0, "skipping test that requires root")
+	tmpdir := t.TempDir()
+	dest := filepath.Join(tmpdir, "dest")
+	if err := os.Mkdir(dest, 0o700); err != nil {
+		t.Fatal(err)
+	}
+	stream := &slowEmptyTarReader{size: 10240, chunkSize: 1024}
+	if _, err := ApplyLayer(dest, stream); err != nil {
+		t.Fatal(err)
+	}
+}
+
+func TestChrootApplyDotDotFile(t *testing.T) {
+	skip.If(t, os.Getuid() != 0, "skipping test that requires root")
+	tmpdir := t.TempDir()
+	src := filepath.Join(tmpdir, "src")
+	if err := os.Mkdir(src, 0o700); err != nil {
+		t.Fatal(err)
+	}
+	if err := os.WriteFile(filepath.Join(src, "..gitme"), []byte(""), 0o644); err != nil {
+		t.Fatal(err)
+	}
+	stream, err := archive.Tar(src, archive.Uncompressed)
+	if err != nil {
+		t.Fatal(err)
+	}
+	dest := filepath.Join(tmpdir, "dest")
+	if err := os.Mkdir(dest, 0o700); err != nil {
+		t.Fatal(err)
+	}
+	if _, err := ApplyLayer(dest, stream); err != nil {
+		t.Fatal(err)
+	}
+}
diff --git a/vendor/github.com/moby/go-archive/chrootarchive/archive_unix.go b/pkg/chrootarchive/archive_unix.go
similarity index 97%
rename from vendor/github.com/moby/go-archive/chrootarchive/archive_unix.go
rename to pkg/chrootarchive/archive_unix.go
index f82b95bcbf..047237d779 100644
--- a/vendor/github.com/moby/go-archive/chrootarchive/archive_unix.go
+++ b/pkg/chrootarchive/archive_unix.go
@@ -10,7 +10,7 @@ import (
 	"path/filepath"
 	"strings"
 
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 )
 
 func init() {
diff --git a/vendor/github.com/moby/go-archive/chrootarchive/archive_unix_nolinux.go b/pkg/chrootarchive/archive_unix_nolinux.go
similarity index 99%
rename from vendor/github.com/moby/go-archive/chrootarchive/archive_unix_nolinux.go
rename to pkg/chrootarchive/archive_unix_nolinux.go
index f5b02ea550..dbfa8e79ac 100644
--- a/vendor/github.com/moby/go-archive/chrootarchive/archive_unix_nolinux.go
+++ b/pkg/chrootarchive/archive_unix_nolinux.go
@@ -10,10 +10,9 @@ import (
 	"os"
 	"syscall"
 
+	"github.com/docker/docker/pkg/archive"
 	"github.com/moby/sys/reexec"
 	"golang.org/x/sys/unix"
-
-	"github.com/moby/go-archive"
 )
 
 const (
diff --git a/pkg/chrootarchive/archive_unix_nolinux_test.go b/pkg/chrootarchive/archive_unix_nolinux_test.go
new file mode 100644
index 0000000000..0a68df207d
--- /dev/null
+++ b/pkg/chrootarchive/archive_unix_nolinux_test.go
@@ -0,0 +1,16 @@
+//go:build unix && !linux
+
+package chrootarchive
+
+import (
+	"testing"
+
+	"github.com/moby/sys/reexec"
+)
+
+func TestMain(m *testing.M) {
+	if reexec.Init() {
+		return
+	}
+	m.Run()
+}
diff --git a/pkg/chrootarchive/archive_unix_test.go b/pkg/chrootarchive/archive_unix_test.go
new file mode 100644
index 0000000000..c7a0b5f81b
--- /dev/null
+++ b/pkg/chrootarchive/archive_unix_test.go
@@ -0,0 +1,173 @@
+//go:build !windows
+
+package chrootarchive
+
+import (
+	gotar "archive/tar"
+	"bytes"
+	"io"
+	"os"
+	"path"
+	"path/filepath"
+	"strings"
+	"testing"
+
+	"github.com/docker/docker/pkg/archive"
+	"golang.org/x/sys/unix"
+	"gotest.tools/v3/assert"
+	"gotest.tools/v3/skip"
+)
+
+// Test for CVE-2018-15664
+// Assures that in the case where an "attacker" controlled path is a symlink to
+// some path outside of a container's rootfs that we do not copy data to a
+// container path that will actually overwrite data on the host
+func TestUntarWithMaliciousSymlinks(t *testing.T) {
+	skip.If(t, os.Getuid() != 0, "skipping test that requires root")
+	dir := t.TempDir()
+
+	root := filepath.Join(dir, "root")
+
+	err := os.Mkdir(root, 0o755)
+	assert.NilError(t, err)
+
+	// Add a file into a directory above root
+	// Ensure that we can't access this file while tarring.
+	err = os.WriteFile(filepath.Join(dir, "host-file"), []byte("I am a host file"), 0o644)
+	assert.NilError(t, err)
+
+	// Create some data to copy into the "container" root into
+	// the symlinked path.
+	// Before this change, the copy would overwrite the "host" content.
+	// With this change it should not.
+	data := filepath.Join(dir, "data")
+	err = os.Mkdir(data, 0o755)
+	assert.NilError(t, err)
+	err = os.WriteFile(filepath.Join(data, "local-file"), []byte("pwn3d"), 0o644)
+	assert.NilError(t, err)
+
+	safe := filepath.Join(root, "safe")
+	err = unix.Symlink(dir, safe)
+	assert.NilError(t, err)
+
+	rdr, err := archive.TarWithOptions(data, &archive.TarOptions{IncludeFiles: []string{"local-file"}, RebaseNames: map[string]string{"local-file": "host-file"}})
+	assert.NilError(t, err)
+
+	// Use tee to test both the good case and the bad case w/o recreating the archive
+	bufRdr := bytes.NewBuffer(nil)
+	tee := io.TeeReader(rdr, bufRdr)
+
+	err = UntarWithRoot(tee, safe, nil, root)
+	assert.Assert(t, err != nil)
+	assert.ErrorContains(t, err, "open /safe/host-file: no such file or directory")
+
+	// Make sure the "host" file is still in tact
+	// Before the fix the host file would be overwritten
+	hostData, err := os.ReadFile(filepath.Join(dir, "host-file"))
+	assert.NilError(t, err)
+	assert.Equal(t, string(hostData), "I am a host file")
+
+	io.Copy(io.Discard, tee)
+
+	// Now test by chrooting to an attacker controlled path
+	// This should succeed as is and overwrite a "host" file
+	// Note that this would be a mis-use of this function.
+	err = UntarWithRoot(bufRdr, safe, nil, safe)
+	assert.NilError(t, err)
+
+	hostData, err = os.ReadFile(filepath.Join(dir, "host-file"))
+	assert.NilError(t, err)
+	assert.Equal(t, string(hostData), "pwn3d")
+}
+
+// Test for CVE-2018-15664
+// Assures that in the case where an "attacker" controlled path is a symlink to
+// some path outside of a container's rootfs that we do not unwittingly leak
+// host data into the archive.
+func TestTarWithMaliciousSymlinks(t *testing.T) {
+	skip.If(t, os.Getuid() != 0, "skipping test that requires root")
+	dir, err := os.MkdirTemp("", t.Name())
+	assert.NilError(t, err)
+	// defer os.RemoveAll(dir)
+	t.Log(dir)
+
+	root := filepath.Join(dir, "root")
+
+	err = os.Mkdir(root, 0o755)
+	assert.NilError(t, err)
+
+	hostFileData := []byte("I am a host file")
+
+	// Add a file into a directory above root
+	// Ensure that we can't access this file while tarring.
+	err = os.WriteFile(filepath.Join(dir, "host-file"), hostFileData, 0o644)
+	assert.NilError(t, err)
+
+	safe := filepath.Join(root, "safe")
+	err = unix.Symlink(dir, safe)
+	assert.NilError(t, err)
+
+	data := filepath.Join(dir, "data")
+	err = os.Mkdir(data, 0o755)
+	assert.NilError(t, err)
+
+	type testCase struct {
+		p        string
+		includes []string
+	}
+
+	cases := []testCase{
+		{p: safe, includes: []string{"host-file"}},
+		{p: safe + "/", includes: []string{"host-file"}},
+		{p: safe, includes: nil},
+		{p: safe + "/", includes: nil},
+		{p: root, includes: []string{"safe/host-file"}},
+		{p: root, includes: []string{"/safe/host-file"}},
+		{p: root, includes: nil},
+	}
+
+	maxBytes := len(hostFileData)
+
+	for _, tc := range cases {
+		t.Run(path.Join(tc.p+"_"+strings.Join(tc.includes, "_")), func(t *testing.T) {
+			// Here if we use archive.TarWithOptions directly or change the "root" parameter
+			// to be the same as "safe", data from the host will be leaked into the archive
+			var opts *archive.TarOptions
+			if tc.includes != nil {
+				opts = &archive.TarOptions{
+					IncludeFiles: tc.includes,
+				}
+			}
+			rdr, err := Tar(tc.p, opts, root)
+			assert.NilError(t, err)
+			defer rdr.Close()
+
+			tr := gotar.NewReader(rdr)
+			assert.Assert(t, !isDataInTar(t, tr, hostFileData, int64(maxBytes)), "host data leaked to archive")
+		})
+	}
+}
+
+func isDataInTar(t *testing.T, tr *gotar.Reader, compare []byte, maxBytes int64) bool {
+	for {
+		h, err := tr.Next()
+		if err == io.EOF {
+			break
+		}
+		assert.NilError(t, err)
+
+		if h.Size == 0 {
+			continue
+		}
+		assert.Assert(t, h.Size <= maxBytes, "%s: file size exceeds max expected size %d: %d", h.Name, maxBytes, h.Size)
+
+		data := make([]byte, int(h.Size))
+		_, err = io.ReadFull(tr, data)
+		assert.NilError(t, err)
+		if bytes.Contains(data, compare) {
+			return true
+		}
+	}
+
+	return false
+}
diff --git a/vendor/github.com/moby/go-archive/chrootarchive/archive_windows.go b/pkg/chrootarchive/archive_windows.go
similarity index 97%
rename from vendor/github.com/moby/go-archive/chrootarchive/archive_windows.go
rename to pkg/chrootarchive/archive_windows.go
index 078341f57f..d7f70bd3a9 100644
--- a/vendor/github.com/moby/go-archive/chrootarchive/archive_windows.go
+++ b/pkg/chrootarchive/archive_windows.go
@@ -4,7 +4,7 @@ import (
 	"io"
 	"strings"
 
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 )
 
 // longPathPrefix is the longpath prefix for Windows file paths.
diff --git a/vendor/github.com/moby/go-archive/chrootarchive/chroot_linux.go b/pkg/chrootarchive/chroot_linux.go
similarity index 92%
rename from vendor/github.com/moby/go-archive/chrootarchive/chroot_linux.go
rename to pkg/chrootarchive/chroot_linux.go
index 3d9790be46..622f70ef19 100644
--- a/vendor/github.com/moby/go-archive/chrootarchive/chroot_linux.go
+++ b/pkg/chrootarchive/chroot_linux.go
@@ -1,11 +1,10 @@
 package chrootarchive
 
 import (
+	"github.com/docker/docker/internal/mounttree"
+	"github.com/docker/docker/internal/unshare"
 	"github.com/moby/sys/mount"
 	"golang.org/x/sys/unix"
-
-	"github.com/moby/go-archive/internal/mounttree"
-	"github.com/moby/go-archive/internal/unshare"
 )
 
 // goInChroot starts fn in a goroutine where the root directory, current working
diff --git a/vendor/github.com/moby/go-archive/chrootarchive/diff.go b/pkg/chrootarchive/diff.go
similarity index 95%
rename from vendor/github.com/moby/go-archive/chrootarchive/diff.go
rename to pkg/chrootarchive/diff.go
index c09fa5b0d0..49acad79ff 100644
--- a/vendor/github.com/moby/go-archive/chrootarchive/diff.go
+++ b/pkg/chrootarchive/diff.go
@@ -3,7 +3,7 @@ package chrootarchive
 import (
 	"io"
 
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 )
 
 // ApplyLayer parses a diff in the standard layer format from `layer`,
diff --git a/pkg/chrootarchive/diff_deprecated.go b/pkg/chrootarchive/diff_deprecated.go
deleted file mode 100644
index 26f8123dfc..0000000000
--- a/pkg/chrootarchive/diff_deprecated.go
+++ /dev/null
@@ -1,24 +0,0 @@
-package chrootarchive
-
-import (
-	"io"
-
-	"github.com/docker/docker/pkg/archive"
-	"github.com/moby/go-archive/chrootarchive"
-)
-
-// ApplyLayer parses a diff in the standard layer format from `layer`,
-// and applies it to the directory `dest`.
-//
-// Deprecated: use [chrootarchive.ApplyLayer] insteead.
-func ApplyLayer(dest string, layer io.Reader) (size int64, err error) {
-	return chrootarchive.ApplyLayer(dest, layer)
-}
-
-// ApplyUncompressedLayer parses a diff in the standard layer format from
-// `layer`, and applies it to the directory `dest`.
-//
-// Deprecated: use [chrootarchive.ApplyUncompressedLayer] insteead.
-func ApplyUncompressedLayer(dest string, layer io.Reader, options *archive.TarOptions) (int64, error) {
-	return chrootarchive.ApplyUncompressedLayer(dest, layer, archive.ToArchiveOpt(options))
-}
diff --git a/vendor/github.com/moby/go-archive/chrootarchive/diff_unix.go b/pkg/chrootarchive/diff_unix.go
similarity index 95%
rename from vendor/github.com/moby/go-archive/chrootarchive/diff_unix.go
rename to pkg/chrootarchive/diff_unix.go
index 70300b8967..be1110dcc3 100644
--- a/vendor/github.com/moby/go-archive/chrootarchive/diff_unix.go
+++ b/pkg/chrootarchive/diff_unix.go
@@ -6,9 +6,8 @@ import (
 	"io"
 	"path/filepath"
 
+	"github.com/docker/docker/pkg/archive"
 	"github.com/moby/sys/userns"
-
-	"github.com/moby/go-archive"
 )
 
 // applyLayerHandler parses a diff in the standard layer format from `layer`, and
diff --git a/vendor/github.com/moby/go-archive/chrootarchive/diff_windows.go b/pkg/chrootarchive/diff_windows.go
similarity index 95%
rename from vendor/github.com/moby/go-archive/chrootarchive/diff_windows.go
rename to pkg/chrootarchive/diff_windows.go
index ac332bc40a..2a0c8b674e 100644
--- a/vendor/github.com/moby/go-archive/chrootarchive/diff_windows.go
+++ b/pkg/chrootarchive/diff_windows.go
@@ -5,7 +5,7 @@ import (
 	"io"
 	"path/filepath"
 
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 )
 
 // applyLayerHandler parses a diff in the standard layer format from `layer`, and
diff --git a/pkg/idtools/idtools.go b/pkg/idtools/idtools.go
index 23e90c22b3..9d50eb526b 100644
--- a/pkg/idtools/idtools.go
+++ b/pkg/idtools/idtools.go
@@ -144,31 +144,6 @@ func fromUserIDMap(u []user.IDMap) []IDMap {
 	return m
 }
 
-// ToUserIdentityMapping converts an [idtools.IdentityMapping] to a [user.IdentityMapping].
-//
-// Deprecated: use [user.IdentityMapping] directly, this is transitioning to user package.
-func ToUserIdentityMapping(u IdentityMapping) user.IdentityMapping {
-	return user.IdentityMapping{
-		UIDMaps: toUserIDMap(u.UIDMaps),
-		GIDMaps: toUserIDMap(u.GIDMaps),
-	}
-}
-
-func toUserIDMap(u []IDMap) []user.IDMap {
-	if u == nil {
-		return nil
-	}
-	m := make([]user.IDMap, len(u))
-	for i := range u {
-		m[i] = user.IDMap{
-			ID:       int64(u[i].ContainerID),
-			ParentID: int64(u[i].HostID),
-			Count:    int64(u[i].Size),
-		}
-	}
-	return m
-}
-
 // RootPair returns a uid and gid pair for the root user. The error is ignored
 // because a root user always exists, and the defaults are correct when the uid
 // and gid maps are empty.
diff --git a/plugin/backend_linux.go b/plugin/backend_linux.go
index 981615f943..469aa4e1d2 100644
--- a/plugin/backend_linux.go
+++ b/plugin/backend_linux.go
@@ -31,11 +31,11 @@ import (
 	"github.com/docker/docker/errdefs"
 	"github.com/docker/docker/internal/containerfs"
 	"github.com/docker/docker/pkg/authorization"
+	"github.com/docker/docker/pkg/chrootarchive"
 	"github.com/docker/docker/pkg/pools"
 	"github.com/docker/docker/pkg/progress"
 	"github.com/docker/docker/pkg/stringid"
 	v2 "github.com/docker/docker/plugin/v2"
-	"github.com/moby/go-archive/chrootarchive"
 	"github.com/moby/sys/mount"
 	"github.com/opencontainers/go-digest"
 	ocispec "github.com/opencontainers/image-spec/specs-go/v1"
diff --git a/plugin/fetch_linux.go b/plugin/fetch_linux.go
index 4847d6748e..5557445cb5 100644
--- a/plugin/fetch_linux.go
+++ b/plugin/fetch_linux.go
@@ -15,10 +15,10 @@ import (
 	"github.com/distribution/reference"
 	"github.com/docker/docker/api/types/registry"
 	progressutils "github.com/docker/docker/distribution/utils"
+	"github.com/docker/docker/pkg/chrootarchive"
 	"github.com/docker/docker/pkg/ioutils"
 	"github.com/docker/docker/pkg/progress"
 	"github.com/docker/docker/pkg/stringid"
-	"github.com/moby/go-archive/chrootarchive"
 	"github.com/opencontainers/go-digest"
 	ocispec "github.com/opencontainers/image-spec/specs-go/v1"
 	"github.com/pkg/errors"
diff --git a/testutil/fakecontext/context.go b/testutil/fakecontext/context.go
index 036befd333..05dc56fcef 100644
--- a/testutil/fakecontext/context.go
+++ b/testutil/fakecontext/context.go
@@ -7,7 +7,7 @@ import (
 	"path/filepath"
 	"testing"
 
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 )
 
 // New creates a fake build context
diff --git a/testutil/fakestorage/fixtures.go b/testutil/fakestorage/fixtures.go
index f9370698d5..35c61919d7 100644
--- a/testutil/fakestorage/fixtures.go
+++ b/testutil/fakestorage/fixtures.go
@@ -10,7 +10,7 @@ import (
 	"testing"
 
 	"github.com/docker/docker/api/types"
-	"github.com/moby/go-archive"
+	"github.com/docker/docker/pkg/archive"
 	"gotest.tools/v3/assert"
 )
 
diff --git a/testutil/fixtures/plugin/plugin.go b/testutil/fixtures/plugin/plugin.go
index e8f3fca332..acbc38343e 100644
--- a/testutil/fixtures/plugin/plugin.go
+++ b/testutil/fixtures/plugin/plugin.go
@@ -12,9 +12,9 @@ import (
 	"github.com/docker/docker/api/types"
 	"github.com/docker/docker/api/types/events"
 	"github.com/docker/docker/api/types/registry"
+	"github.com/docker/docker/pkg/archive"
 	"github.com/docker/docker/plugin"
 	registrypkg "github.com/docker/docker/registry"
-	"github.com/moby/go-archive"
 	"github.com/pkg/errors"
 )
 
diff --git a/vendor.mod b/vendor.mod
index 0c0eaca89a..919287d505 100644
--- a/vendor.mod
+++ b/vendor.mod
@@ -59,12 +59,12 @@ require (
 	github.com/hashicorp/memberlist v0.4.0
 	github.com/hashicorp/serf v0.8.5
 	github.com/ishidawataru/sctp v0.0.0-20230406120618-7ff4192f6ff2
+	github.com/klauspost/compress v1.18.0
 	github.com/miekg/dns v1.1.61
 	github.com/mistifyio/go-zfs/v3 v3.0.1
 	github.com/mitchellh/copystructure v1.2.0
 	github.com/moby/buildkit v0.20.2
 	github.com/moby/docker-image-spec v1.3.1
-	github.com/moby/go-archive v0.0.0-20250404171912-21f3f3385ab7
 	github.com/moby/ipvs v1.1.0
 	github.com/moby/locker v1.0.1
 	github.com/moby/patternmatcher v0.6.0
@@ -185,7 +185,6 @@ require (
 	github.com/in-toto/in-toto-golang v0.5.0 // indirect
 	github.com/inconshreveable/mousetrap v1.1.0 // indirect
 	github.com/jmoiron/sqlx v1.3.3 // indirect
-	github.com/klauspost/compress v1.18.0 // indirect
 	github.com/mitchellh/hashstructure/v2 v2.0.2 // indirect
 	github.com/mitchellh/reflectwalk v1.0.2 // indirect
 	github.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect
diff --git a/vendor.sum b/vendor.sum
index f13679488e..3be7c373b9 100644
--- a/vendor.sum
+++ b/vendor.sum
@@ -387,8 +387,6 @@ github.com/moby/buildkit v0.20.2 h1:qIeR47eQ1tzI1rwz0on3Xx2enRw/1CKjFhoONVcTlMA=
 github.com/moby/buildkit v0.20.2/go.mod h1:DhaF82FjwOElTftl0JUAJpH/SUIUx4UvcFncLeOtlDI=
 github.com/moby/docker-image-spec v1.3.1 h1:jMKff3w6PgbfSa69GfNg+zN/XLhfXJGnEx3Nl2EsFP0=
 github.com/moby/docker-image-spec v1.3.1/go.mod h1:eKmb5VW8vQEh/BAr2yvVNvuiJuY6UIocYsFu/DxxRpo=
-github.com/moby/go-archive v0.0.0-20250404171912-21f3f3385ab7 h1:CWAY9uG9JhmLmnM7T64+bV0C9IraDrvxEwXq1HJ7hhk=
-github.com/moby/go-archive v0.0.0-20250404171912-21f3f3385ab7/go.mod h1:G9B+YoujNohJmrIYFBpSd54GTUB4lt9S+xVQvsJyFuo=
 github.com/moby/ipvs v1.1.0 h1:ONN4pGaZQgAx+1Scz5RvWV4Q7Gb+mvfRh3NsPS+1XQQ=
 github.com/moby/ipvs v1.1.0/go.mod h1:4VJMWuf098bsUMmZEiD4Tjk/O7mOn3l1PTD3s4OoYAs=
 github.com/moby/locker v1.0.1 h1:fOXqR41zeveg4fFODix+1Ch4mj/gT0NE1XJbp/epuBg=
diff --git a/vendor/github.com/moby/go-archive/LICENSE b/vendor/github.com/moby/go-archive/LICENSE
deleted file mode 100644
index d645695673..0000000000
--- a/vendor/github.com/moby/go-archive/LICENSE
+++ /dev/null
@@ -1,202 +0,0 @@
-
-                                 Apache License
-                           Version 2.0, January 2004
-                        http://www.apache.org/licenses/
-
-   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
-
-   1. Definitions.
-
-      "License" shall mean the terms and conditions for use, reproduction,
-      and distribution as defined by Sections 1 through 9 of this document.
-
-      "Licensor" shall mean the copyright owner or entity authorized by
-      the copyright owner that is granting the License.
-
-      "Legal Entity" shall mean the union of the acting entity and all
-      other entities that control, are controlled by, or are under common
-      control with that entity. For the purposes of this definition,
-      "control" means (i) the power, direct or indirect, to cause the
-      direction or management of such entity, whether by contract or
-      otherwise, or (ii) ownership of fifty percent (50%) or more of the
-      outstanding shares, or (iii) beneficial ownership of such entity.
-
-      "You" (or "Your") shall mean an individual or Legal Entity
-      exercising permissions granted by this License.
-
-      "Source" form shall mean the preferred form for making modifications,
-      including but not limited to software source code, documentation
-      source, and configuration files.
-
-      "Object" form shall mean any form resulting from mechanical
-      transformation or translation of a Source form, including but
-      not limited to compiled object code, generated documentation,
-      and conversions to other media types.
-
-      "Work" shall mean the work of authorship, whether in Source or
-      Object form, made available under the License, as indicated by a
-      copyright notice that is included in or attached to the work
-      (an example is provided in the Appendix below).
-
-      "Derivative Works" shall mean any work, whether in Source or Object
-      form, that is based on (or derived from) the Work and for which the
-      editorial revisions, annotations, elaborations, or other modifications
-      represent, as a whole, an original work of authorship. For the purposes
-      of this License, Derivative Works shall not include works that remain
-      separable from, or merely link (or bind by name) to the interfaces of,
-      the Work and Derivative Works thereof.
-
-      "Contribution" shall mean any work of authorship, including
-      the original version of the Work and any modifications or additions
-      to that Work or Derivative Works thereof, that is intentionally
-      submitted to Licensor for inclusion in the Work by the copyright owner
-      or by an individual or Legal Entity authorized to submit on behalf of
-      the copyright owner. For the purposes of this definition, "submitted"
-      means any form of electronic, verbal, or written communication sent
-      to the Licensor or its representatives, including but not limited to
-      communication on electronic mailing lists, source code control systems,
-      and issue tracking systems that are managed by, or on behalf of, the
-      Licensor for the purpose of discussing and improving the Work, but
-      excluding communication that is conspicuously marked or otherwise
-      designated in writing by the copyright owner as "Not a Contribution."
-
-      "Contributor" shall mean Licensor and any individual or Legal Entity
-      on behalf of whom a Contribution has been received by Licensor and
-      subsequently incorporated within the Work.
-
-   2. Grant of Copyright License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      copyright license to reproduce, prepare Derivative Works of,
-      publicly display, publicly perform, sublicense, and distribute the
-      Work and such Derivative Works in Source or Object form.
-
-   3. Grant of Patent License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      (except as stated in this section) patent license to make, have made,
-      use, offer to sell, sell, import, and otherwise transfer the Work,
-      where such license applies only to those patent claims licensable
-      by such Contributor that are necessarily infringed by their
-      Contribution(s) alone or by combination of their Contribution(s)
-      with the Work to which such Contribution(s) was submitted. If You
-      institute patent litigation against any entity (including a
-      cross-claim or counterclaim in a lawsuit) alleging that the Work
-      or a Contribution incorporated within the Work constitutes direct
-      or contributory patent infringement, then any patent licenses
-      granted to You under this License for that Work shall terminate
-      as of the date such litigation is filed.
-
-   4. Redistribution. You may reproduce and distribute copies of the
-      Work or Derivative Works thereof in any medium, with or without
-      modifications, and in Source or Object form, provided that You
-      meet the following conditions:
-
-      (a) You must give any other recipients of the Work or
-          Derivative Works a copy of this License; and
-
-      (b) You must cause any modified files to carry prominent notices
-          stating that You changed the files; and
-
-      (c) You must retain, in the Source form of any Derivative Works
-          that You distribute, all copyright, patent, trademark, and
-          attribution notices from the Source form of the Work,
-          excluding those notices that do not pertain to any part of
-          the Derivative Works; and
-
-      (d) If the Work includes a "NOTICE" text file as part of its
-          distribution, then any Derivative Works that You distribute must
-          include a readable copy of the attribution notices contained
-          within such NOTICE file, excluding those notices that do not
-          pertain to any part of the Derivative Works, in at least one
-          of the following places: within a NOTICE text file distributed
-          as part of the Derivative Works; within the Source form or
-          documentation, if provided along with the Derivative Works; or,
-          within a display generated by the Derivative Works, if and
-          wherever such third-party notices normally appear. The contents
-          of the NOTICE file are for informational purposes only and
-          do not modify the License. You may add Your own attribution
-          notices within Derivative Works that You distribute, alongside
-          or as an addendum to the NOTICE text from the Work, provided
-          that such additional attribution notices cannot be construed
-          as modifying the License.
-
-      You may add Your own copyright statement to Your modifications and
-      may provide additional or different license terms and conditions
-      for use, reproduction, or distribution of Your modifications, or
-      for any such Derivative Works as a whole, provided Your use,
-      reproduction, and distribution of the Work otherwise complies with
-      the conditions stated in this License.
-
-   5. Submission of Contributions. Unless You explicitly state otherwise,
-      any Contribution intentionally submitted for inclusion in the Work
-      by You to the Licensor shall be under the terms and conditions of
-      this License, without any additional terms or conditions.
-      Notwithstanding the above, nothing herein shall supersede or modify
-      the terms of any separate license agreement you may have executed
-      with Licensor regarding such Contributions.
-
-   6. Trademarks. This License does not grant permission to use the trade
-      names, trademarks, service marks, or product names of the Licensor,
-      except as required for reasonable and customary use in describing the
-      origin of the Work and reproducing the content of the NOTICE file.
-
-   7. Disclaimer of Warranty. Unless required by applicable law or
-      agreed to in writing, Licensor provides the Work (and each
-      Contributor provides its Contributions) on an "AS IS" BASIS,
-      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-      implied, including, without limitation, any warranties or conditions
-      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
-      PARTICULAR PURPOSE. You are solely responsible for determining the
-      appropriateness of using or redistributing the Work and assume any
-      risks associated with Your exercise of permissions under this License.
-
-   8. Limitation of Liability. In no event and under no legal theory,
-      whether in tort (including negligence), contract, or otherwise,
-      unless required by applicable law (such as deliberate and grossly
-      negligent acts) or agreed to in writing, shall any Contributor be
-      liable to You for damages, including any direct, indirect, special,
-      incidental, or consequential damages of any character arising as a
-      result of this License or out of the use or inability to use the
-      Work (including but not limited to damages for loss of goodwill,
-      work stoppage, computer failure or malfunction, or any and all
-      other commercial damages or losses), even if such Contributor
-      has been advised of the possibility of such damages.
-
-   9. Accepting Warranty or Additional Liability. While redistributing
-      the Work or Derivative Works thereof, You may choose to offer,
-      and charge a fee for, acceptance of support, warranty, indemnity,
-      or other liability obligations and/or rights consistent with this
-      License. However, in accepting such obligations, You may act only
-      on Your own behalf and on Your sole responsibility, not on behalf
-      of any other Contributor, and only if You agree to indemnify,
-      defend, and hold each Contributor harmless for any liability
-      incurred by, or claims asserted against, such Contributor by reason
-      of your accepting any such warranty or additional liability.
-
-   END OF TERMS AND CONDITIONS
-
-   APPENDIX: How to apply the Apache License to your work.
-
-      To apply the Apache License to your work, attach the following
-      boilerplate notice, with the fields enclosed by brackets "[]"
-      replaced with your own identifying information. (Don't include
-      the brackets!)  The text should be enclosed in the appropriate
-      comment syntax for the file format. We also recommend that a
-      file or class name and description of purpose be included on the
-      same "printed page" as the copyright notice for easier
-      identification within third-party archives.
-
-   Copyright [yyyy] [name of copyright owner]
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
diff --git a/vendor/github.com/moby/go-archive/internal/mounttree/switchroot_linux.go b/vendor/github.com/moby/go-archive/internal/mounttree/switchroot_linux.go
deleted file mode 100644
index 31a8e0ed7a..0000000000
--- a/vendor/github.com/moby/go-archive/internal/mounttree/switchroot_linux.go
+++ /dev/null
@@ -1,94 +0,0 @@
-package mounttree
-
-import (
-	"fmt"
-	"os"
-	"path/filepath"
-
-	"github.com/moby/sys/mount"
-	"github.com/moby/sys/mountinfo"
-	"golang.org/x/sys/unix"
-)
-
-// SwitchRoot changes path to be the root of the mount tree and changes the
-// current working directory to the new root.
-//
-// This function bind-mounts onto path; it is the caller's responsibility to set
-// the desired propagation mode of path's parent mount beforehand to prevent
-// unwanted propagation into different mount namespaces.
-func SwitchRoot(path string) error {
-	if mounted, _ := mountinfo.Mounted(path); !mounted {
-		if err := mount.Mount(path, path, "bind", "rbind,rw"); err != nil {
-			return realChroot(path)
-		}
-	}
-
-	// setup oldRoot for pivot_root
-	pivotDir, err := os.MkdirTemp(path, ".pivot_root")
-	if err != nil {
-		return fmt.Errorf("Error setting up pivot dir: %v", err)
-	}
-
-	var mounted bool
-	defer func() {
-		if mounted {
-			// make sure pivotDir is not mounted before we try to remove it
-			if errCleanup := unix.Unmount(pivotDir, unix.MNT_DETACH); errCleanup != nil {
-				if err == nil {
-					err = errCleanup
-				}
-				return
-			}
-		}
-
-		errCleanup := os.Remove(pivotDir)
-		// pivotDir doesn't exist if pivot_root failed and chroot+chdir was successful
-		// because we already cleaned it up on failed pivot_root
-		if errCleanup != nil && !os.IsNotExist(errCleanup) {
-			errCleanup = fmt.Errorf("Error cleaning up after pivot: %v", errCleanup)
-			if err == nil {
-				err = errCleanup
-			}
-		}
-	}()
-
-	if err := unix.PivotRoot(path, pivotDir); err != nil {
-		// If pivot fails, fall back to the normal chroot after cleaning up temp dir
-		if err := os.Remove(pivotDir); err != nil {
-			return fmt.Errorf("Error cleaning up after failed pivot: %v", err)
-		}
-		return realChroot(path)
-	}
-	mounted = true
-
-	// This is the new path for where the old root (prior to the pivot) has been moved to
-	// This dir contains the rootfs of the caller, which we need to remove so it is not visible during extraction
-	pivotDir = filepath.Join("/", filepath.Base(pivotDir))
-
-	if err := unix.Chdir("/"); err != nil {
-		return fmt.Errorf("Error changing to new root: %v", err)
-	}
-
-	// Make the pivotDir (where the old root lives) private so it can be unmounted without propagating to the host
-	if err := unix.Mount("", pivotDir, "", unix.MS_PRIVATE|unix.MS_REC, ""); err != nil {
-		return fmt.Errorf("Error making old root private after pivot: %v", err)
-	}
-
-	// Now unmount the old root so it's no longer visible from the new root
-	if err := unix.Unmount(pivotDir, unix.MNT_DETACH); err != nil {
-		return fmt.Errorf("Error while unmounting old root after pivot: %v", err)
-	}
-	mounted = false
-
-	return nil
-}
-
-func realChroot(path string) error {
-	if err := unix.Chroot(path); err != nil {
-		return fmt.Errorf("Error after fallback to chroot: %v", err)
-	}
-	if err := unix.Chdir("/"); err != nil {
-		return fmt.Errorf("Error changing to new root after chroot: %v", err)
-	}
-	return nil
-}
diff --git a/vendor/github.com/moby/go-archive/internal/unshare/unshare_linux.go b/vendor/github.com/moby/go-archive/internal/unshare/unshare_linux.go
deleted file mode 100644
index 8491b3abc0..0000000000
--- a/vendor/github.com/moby/go-archive/internal/unshare/unshare_linux.go
+++ /dev/null
@@ -1,173 +0,0 @@
-package unshare
-
-import (
-	"fmt"
-	"os"
-	"runtime"
-
-	"golang.org/x/sys/unix"
-)
-
-func init() {
-	// The startup thread of a process is special in a few different ways.
-	// Most pertinent to the discussion at hand, any per-thread kernel state
-	// reflected in the /proc/[pid]/ directory for a process is taken from
-	// the state of the startup thread. Same goes for /proc/self/; it shows
-	// the state of the current process' startup thread, no matter which
-	// thread the files are being opened from. For most programs this is a
-	// distinction without a difference as the kernel state, such as the
-	// mount namespace and current working directory, is shared among (and
-	// kept synchronized across) all threads of a process. But things start
-	// to break down once threads start unsharing and modifying parts of
-	// their kernel state.
-	//
-	// The Go runtime schedules goroutines to execute on the startup thread,
-	// same as any other. How this could be problematic is best illustrated
-	// with a concrete example. Consider what happens if a call to
-	// Go(unix.CLONE_NEWNS, ...) spawned a goroutine which gets scheduled
-	// onto the startup thread. The thread's mount namespace will be
-	// unshared and modified. The contents of the /proc/[pid]/mountinfo file
-	// will then describe the mount tree of the unshared namespace, not the
-	// namespace of any other thread. It will remain this way until the
-	// process exits. (The startup thread is special in another way: exiting
-	// it puts the process into a "non-waitable zombie" state. To avoid this
-	// fate, the Go runtime parks the thread instead of exiting if a
-	// goroutine returns while locked to the startup thread. More
-	// information can be found in the Go runtime sources:
-	// `go doc -u -src runtime.mexit`.) The github.com/moby/sys/mountinfo
-	// package reads from /proc/self/mountinfo, so will read the mount tree
-	// for the wrong namespace if the startup thread has had its mount
-	// namespace unshared! The /proc/thread-self/ directory, introduced in
-	// Linux 3.17, is one potential solution to this problem, but every
-	// package which opens files in /proc/self/ would need to be updated,
-	// and fallbacks to /proc/self/task/[tid]/ would be required to support
-	// older kernels. Overlooking any reference to /proc/self/ would
-	// manifest as stochastically-reproducible bugs, so this is far from an
-	// ideal solution.
-	//
-	// Reading from /proc/self/ would not be a problem if we could prevent
-	// the per-thread state of the startup thread from being modified
-	// nondeterministically in the first place. We can accomplish this
-	// simply by locking the main() function to the startup thread! Doing so
-	// excludes any other goroutine from being scheduled on the thread.
-	runtime.LockOSThread()
-}
-
-// reversibleSetnsFlags maps the unshare(2) flags whose effects can be fully
-// reversed using setns(2). The values are the basenames of the corresponding
-// /proc/self/task/[tid]/ns/ magic symlinks to use to save and restore the
-// state.
-var reversibleSetnsFlags = map[int]string{
-	unix.CLONE_NEWCGROUP: "cgroup",
-	unix.CLONE_NEWNET:    "net",
-	unix.CLONE_NEWUTS:    "uts",
-	unix.CLONE_NEWPID:    "pid",
-	unix.CLONE_NEWTIME:   "time",
-
-	// The following CLONE_NEW* flags are not included because they imply
-	// another, irreversible flag when used with unshare(2).
-	//  - unix.CLONE_NEWIPC:  implies CLONE_SYSVMEM
-	//  - unix.CLONE_NEWNS:   implies CLONE_FS
-	//  - unix.CLONE_NEWUSER: implies CLONE_FS since Linux 3.9
-}
-
-// Go calls the given functions in a new goroutine, locked to an OS thread,
-// which has had the parts of its execution state disassociated from the rest of
-// the current process using [unshare(2)]. It blocks until the new goroutine has
-// started and setupfn has returned. fn is only called if setupfn returns nil. A
-// nil setupfn or fn is equivalent to passing a no-op function.
-//
-// The disassociated execution state and any changes made to it are only visible
-// to the goroutine which the functions are called in. Any other goroutines,
-// including ones started from the function, will see the same execution state
-// as the rest of the process.
-//
-// The acceptable flags are documented in the [unshare(2)] Linux man-page.
-// The corresponding CLONE_* constants are defined in package [unix].
-//
-// # Warning
-//
-// This function may terminate the thread which the new goroutine executed on
-// after fn returns, which could cause subprocesses started with the
-// [syscall.SysProcAttr] Pdeathsig field set to be signaled before process
-// termination. Any subprocess started before this function is called may be
-// affected, in addition to any subprocesses started inside setupfn or fn.
-// There are more details at https://go.dev/issue/27505.
-//
-// [unshare(2)]: https://man7.org/linux/man-pages/man2/unshare.2.html
-func Go(flags int, setupfn func() error, fn func()) error {
-	started := make(chan error)
-
-	maskedFlags := flags
-	for f := range reversibleSetnsFlags {
-		maskedFlags &^= f
-	}
-	isReversible := maskedFlags == 0
-
-	go func() {
-		// Prepare to manipulate per-thread kernel state.
-		runtime.LockOSThread()
-
-		// Not all changes to the execution state can be reverted.
-		// If an irreversible change to the execution state is made, our
-		// only recourse is to have the tampered thread terminated by
-		// returning from this function while the goroutine remains
-		// wired to the thread. The Go runtime will terminate the thread
-		// and replace it with a fresh one as needed.
-
-		if isReversible {
-			defer func() {
-				if isReversible {
-					// All execution state has been restored without error.
-					// The thread is once again fungible.
-					runtime.UnlockOSThread()
-				}
-			}()
-			tid := unix.Gettid()
-			for f, ns := range reversibleSetnsFlags {
-				if flags&f != f {
-					continue
-				}
-				// The /proc/thread-self directory was added in Linux 3.17.
-				// We are not using it to maximize compatibility.
-				pth := fmt.Sprintf("/proc/self/task/%d/ns/%s", tid, ns)
-				fd, err := unix.Open(pth, unix.O_RDONLY|unix.O_CLOEXEC, 0)
-				if err != nil {
-					started <- &os.PathError{Op: "open", Path: pth, Err: err}
-					return
-				}
-				defer func() {
-					if isReversible {
-						if err := unix.Setns(fd, 0); err != nil {
-							isReversible = false
-						}
-					}
-					_ = unix.Close(fd)
-				}()
-			}
-		}
-
-		// Threads are implemented under Linux as processes which share
-		// a virtual memory space. Therefore in a multithreaded process
-		// unshare(2) disassociates parts of the calling thread's
-		// context from the thread it was clone(2)'d from.
-		if err := unix.Unshare(flags); err != nil {
-			started <- os.NewSyscallError("unshare", err)
-			return
-		}
-
-		if setupfn != nil {
-			if err := setupfn(); err != nil {
-				started <- err
-				return
-			}
-		}
-		close(started)
-
-		if fn != nil {
-			fn()
-		}
-	}()
-
-	return <-started
-}
diff --git a/vendor/modules.txt b/vendor/modules.txt
index 156f66cd76..72a57ed96d 100644
--- a/vendor/modules.txt
+++ b/vendor/modules.txt
@@ -924,12 +924,6 @@ github.com/moby/buildkit/worker/label
 # github.com/moby/docker-image-spec v1.3.1
 ## explicit; go 1.18
 github.com/moby/docker-image-spec/specs-go/v1
-# github.com/moby/go-archive v0.0.0-20250404171912-21f3f3385ab7
-## explicit; go 1.23.0
-github.com/moby/go-archive
-github.com/moby/go-archive/chrootarchive
-github.com/moby/go-archive/internal/mounttree
-github.com/moby/go-archive/internal/unshare
 # github.com/moby/ipvs v1.1.0
 ## explicit; go 1.17
 github.com/moby/ipvs
